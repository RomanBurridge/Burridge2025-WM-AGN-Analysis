{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Here for Making Beam-Date Graphs\n",
    "#format beamsize number\n",
    "def format_number(number):\n",
    "        # Case 1: If the number is less than 1 (e.g., 0.004567)\n",
    "        if number < 0:\n",
    "                # Format the positive part of the number and prepend the negative sign\n",
    "                return \"-\" + format_number(abs(number))\n",
    "        if number < 1:\n",
    "                # Convert the number to a string with high precision\n",
    "                num_str = f\"{number:.16g}\"\n",
    "\n",
    "                # Identify the leading zeros and decimal point\n",
    "                leading_part = []\n",
    "                for char in num_str:\n",
    "                        if char == '0' or char == '.':\n",
    "                                leading_part.append(char)\n",
    "                        else:\n",
    "                                break\n",
    "\n",
    "                # Remove leading zeros and the decimal point for significant digits\n",
    "                significant_digits = \"\".join(char for char in num_str if char.isdigit() and char != \"0\")\n",
    "\n",
    "                # Extract the first two non-zero digits\n",
    "                if len(significant_digits) >= 2:\n",
    "                        first_two = significant_digits[:2]\n",
    "                elif len(significant_digits) == 1:\n",
    "                        first_two = significant_digits + \"0\"  # Pad with zero if only one significant digit exists\n",
    "                else:\n",
    "                        first_two = \"00\"  # Handle edge case like 0\n",
    "\n",
    "                # Combine the leading zeros and the first two non-zero digits\n",
    "                return \"\".join(leading_part) + first_two\n",
    "\n",
    "        # Case 2: If the number is greater than or equal to 1\n",
    "        else:\n",
    "                # Format to two decimal places\n",
    "                return f\"{number:.2f}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spectral Plots\n",
    "import matplotlib.pyplot as pylab\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import matplotlib.cm as cmx\n",
    "import math\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import copy\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "jet = pylab.get_cmap('jet')\n",
    "colors = jet(np.linspace(0, 1, 256))\n",
    "colors = colors[np.logical_not((colors[:,0] > 0.9) & (colors[:,1] > 0.9))]  # crude yellow filter\n",
    "cm2 = LinearSegmentedColormap.from_list('jet_no_yellow', colors)\n",
    "\n",
    "os.chdir('analysis/multi_freq_from_archive')\n",
    "\n",
    "sourcesofinterest=('4258','1194','3079','4945','Circinus','1068','2273','4388','2960','3789')\n",
    "#sourcesofinterest=('1194','4258')\n",
    "\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "msize=10\n",
    "\n",
    "path = f'SpectraGraphs'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "freqs=[]\n",
    "fluxs=[]\n",
    "beams=[]\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    jfin=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in source.lower():\n",
    "                jfin=jfin+1 \n",
    "grouped_data = {}\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    for line in infile:\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        \n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in source.lower():\n",
    "                breaker=0\n",
    "        if breaker==1:\n",
    "            continue\n",
    "        j=j+1\n",
    "        \n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            beams='NA'\n",
    "\n",
    "\n",
    "        if source not in grouped_data:\n",
    "            grouped_data[source] = {\n",
    "                'sfreqs': [], 'sfluxs': [], 'sbeams': [], 'sdates': [],\n",
    "                'sfreqs2': [], 'sfluxs2': [], 'sbeams2': [], 'sdates2': [],\n",
    "            }\n",
    "\n",
    "        if j==0:\n",
    "            minfreq=freq\n",
    "            maxfreq=freq\n",
    "            minflux=flux\n",
    "            maxflux=flux\n",
    "            minbeam=beam\n",
    "            maxbeam=beam\n",
    "        if j!=0:\n",
    "            if freq>maxfreq:\n",
    "                maxfreq=freq\n",
    "            if freq<minfreq:\n",
    "                minfreq=freq\n",
    "            if flux>maxflux:\n",
    "                maxflux=flux\n",
    "            if flux<minflux:\n",
    "                minflux=flux\n",
    "            if beam>maxbeam:\n",
    "                maxbeam=beam\n",
    "            if beam<minbeam:\n",
    "                minbeam=beam\n",
    "\n",
    "\n",
    "minfreqp=round_down_to_half_integer(minfreq)\n",
    "maxfreqp=round_up_to_half_integer(maxfreq)\n",
    "\n",
    "minfluxp=round_down_to_half_integer(minflux)\n",
    "maxfluxp=round_up_to_half_integer(maxflux)\n",
    "\n",
    "minbeamp=round_down_to_half_integer(minbeam)\n",
    "maxbeamp=round_up_to_half_integer(maxbeam)\n",
    "\n",
    "interval = maxfreqp - minfreqp\n",
    "ten_percent = interval * 0.05\n",
    "minfreq = minfreqp - ten_percent\n",
    "maxfreq = maxfreqp + ten_percent\n",
    "\n",
    "interval = maxfluxp - minfluxp\n",
    "ten_percent = interval * 0.05\n",
    "minflux = minfluxp - ten_percent\n",
    "maxflux = maxfluxp + ten_percent\n",
    "\n",
    "interval = maxbeamp - minbeamp\n",
    "ten_percent = interval * 0.05\n",
    "minbeam = minbeamp - ten_percent\n",
    "maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "\n",
    "x_tick_positions=np.arange(minfreqp, maxfreqp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5, 0.5)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "stick_positions = np.arange(minbeamp, maxbeamp + 1, 1)  # 6 evenly spaced ticks\n",
    "stick_labels = [f\"{pos:.2f}\" for pos in stick_positions]  # Convert log to linear\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "\n",
    "sourcedone=[]\n",
    "sources=[]\n",
    "\n",
    "oldsources=[]\n",
    "oldsource='NA'\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    j2=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "\n",
    "        breaker=1\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in source.lower():\n",
    "                j2=j2+1 \n",
    "                breaker=0\n",
    "        if breaker==1:\n",
    "            continue\n",
    "        j=j+1\n",
    "\n",
    "        if j==0:\n",
    "            sbeamsizes=[]\n",
    "            sdates=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sbeamsizes2=[]\n",
    "            sdates2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "\n",
    "            \n",
    "        breaker=0\n",
    "\n",
    "        sources.append(source)\n",
    "        sources=list(set(sources))\n",
    "\n",
    "        if len(sources)-len(oldsources)!=0 and j!=0:\n",
    "            source=oldsource\n",
    "\n",
    "            for isource in sourcedone:\n",
    "                if source==isource:\n",
    "                    breaker=1\n",
    "            if breaker==1:\n",
    "                continue\n",
    "            sourcedone.append(source)\n",
    "\n",
    "            fig, ax = pylab.subplots(dpi=300) \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeamp, vmax=maxbeamp), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source} Spectra')\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs'):\n",
    "                os.makedirs(f'SpectraGraphs')\n",
    "            if os.path.exists(f'SpectraGraphs/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{nicename}')\n",
    "            pylab.savefig(f'SpectraGraphs/{nicename}', dpi=300)\n",
    "            pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "            sbeamsizes=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sdates=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "            sdates2=[]\n",
    "\n",
    "        if j2==jfin-1:\n",
    "            if line=='\\n':\n",
    "                continue\n",
    " \n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source} Spectra')\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs'):\n",
    "                os.makedirs('SpectraGraphs')\n",
    "            if os.path.exists(f'SpectraGraphs/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{nicename}')\n",
    "            pylab.savefig(f'SpectraGraphs/{nicename}', dpi=300)\n",
    "            pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "        oldsource=source\n",
    "\n",
    "        flux_upperb=0\n",
    "        if len(str(line[3]).split('*'))>1:\n",
    "            flux_upperb=1\n",
    "\n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        odate=line[4]\n",
    "        if odate!='NA':\n",
    "            odate=odate.split('/')\n",
    "            date=float(odate[0]) + float(odate[1]) / 12 + float(odate[2]) / 365\n",
    "        else:\n",
    "            date='NA'\n",
    "\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            beams=line[5].split('-')\n",
    "            beamavg=(float(beams[0])+float(beams[1]))/2\n",
    "            beam=np.log10(beamavg)\n",
    "\n",
    "        if flux_upperb==0:\n",
    "            sbeamsizes.append(beam)\n",
    "            sfluxs.append(flux)\n",
    "            sfreqs.append(freq)\n",
    "            sdates.append(date)\n",
    "\n",
    "        if flux_upperb==1:\n",
    "            sbeamsizes2.append(beam)\n",
    "            sfluxs2.append(flux)\n",
    "            sfreqs2.append(freq)\n",
    "            sdates2.append(date)\n",
    "\n",
    "        oldsources=copy.deepcopy(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functino to Group frequencies dynamically\n",
    "def group_by_frequency(freqs, fluxes, beams, dates, tolerance):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    current_group_freqs, current_group_fluxes, current_group_beams, current_group_dates = [], [], [], []\n",
    "\n",
    "    sorted_data = sorted(zip(freqs, fluxes, beams, dates), key=lambda x: x[0])\n",
    "    for freq, flux, beam, date in sorted_data:\n",
    "        if not current_group_freqs or abs(freq - current_group_freqs[0]) <= tolerance:\n",
    "            current_group_freqs.append(freq)\n",
    "            current_group_fluxes.append(flux)\n",
    "            current_group_beams.append(beam)\n",
    "            current_group_dates.append(date)\n",
    "        else:\n",
    "            grouped_freqs.append(current_group_freqs)\n",
    "            grouped_fluxes.append(current_group_fluxes)\n",
    "            grouped_beams.append(current_group_beams)\n",
    "            grouped_dates.append(current_group_dates)\n",
    "            current_group_freqs = [freq]\n",
    "            current_group_fluxes = [flux]\n",
    "            current_group_beams = [beam]\n",
    "            current_group_dates = [date]\n",
    "\n",
    "    if current_group_freqs:\n",
    "        grouped_freqs.append(current_group_freqs)\n",
    "        grouped_fluxes.append(current_group_fluxes)\n",
    "        grouped_beams.append(current_group_beams)\n",
    "        grouped_dates.append(current_group_dates)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define frequency ranges for VLA and ALMA bands\n",
    "vla_bands = [\n",
    "    (0.0,0.054) ,     #for Rounding \n",
    "    (0.054, 0.086),  # 4 Band\n",
    "    (0.230, 0.470),  # P Band\n",
    "    (1, 2),          # L Band\n",
    "    (2, 4),          # S Band\n",
    "    (4, 8),          # C Band\n",
    "    (8, 12),         # X Band\n",
    "    (12, 18),        # Ku Band\n",
    "    (18, 26.5),      # K Band\n",
    "    (26.5, 40),      # Ka Band\n",
    "    (40, 50),        # Q Band\n",
    "]\n",
    "\n",
    "alma_bands = [\n",
    "    (31.3, 45),   # Band 1\n",
    "    (67, 90),     # Band 2\n",
    "    (84, 116),    # Band 3\n",
    "    (125, 163),   # Band 4\n",
    "    (163, 211),   # Band 5\n",
    "    (211, 275),   # Band 6\n",
    "    (275, 373),   # Band 7\n",
    "    (385, 500),   # Band 8\n",
    "    (602, 720),   # Band 9\n",
    "    (787, 950),   # Band 10\n",
    "]\n",
    "\n",
    "# Combine all boundaries and create continuous intervals\n",
    "all_boundaries = sorted(set([freq for band in vla_bands + alma_bands for freq in band]))\n",
    "non_overlapping_intervals = [(all_boundaries[i], all_boundaries[i + 1]) for i in range(len(all_boundaries) - 1)]\n",
    "\n",
    "# Remove gaps by ensuring no holes\n",
    "continuous_intervals = []\n",
    "for i, (start, end) in enumerate(non_overlapping_intervals):\n",
    "    if i > 0 and start > continuous_intervals[-1][1]:\n",
    "        # Fill the gap between the previous interval and the current one\n",
    "        continuous_intervals.append((continuous_intervals[-1][1], start))\n",
    "    continuous_intervals.append((start, end))\n",
    "\n",
    "# Function to check if a frequency is in any interval\n",
    "def is_frequency_in_intervals(frequency, intervals):\n",
    "    for start, end in intervals:\n",
    "        if start <= frequency < end:  # Check if frequency is in the interval\n",
    "            return True, (start, end)\n",
    "    return False, None\n",
    "\n",
    "# Print all intervals for verification\n",
    "print(\"\\nAll continuous intervals:\")\n",
    "for i, interval in enumerate(continuous_intervals):\n",
    "    print(f\"Interval {i + 1}: {interval[0]}–{interval[1]} GHz\")\n",
    "\n",
    "def group_by_band(freqs, fluxes, beams, dates, intervals):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    interval_mapping = {interval: ([], [], [], []) for interval in intervals}\n",
    "\n",
    "    for freq, flux, beam, date in zip(freqs, fluxes, beams, dates):\n",
    "        found, assigned_interval = is_frequency_in_intervals(freq, intervals)\n",
    "        if found:\n",
    "            interval_mapping[assigned_interval][0].append(freq)\n",
    "            interval_mapping[assigned_interval][1].append(flux)\n",
    "            interval_mapping[assigned_interval][2].append(beam)\n",
    "            interval_mapping[assigned_interval][3].append(date)\n",
    "\n",
    "    for interval, (freq_list, flux_list, beam_list, date_list) in interval_mapping.items():\n",
    "        if freq_list:\n",
    "            grouped_freqs.append(freq_list)\n",
    "            grouped_fluxes.append(flux_list)\n",
    "            grouped_beams.append(beam_list)\n",
    "            grouped_dates.append(date_list)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Statistical Spectral Plots\n",
    "# Define tolerance for grouping frequencies (log space)\n",
    "tolerance = .05\n",
    "\n",
    "#define if it should be grouped dynamicall or by band\n",
    "grouper='byband'\n",
    "#grouper='bydynam'\n",
    "\n",
    "# Generate consistent x-axis and y-axis tick positions\n",
    "x_tick_positions = np.linspace(minfreq, maxfreq, num=6)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{10**pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.linspace(minflux, maxflux, num=6)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{10**pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "# Apply grouping to all sources\n",
    "for source, data in grouped_data.items():\n",
    "    if grouper=='bydynam':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_frequency(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'],data['sdates'],tolerance\n",
    "        )\n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_frequency(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'],tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_band(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'], continuous_intervals\n",
    "        )\n",
    "        \n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_band(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'], continuous_intervals\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize combined arrays\n",
    "combined_freqs = []  # Combined frequencies\n",
    "combined_fluxes = []  # Combined fluxes\n",
    "combined_beams = []  # Combined beam sizes\n",
    "\n",
    "for source, data in grouped_data.items():\n",
    "    # Combine all frequency, flux, and beam data for the current source\n",
    "    combined_freqs = data['sfreqs'] \n",
    "    combined_fluxes = data['sfluxs'] \n",
    "    combined_beams = data['sbeams'] \n",
    "    combined_dates = data['sdates'] \n",
    "\n",
    "    combined_freqs_2 = data['sfreqs2']\n",
    "    combined_fluxes_2 = data['sfluxs2'] \n",
    "    combined_beams_2 = data['sbeams2'] \n",
    "    combined_dates_2 = data['sdates2'] \n",
    "\n",
    "    # Group the combined data dynamically for the current source\n",
    "    if grouper=='bydynam':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_frequency(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_band(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, continuous_intervals\n",
    "        )\n",
    "\n",
    "    # Iterate over grouped combined data\n",
    "    for freq_group, flux_group, beam_group in zip(grouped_freqs, grouped_fluxes, grouped_beams):\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        if group_size >= 4:\n",
    "            pylab.boxplot(flux_group, positions=[central_freq],widths=0.1,\n",
    "            showfliers=False)  # Customize outliers\n",
    "        elif group_size == 3:\n",
    "            # Vertical line with caps at min and max\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = np.median(flux_group)\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5,  # Length of caps\n",
    "                color='k'\n",
    "            )\n",
    "            # Add a horizontal line at the median_flux\n",
    "            pylab.hlines(\n",
    "                y=median_flux,  # Position of the horizontal line\n",
    "                xmin=central_freq - 0.05,  # Adjust as needed for length\n",
    "                xmax=central_freq + 0.05, \n",
    "                color='r',  # Color of the line\n",
    "                linewidth=1  # Thickness of the horizontal line\n",
    "            )\n",
    "        elif group_size == 2:\n",
    "            # Vertical line with caps at min and max (no median)\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = (min_flux + max_flux) / 2  # Just for centering the line\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5, \n",
    "                color='k'\n",
    "            )\n",
    "\n",
    "        elif group_size == 1:\n",
    "            pylab.scatter([central_freq], [flux_group[0]], c='b', marker='o', s=10)\n",
    "\n",
    "    if combined_fluxes_2:  # Ensure '2' fluxes exist\n",
    "        if not combined_fluxes or min(combined_fluxes_2) < min(combined_fluxes):\n",
    "            # If main fluxes are empty OR '2' minimum is lower\n",
    "            min_flux_2 = min(combined_fluxes_2)\n",
    "            min_flux_2_index = combined_fluxes_2.index(min_flux_2)\n",
    "            min_freq_2 = combined_freqs_2[min_flux_2_index]\n",
    "            # Mark the lowest value with a downward triangle\n",
    "            pylab.scatter([min_freq_2], [min_flux_2], c='black', marker='v', s=7, label='Min Flux from 2')\n",
    "\n",
    "\n",
    "    # Set consistent x and y limits for all plots\n",
    "    pylab.xlim(minfreq - 0.1, maxfreq + 0.1)  # Add slight padding\n",
    "    pylab.ylim(minflux - 0.1, maxflux + 0.1)  # Add slight padding\n",
    "    # Set consistent x-axis ticks and labels\n",
    "    # Set consistent x-axis and y-axis ticks and labels\n",
    "    pylab.xticks(x_tick_positions, x_tick_labels)\n",
    "    pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "\n",
    "    # Add labels and title\n",
    "    pylab.xlabel('Frequency [GHz]')\n",
    "    pylab.ylabel(r'Flux [mJy][Beam]$^{-1}$')\n",
    "    pylab.title(f'{source} Stats')\n",
    "\n",
    "    nicename=f'{source} statistical spectra.pdf'\n",
    "    if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "        os.makedirs(f'SpectraGraphs/{source}')\n",
    "    if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "        os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "    pylab.savefig(f'SpectraGraphs/{source}/{nicename}', dpi=300)\n",
    "    pylab.show()\n",
    "    pylab.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make function to get distances\n",
    "\n",
    "import os\n",
    "from astroquery.ned import Ned\n",
    "import ast  # For safely parsing text file data\n",
    "\n",
    "import os\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "from scipy import constants\n",
    "c=constants.c\n",
    "\n",
    "def is_subsequence(small, large):\n",
    "    it = iter(large)\n",
    "    return all(char in it for char in small)\n",
    "\n",
    "def decompose_string(s):\n",
    "    parts = re.findall(r\"[A-Za-z]+|\\d+\", s)  # Finds all letter and number sequences\n",
    "    return parts if parts else [s]\n",
    "\n",
    "# Input file with source names and coordinates\n",
    "txtnamesandcoords = 'namesandcoords.txt'\n",
    "\n",
    "# List of desired reference codes\n",
    "wantrefs = ['2018ApJ...863..', '2023ApJ...948..', '2020ApJ...890..', '2020ApJ...891..']\n",
    "\n",
    "def getdists(newnames):\n",
    "    newrefs=[]\n",
    "    if not os.path.exists('distancetable.csv'):\n",
    "        url = 'https://ned.ipac.caltech.edu/Archive/Distances/NED30.5.1-D-17.1.2-20200415.csv'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open('distancetable.csv', \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            return(f\"Failed to download. Status code: {response.status_code}\")\n",
    "    \n",
    "    maserdist=[]\n",
    "    otherdist=[]\n",
    "    j1=-1\n",
    "    j2=-1\n",
    "    with open('distancetable.csv', \"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            textsource=row[3]\n",
    "            if len(textsource)==0:\n",
    "                continue\n",
    "            textdistmm=row[4]\n",
    "            textdistmmerr=row[5]\n",
    "\n",
    "            textdistMpc=row[6]\n",
    "            textmethod=row[7]\n",
    "            refcode=row[8]\n",
    "\n",
    "\n",
    "            textsource=textsource.replace(' ','')\n",
    "\n",
    "            findred=0\n",
    "            for i in newnames:\n",
    "                checkers=[]\n",
    "                for ii in i:\n",
    "                    ii=ii.split('Galaxy')[0]\n",
    "                    if is_subsequence(ii, textsource):\n",
    "                        checkers.append(ii)\n",
    "                if len(checkers)==len(i):\n",
    "                    if row[10]:\n",
    "                        findred=1\n",
    "                        redshift=row[10]\n",
    "                        Hubble=row[11]\n",
    "                        newdist=c*float(redshift)/float(Hubble)*c\n",
    "                    \n",
    "                    if textdistmmerr:\n",
    "                        if float(textdistmmerr)>0:\n",
    "                            if 'maser' in textmethod.lower():\n",
    "                                j1=j1+1\n",
    "                                newrefs.append(refcode)\n",
    "                                if j1==0:\n",
    "                                        maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                        maserdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<maserdisuncer:\n",
    "                                    maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                            else:\n",
    "                                j2=j2+1\n",
    "                                if j2==0:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                    otherdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<otherdisuncer:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "\n",
    "    return(maserdist,otherdist,refcode,findred,newrefs)\n",
    "\n",
    "# Function to process each source\n",
    "def process_source(source_name, wantrefs, ra, dec,threshold, secondarynames):\n",
    "  \n",
    "    \"\"\"Query NED for redshift data and filter based on references and uncertainties.\"\"\"\n",
    "    # Skip excluded sources\n",
    "\n",
    "    # Query the redshift table from NED\n",
    "    distances_table = Ned.get_table(source_name, table='redshifts')\n",
    "\n",
    "    # Extract relevant columns\n",
    "    redshifts = distances_table['Published Redshift']\n",
    "    uncertainties = distances_table['Published Redshift Uncertainty']\n",
    "    refcodes = distances_table['Refcode']\n",
    "\n",
    "    # Combine into tuples\n",
    "    entries = [\n",
    "        (redshift, uncertainty, refcode)\n",
    "        for redshift, uncertainty, refcode in zip(redshifts, uncertainties, refcodes)\n",
    "    ]\n",
    "\n",
    "    # Filter for entries with desired references\n",
    "    desired_entries = [\n",
    "        entry for entry in entries if any(ref in entry[2] for ref in wantrefs)\n",
    "    ]\n",
    "\n",
    "    entries_with_reference = []\n",
    "    entries_without_reference = []\n",
    "\n",
    "    for redshift, uncertainty, refcode in desired_entries:\n",
    "        if any(ref in refcode for ref in wantrefs):  # Check if refcode contains a wanted reference\n",
    "            entries_with_reference.append((redshift, uncertainty, refcode))\n",
    "        else:\n",
    "            entries_without_reference.append((redshift, uncertainty, refcode))\n",
    "\n",
    "\n",
    "    reduced_entries = {}\n",
    "\n",
    "    # Step 2a: Prioritize entries from `entries_with_reference`\n",
    "    if entries_with_reference:\n",
    "        for redshift, uncertainty, refcode in entries_with_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "    if len(reduced_entries)==0:\n",
    "        # Step 2b: If `entries_with_reference` is empty, use `entries_without_reference`\n",
    "        for redshift, uncertainty, refcode in entries_without_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "\n",
    "\n",
    "    # Print results based on the filtering\n",
    "    redshift='NA'\n",
    "    uncertainty='NA'\n",
    "\n",
    "    newnames=[]\n",
    "    newlist=decompose_string(secondarynames[0][0])\n",
    "\n",
    "    newnames.append(newlist)\n",
    "    if len(secondarynames[0][1])!=0:\n",
    "        if secondarynames[0][1][0]!='NA':\n",
    "            for i in secondarynames[0][1]:\n",
    "                if not is_subsequence(secondarynames[0][0], i):\n",
    "                    newlist=decompose_string(i)\n",
    "                    newnames.append(newlist)\n",
    "\n",
    "    maserdists, otherdists, inewrefs, findred, newrefs = getdists(newnames)\n",
    "\n",
    "    if reduced_entries:\n",
    "        for irefcode, (iredshift, iuncertainty) in reduced_entries.items():\n",
    "            redshift=iredshift\n",
    "            ynfindref='y'\n",
    "            refcode=irefcode\n",
    "            if iuncertainty>0:\n",
    "                uncertainty=iuncertainty\n",
    "            else:\n",
    "                input(f'No uncertainty for chosen referencecode: {refcode} , {source}')\n",
    "                uncertainty='NA'\n",
    "    else:\n",
    "\n",
    "        # If no desired references, and no maser distances, find valid entries with uncertainties\n",
    "        valid_entries = [entry for entry in entries if entry[1] > 0]\n",
    "        if valid_entries:\n",
    "            # Select the entry with the lowest uncertainty\n",
    "            lowest_uncertainty_entry = min(valid_entries, key=lambda x: x[1])\n",
    "            lowest_redshift, lowest_uncertainty, reference_code = lowest_uncertainty_entry\n",
    "            redshift=lowest_redshift\n",
    "            uncertainty= lowest_uncertainty\n",
    "            refcode=reference_code\n",
    "            ynfindref='n'\n",
    "        else:\n",
    "            input(f\"No valid redshift entries found for {source_name} (1)\\n\")\n",
    "        if len(maserdists)!=0:\n",
    "            z_observed = redshift\n",
    "            if z_observed >= threshold:\n",
    "                if len(maserdists)!=0 and findred==1:\n",
    "                        input('new maser source found... adjust accordingly (1)')\n",
    "        \n",
    "    z_observed = redshift\n",
    "    z_uncer=uncertainty\n",
    "\n",
    "    if z_observed <= threshold:\n",
    "        if len(maserdists)!=0:\n",
    "            input('new maser source found... adjust accordingly (2)')\n",
    "        if len(maserdists)==0:\n",
    "            textdistmm=float(otherdists[1])\n",
    "            textdistmmerr=float(otherdists[2])\n",
    "            textdistMpc=float(otherdists[3])\n",
    "\n",
    "            newdist=10**((textdistmm)/5-5)\n",
    "            newdist_uncer=np.log(10)/5*newdist*textdistmmerr\n",
    "            textmethod=otherdists[4]\n",
    "            refcode=otherdists[5]\n",
    "\n",
    "            return([newdist,newdist_uncer],textmethod,'NA',refcode,'DISTANCE',newrefs)\n",
    "\n",
    "    # Calculate heliocentric velocity\n",
    "    c = 299792.458  # Speed of light in km/s\n",
    "    v_helio = z_observed * c\n",
    "    v_helio_uncer = z_uncer * c\n",
    "\n",
    "    #Hubble Constant\n",
    "    #Pesce, APJ 891:L1\n",
    "    H = 73.9\n",
    "    H_uncer = 3\n",
    "    dist=v_helio/H\n",
    "    dist_uncer=np.sqrt((v_helio_uncer/H)**2 + (v_helio/H**2*H_uncer)**2)\n",
    "\n",
    "    return([dist,dist_uncer],'NA',ynfindref,refcode,'REDSHIFT', newrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on local computer to SMBH mass\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parent\n",
    "Greenepath=f'{parent_dir}/CountingBHS_and_Spectra/Greene_params/Greene_params.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date format\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def decimal_year_to_date(decimal_year):\n",
    "    year = int(decimal_year)  # Extract the year\n",
    "    fraction = decimal_year - year  # Extract the decimal part\n",
    "\n",
    "    # Convert the decimal part to days (assuming 365 days in a year)\n",
    "    days_elapsed = int(round(fraction * 365))  \n",
    "\n",
    "    # Compute the actual date by adding days to January 1st of that year\n",
    "    date = datetime(year, 1, 1) + timedelta(days=days_elapsed)\n",
    "\n",
    "    # Format as YY.MM.DD\n",
    "    #return f\"{date.year }/{date.month:02}/{date.day:02}\"\n",
    "    return f\"{date.year }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get SMBH size\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "def getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc):\n",
    "    mass=10**float(log_BH_mass_solar)*mass_sun\n",
    "    mass_unc=mass*np.log(10)*float(log_BH_mass_solar_uncer)\n",
    "    mass_fracerror=(mass_unc/mass)*100\n",
    "\n",
    "    distance=distanceMPc*pc*10**6\n",
    "    distance_uncer=distanceMPc_uncer*pc*10**6\n",
    "    dist_fracerror=(distance_uncer/distance)*100\n",
    "    \n",
    "    if arcsectopc=='NA':\n",
    "        m_d=mass/distance\n",
    "        m_d_unc=np.sqrt((m_d/mass*mass_unc)**2+(m_d/distance*distance_uncer)**2)\n",
    "        m_d_fracerror=(m_d_unc/m_d)*100\n",
    "        diam_bhs_microarcsec_fracerror = m_d_fracerror\n",
    "\n",
    "        diam_bhs_rad=2*np.sqrt(27)*G/(c**2)*m_d\n",
    "        diam_bhs_deg=diam_bhs_rad*360/(2*pi)\n",
    "        diam_bhs_arcsec=diam_bhs_deg*60*60\n",
    "        diam_bhs_microarcsec=diam_bhs_arcsec*10**6\n",
    "\n",
    "        diam_bhs_microarcsec_unc=diam_bhs_microarcsec/(m_d)*m_d_unc\n",
    "\n",
    "\n",
    "        return(log_BH_mass_solar, log_BH_mass_solar_uncer, mass_fracerror, distanceMPc, distanceMPc_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "        \n",
    "    diam_bhs=2*np.sqrt(27)*G/(c**2)*mass\n",
    "    diam_bhs_unc = 2*np.sqrt(27)*G/(c**2)*mass_unc\n",
    "    \n",
    "    diam_bhspc=diam_bhs/pc\n",
    "    diam_bhspc_unc=diam_bhs_unc/pc\n",
    "\n",
    "    diam_bhs_arsec=diam_bhspc/arcsectopc\n",
    "    diam_bhs_microarcsec=diam_bhs_arsec*10**6\n",
    "\n",
    "    diam_bhs_arsec_unc=np.sqrt(\n",
    "                                (diam_bhspc_unc/arcsectopc)**2\n",
    "                                + ((-1)*diam_bhspc/arcsectopc**2*arcsectopc_unc)**2\n",
    "                                )\n",
    "    \n",
    "    diam_bhs_microarcsec_unc=diam_bhs_arsec_unc*10**6\n",
    "    diam_bhs_microarcsec_fracerror = (diam_bhs_microarcsec_unc/diam_bhs_microarcsec)*100\n",
    "\n",
    "    return(mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "sagmass=6.6\n",
    "sagmass_unc_up=.12\n",
    "sagmass_unc_down=.07\n",
    "sagdist=8.15*10**(-3)\n",
    "sagdist_unc=.15*10**(-3)\n",
    "\n",
    "distanceMPc=sagdist\n",
    "distanceMPc_uncer=sagdist_unc\n",
    "\n",
    "log_BH_mass_solar=sagmass\n",
    "log_BH_mass_solar_uncerup=sagmass_unc_up\n",
    "log_BH_mass_solar_uncerdown=sagmass_unc_down\n",
    "\n",
    "mass, mass_uncup, mass_fracerrorup, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(sagmass,sagmass_unc_up,sagdist,sagdist_unc,'NA','NA')\n",
    "mass, mass_uncdown, mass_fracerrordown, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(sagmass,sagmass_unc_down,sagdist,sagdist_unc,'NA','NA')\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'SagA*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} ± {format_number(distanceMPc_uncer)} MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "log_BH_mass_solar_uncerup=format_number(float(log_BH_mass_solar_uncerup))\n",
    "log_BH_mass_solar_uncerdown=format_number(float(log_BH_mass_solar_uncerdown))\n",
    "mass_fracerror=(mass_fracerrorup+mass_fracerrordown)/2\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} $^{{+{log_BH_mass_solar_uncerup}}}_{{-{log_BH_mass_solar_uncerdown}}}$ log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles1=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "fig, ax = pylab.subplots(dpi=300)\n",
    "\n",
    "m87mass=9.81\n",
    "m87mass_unc=0.06\n",
    "m87dist=16.8\n",
    "m87dist_uncup=.8\n",
    "m87dist_uncdown=.7\n",
    "\n",
    "distanceMPc=m87dist\n",
    "distanceMPc_uncerup=m87dist_uncup\n",
    "distanceMPc_uncerdown=m87dist_uncdown\n",
    "\n",
    "log_BH_mass_solar=m87mass\n",
    "log_BH_mass_solar_uncer=m87mass_unc\n",
    "\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerup, dist_fracerrorup, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncup,'NA','NA')\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerdown, dist_fracerrordown, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncdown,'NA','NA')\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'M87*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "dist_fracerror=(distanceMPc_uncerup+distanceMPc_uncerdown)/2\n",
    "distanceMPc_uncerup=format_number(float(distanceMPc_uncerup))\n",
    "distanceMPc_uncerdown=format_number(float(distanceMPc_uncerdown))\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} $^{{+{distanceMPc_uncerup}}}_{{-{distanceMPc_uncerdown}}}$ MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} ±{log_BH_mass_solar_uncerdown} log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles2=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "legend1=ax.legend(handles=handles2, loc='upper center')   \n",
    "ax.add_artist(legend1)\n",
    "ax.legend(handles=handles1, loc='lower center')   \n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xticks([])  # Remove x-axis ticks\n",
    "ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "# Remove tick labels\n",
    "ax.set_xticklabels([])  # Remove x-axis labels\n",
    "ax.set_yticklabels([])  # Remove y-axis labels\n",
    "if not os.path.exists('Extras'):\n",
    "    os.makedirs('Extras')\n",
    "pylab.savefig(f'Extras/SMBH of SagA* and M87')\n",
    "pylab.clf() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beam Mismatch Graphs\n",
    "\n",
    "import ast\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "\n",
    "tolerance = 0.05\n",
    "\n",
    "sourcesofinterest=('4258','1194','3079','4945','Circinus','1068','2273','4388','2960','3789')\n",
    "freqrange=[200,400]\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "c=constants.c\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "txtnamesandcoords='namesandcoords.txt'\n",
    "path='Beam Mismatch'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "newrefs=[]\n",
    "for isource, data in grouped_data.items():\n",
    "    breaker=1\n",
    "    for i in sourcesofinterest:\n",
    "        if i.lower() in isource.lower():\n",
    "            breaker=0\n",
    "    if breaker==1:\n",
    "        continue\n",
    "    # Main loop to read and process sources from the input file\n",
    "    if os.path.exists(txtnamesandcoords):\n",
    "        with open(txtnamesandcoords, 'r') as infile:\n",
    "            for line in infile:\n",
    "\n",
    "                # Parse the line into a list of name-coordinate pairs\n",
    "                params = ast.literal_eval(line)\n",
    "                for inamecoords in params:                \n",
    "                    source_name = inamecoords[0][0]\n",
    "                    if not isource.lower() in source_name.lower():\n",
    "                        continue\n",
    "                    source=source_name\n",
    "                    ra = inamecoords[1][1]\n",
    "                    dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                    findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                    distanceMPc=findvals[0][0]\n",
    "                    distanceMPc_uncer=findvals[0][1]\n",
    "                    method=findvals[1]\n",
    "                    ynfindref=findvals[2]\n",
    "                    refcode=findvals[3]\n",
    "                    red_depend=findvals[4]\n",
    "                    if len(findvals[5])!=0:\n",
    "                        for i in findvals[5]:\n",
    "                            newrefs.append(i)\n",
    "    else:\n",
    "        print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "    arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "    arcsectopc=arcsectokpc*1000\n",
    "\n",
    "    arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "    arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "    arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "    distance='NA'\n",
    "    with open(Greenepath, 'r') as infile:\n",
    "        j=-1\n",
    "        breaker=1\n",
    "        for line in infile:\n",
    "            j=j+1\n",
    "            if j>20:\n",
    "                continue\n",
    "            source_name=line.split(' ')[0]\n",
    "            source_name=source_name.replace(\"−\",\"-\")\n",
    "            if \"WISEA\" in isource:\n",
    "                isource=isource.split(\"WISEA\")[0]\n",
    "            if isource.lower() in source_name.lower():\n",
    "                log_BH_mass_solar=line.split(' ')[3]\n",
    "                log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                breaker=0\n",
    "        if breaker!=1:\n",
    "            mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "\n",
    "\n",
    "\n",
    "    # Filter out elements where date == 'NA'\n",
    "    valid_sfreqs = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates']) if d != 'NA']\n",
    "    valid_sfreqs2 = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2']) if d != 'NA']\n",
    "\n",
    "    nvalid_sfreqs = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates']) if d == 'NA']\n",
    "    nvalid_sfreqs2 = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2']) if d == 'NA']\n",
    "\n",
    "    # Combine all valid data for grouping\n",
    "    combined_data = valid_sfreqs + valid_sfreqs2\n",
    "    ncombined_data = nvalid_sfreqs + nvalid_sfreqs2 \n",
    "    \n",
    "    # Unpack valid data\n",
    "    if combined_data:\n",
    "        combined_freqs, combined_fluxes, combined_beams, combined_dates = zip(*combined_data)\n",
    "    else:\n",
    "        combined_freqs, combined_fluxes, combined_beams, combined_dates = [], [], [], []\n",
    "\n",
    "    if ncombined_data:\n",
    "        ncombined_freqs, ncombined_fluxes, ncombined_beams, ncombined_dates = zip(*ncombined_data)\n",
    "    else:\n",
    "        ncombined_freqs, ncombined_fluxes, ncombined_beams, ncombined_dates = [], [], [], []\n",
    "\n",
    "    # Group the combined data dynamically for the current source\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_frequency(\n",
    "        combined_freqs, combined_fluxes, combined_beams, combined_dates, tolerance\n",
    "    )\n",
    "\n",
    "    # Group the combined data dynamically for the current source\n",
    "    ngrouped_freqs, ngrouped_fluxes, ngrouped_beams, ngrouped_dates = group_by_frequency(\n",
    "        ncombined_freqs, ncombined_fluxes, ncombined_beams, ncombined_dates, tolerance\n",
    "    )\n",
    "\n",
    "    # Iterate through frequency groups and create separate plots\n",
    "    donefreq=[]\n",
    "    for freq_group, flux_group, beam_group, date_group in zip(grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates):\n",
    "        if 10**np.min(freq_group)>freqrange[1]:\n",
    "            continue\n",
    "        if 10**np.max(freq_group)<freqrange[0]:\n",
    "            continue\n",
    "        donefreq.append(freq_group)\n",
    "        if len(date_group) > 0 and len(flux_group) > 0:  # Only plot if there are valid points\n",
    "            totbeams=[]\n",
    "            totfluxs=[]\n",
    "            totfreqs=[]\n",
    "            totdates=[]           # Separate the points by their original data group for plotting\n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            #to get maximum values\n",
    "            for valid_data in [valid_sfreqs, valid_sfreqs2 ]:\n",
    "                filtered_points = [(d, fl, b) for f, fl, b, d in valid_data if f in freq_group]\n",
    "                if filtered_points:\n",
    "                    filtered_dates, filtered_fluxes, filtered_beams = zip(*filtered_points)\n",
    "                    for i in filtered_beams:\n",
    "\n",
    "                        i = 10** i\n",
    "                        i = i * (np.pi / (180 * 3600))\n",
    "                        i = i * distanceMPc * 1000\n",
    "                        i = np.log10(i)\n",
    "                        totbeams.append(i)\n",
    "\n",
    "                    for i in filtered_fluxes:\n",
    "                        totfluxs.append(i) \n",
    "\n",
    "                    for i in filtered_dates:\n",
    "                        totdates.append(i)\n",
    "\n",
    "            maxbeamp=np.max(totbeams)\n",
    "            minbeamp=np.min(totbeams)\n",
    "\n",
    "            maxfluxp=np.max(totfluxs)\n",
    "            minfluxp=np.min(totfluxs)\n",
    "\n",
    "            maxdatep=np.max(totdates)\n",
    "            mindatep=np.min(totdates)\n",
    "\n",
    "            maxbeamp=round_up_to_half_integer(maxbeamp)\n",
    "            minbeamp=round_down_to_half_integer(minbeamp)\n",
    "\n",
    "            maxfluxp=round_up_to_half_integer(maxfluxp)\n",
    "            minfluxp=round_down_to_half_integer(minfluxp)\n",
    "\n",
    "            maxdatep=np.ceil(maxdatep)\n",
    "            mindatep=np.floor(mindatep)\n",
    "\n",
    "            #interval = maxdatep - mindatep\n",
    "            #ten_percent = interval * 0.05\n",
    "            ten_percent=0\n",
    "            mindate = mindatep - ten_percent\n",
    "            maxdate = maxdatep + ten_percent\n",
    "\n",
    "            interval = maxfluxp - minfluxp\n",
    "            ten_percent = interval * 0.05\n",
    "            minflux = minfluxp - ten_percent\n",
    "            maxflux = maxfluxp + ten_percent\n",
    "\n",
    "            interval = maxbeamp - minbeamp\n",
    "            ten_percent = interval * 0.05\n",
    "            minbeam = minbeamp - ten_percent\n",
    "            maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "            x_tick_positions = np.arange(minbeamp, maxbeamp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "            x_tick_labels =  [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "            y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "            y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "            stick_positions = np.arange(mindatep, maxdatep + 1 , 1)  # 6 evenly spaced ticks\n",
    "            stick_labels = [decimal_year_to_date(pos) for pos in stick_positions]  # Convert log to linear\n",
    "            print(stick_labels)\n",
    "\n",
    "            for label, valid_data, marker, cmap, norm in [\n",
    "                (\"Small Beams Type 1\", valid_sfreqs, 'o', cm2, matplotlib.colors.Normalize(vmin=mindate, vmax=maxdate)),\n",
    "                (\"Small Beams Type 2\", valid_sfreqs2, 'v', cm2, matplotlib.colors.Normalize(vmin=mindate, vmax=maxdate)),\n",
    "            ]:            \n",
    "                #to filter through points for graphing\n",
    "                filtered_points = [(d, fl, b) for f, fl, b, d in valid_data if f in freq_group]\n",
    "                if filtered_points:\n",
    "                    filtered_dates, filtered_fluxes, filtered_beams = zip(*filtered_points)\n",
    "                    filtered_beams = np.array(filtered_beams)\n",
    "                    filtered_beams = 10**filtered_beams\n",
    "                    filtered_beams = filtered_beams * (np.pi / (180 * 3600))\n",
    "                    filtered_beams = filtered_beams * distanceMPc * 1000\n",
    "                    filtered_beams = np.log10(filtered_beams)\n",
    "                    filtered_beams = filtered_beams.tolist()\n",
    "\n",
    "                    #filtered_fluxes=10**np.array(filtered_fluxes) * (np.pi / (180 * 3600)) * distanceMPc * 1000\n",
    "                    #filtered_fluxes=filtered_fluxes.tolist()\n",
    "\n",
    "                    scalar_map = cmx.ScalarMappable(norm=norm, cmap=cmap)\n",
    "                    colors = scalar_map.to_rgba(filtered_dates)\n",
    "                    ax.scatter(filtered_beams, filtered_fluxes, label=label, marker=marker, c=colors, s=msize)\n",
    "\n",
    "            stick2=stick_positions\n",
    "\n",
    "            if len(stick2)>0:\n",
    "                colorbar2 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=mindate, vmax=maxdate), cmap=cm2),\n",
    "                    label='Date',\n",
    "                    ax=ax,\n",
    "                    ticks=stick2\n",
    "                )\n",
    "                colorbar2.set_label(\n",
    "                    \"Date\",  # Label text\n",
    "                    #labelpad=3,  # Adjust the distance between the label and the colorbar\n",
    "                    #fontsize=10,  # Font size\n",
    "                )\n",
    "\n",
    "                colorbar2.ax.set_yticklabels(stick_labels)\n",
    "\n",
    "            minor_tick_locations_date = np.arange(mindatep, maxdatep, 1/4)\n",
    "            major_ticks = colorbar2.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations_date if tick not in major_ticks]\n",
    "            colorbar2.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "\n",
    "            ax = pylab.gca()\n",
    "\n",
    "            ax.set_xlim([minbeam, maxbeam])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            x_minor_locator = MultipleLocator(0.1)\n",
    "            y_minor_locator = MultipleLocator(0.1)\n",
    "            ax.yaxis.set_minor_locator(x_minor_locator)\n",
    "            ax.xaxis.set_minor_locator(y_minor_locator)\n",
    "\n",
    "\n",
    "            # Configure the plot\n",
    "            ax.set_xlabel(r\"log$_{10}$ Resolution [kPc]\")\n",
    "            ax.set_ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')  # Linear y-axis label\n",
    "            #ax.set_title(f'{source}: {10**np.mean(freq_group):.0f}GHz\\n1\" on POS: {format_number(arcsectopc)} Pc\\nµ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)}')\n",
    "            if f'{10**np.min(freq_group):.0f}'==f'{10**np.max(freq_group):.0f}':\n",
    "                ax.set_title(f'{source}: {10**np.min(freq_group):.0f}GHz')\n",
    "            else:\n",
    "                ax.set_title(f'{source}: {10**np.min(freq_group):.0f}-{10**np.max(freq_group):.0f}GHz')\n",
    "\n",
    "            nicename=f'{source} {round(10**np.mean(np.mean(freq_group)))}GHz.pdf'\n",
    "            if not os.path.exists(f'Beam Mismatch'):\n",
    "                os.makedirs(f'Beam Mismatch')\n",
    "            if os.path.exists(f'Beam Mismatch/{nicename}'):\n",
    "                os.remove(f'Beam Mismatch/{nicename}')\n",
    "\n",
    "\n",
    "        # For points with no date\n",
    "        for nfreq_group, nflux_group, nbeam_group, ndate_group in zip(ngrouped_freqs, ngrouped_fluxes, ngrouped_beams, ngrouped_dates):\n",
    "            if nfreq_group==freq_group:\n",
    "                if len(ndate_group) > 0 and len(nflux_group) > 0:  # Only plot if there are valid points\n",
    "                    for valid_data in [nvalid_sfreqs, nvalid_sfreqs2 ]:\n",
    "                        filtered_points = [(d, fl, b) for f, fl, b, d in valid_data if f in nfreq_group]\n",
    "                        if filtered_points:\n",
    "                            filtered_dates, filtered_fluxes, filtered_beams = zip(*filtered_points)\n",
    "                            filtered_beams = np.array(filtered_beams)\n",
    "                            filtered_beams = 10**filtered_beams\n",
    "                            filtered_beams = filtered_beams * (np.pi / (180 * 3600))\n",
    "                            filtered_beams = filtered_beams * distanceMPc * 1000\n",
    "                            filtered_beams = np.log10(filtered_beams)\n",
    "                            filtered_beams = filtered_beams.tolist()\n",
    "                            ax.scatter(filtered_beams, filtered_fluxes, label=label, marker=marker, s=msize, facecolor='white', edgecolors='black')\n",
    "\n",
    "                            for i in filtered_beams:\n",
    "                                i = 10** i\n",
    "                                i = i * (np.pi / (180 * 3600))\n",
    "                                i = i * distanceMPc * 1000\n",
    "                                i = np.log10(i)\n",
    "                                totbeams.append(i)\n",
    "\n",
    "                            for i in filtered_fluxes:\n",
    "                                totfluxs.append(np.log10(i))     \n",
    "\n",
    "                            for i in filtered_dates:\n",
    "                                totdates.append(i)\n",
    "\n",
    "                    nmaxbeamp=np.max(totbeams)\n",
    "                    nminbeamp=np.min(totbeams)\n",
    "\n",
    "                    nmaxfluxp=np.max(totfluxs)\n",
    "                    nminfluxp=np.min(totfluxs)\n",
    "\n",
    "                    if nmaxbeamp>maxbeamp:\n",
    "                        maxbeamp=nmaxbeamp\n",
    "                        maxbeamp=round_up_to_half_integer(maxbeamp)\n",
    "\n",
    "                    if nminbeamp<minbeamp:\n",
    "                        minbeamp=nminbeamp\n",
    "                        minbeamp=round_down_to_half_integer(minbeamp)\n",
    "\n",
    "                    if nmaxfluxp>maxfluxp:\n",
    "                        maxfluxp=nmaxfluxp\n",
    "                        maxfluxp=round_up_to_half_integer(maxfluxp)\n",
    "\n",
    "                    if nminfluxp<minfluxp:\n",
    "                        minfluxp=nminfluxp\n",
    "                        minfluxp=round_down_to_half_integer(minfluxp)\n",
    "\n",
    "                    if nmaxbeamp>maxbeamp or nminbeamp<minbeamp:\n",
    "                        interval = maxbeamp - minbeamp\n",
    "                        ten_percent = interval * 0.05\n",
    "                        minbeam = minbeamp - ten_percent\n",
    "                        maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "                        x_tick_positions = np.arange(minbeam, maxbeam + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "                        x_tick_labels =  [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "                        ax.set_xlim([minbeam, maxbeam])\n",
    "                        ax.set_xticks(x_tick_positions)\n",
    "                        ax.set_xticklabels(x_tick_labels)\n",
    "                        ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "                    if nminfluxp<minfluxp or nmaxfluxp>maxfluxp:\n",
    "\n",
    "                        interval = maxfluxp - minfluxp\n",
    "                        ten_percent = interval * 0.05\n",
    "                        minflux = minfluxp - ten_percent\n",
    "                        maxflux = maxfluxp + ten_percent\n",
    "\n",
    "                        y_tick_positions = np.arange(minflux, maxflux + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "                        y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "                        ax.set_ylim([minflux, maxflux]) \n",
    "                        ax.set_yticks(y_tick_positions)\n",
    "                        ax.set_yticklabels(y_tick_labels)\n",
    "                        ax.yaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "        pylab.savefig(f'Beam Mismatch/{nicename}', bbox_inches='tight', dpi=300)\n",
    "        pylab.show()\n",
    "        pylab.clf() \n",
    "\n",
    "    #for if there is only points that have no date\n",
    "    for nfreq_group, nflux_group, nbeam_group, ndate_group in zip(ngrouped_freqs, ngrouped_fluxes, ngrouped_beams, ngrouped_dates):\n",
    "        onlynone=1\n",
    "\n",
    "        if 10**np.min(nfreq_group)>freqrange[1]:\n",
    "            continue\n",
    "        if 10**np.max(nfreq_group)<freqrange[0]:\n",
    "            continue\n",
    "        for idone in donefreq:\n",
    "            if idone==nfreq_group:\n",
    "                onlynone=0\n",
    "        if onlynone==1:\n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            for valid_data, marker in [(nvalid_sfreqs, 'o'), (nvalid_sfreqs2, 'v') ]:\n",
    "                filtered_points = [(d, fl, b) for f, fl, b, d in valid_data if f in nfreq_group]\n",
    "                if filtered_points:\n",
    "                    filtered_dates, filtered_fluxes, filtered_beams = zip(*filtered_points)\n",
    "                    filtered_beams = np.array(filtered_beams)\n",
    "                    filtered_beams = 10 ** filtered_beams * (np.pi / (180 * 3600))\n",
    "                    filtered_beams = filtered_beams * distanceMPc * 1000\n",
    "                    filtered_beams = np.log10(filtered_beams)\n",
    "                    filtered_beams = filtered_beams.tolist()\n",
    "\n",
    "                    maxbeamp=round_up_to_half_integer(filtered_beams[0])\n",
    "                    minbeamp=round_down_to_half_integer(filtered_beams[0])\n",
    "\n",
    "                    maxfluxp=round_up_to_half_integer(filtered_fluxes[0])\n",
    "                    minfluxp=round_down_to_half_integer(filtered_fluxes[0])\n",
    "\n",
    "                    interval = maxfluxp - minfluxp\n",
    "                    ten_percent = interval * 0.05\n",
    "                    minflux = minfluxp - ten_percent\n",
    "                    maxflux = maxfluxp + ten_percent\n",
    "\n",
    "                    interval = maxbeamp - minbeamp\n",
    "                    ten_percent = interval * 0.05\n",
    "                    minbeam = minbeamp - ten_percent\n",
    "                    maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "                    x_tick_positions = np.arange(minbeamp, maxbeamp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "                    x_tick_labels =  [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "                    y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "                    y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "                    ax.set_xlim([minbeam, maxbeam])\n",
    "                    ax.set_xticks(x_tick_positions)\n",
    "                    ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "                    ax.set_ylim([minflux, maxflux]) \n",
    "                    ax.set_yticks(y_tick_positions)\n",
    "                    ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "                    x_minor_locator = MultipleLocator(0.1)\n",
    "                    y_minor_locator = MultipleLocator(0.1)\n",
    "                    ax.yaxis.set_minor_locator(x_minor_locator)\n",
    "                    ax.xaxis.set_minor_locator(y_minor_locator)\n",
    "\n",
    "                    ax.scatter(filtered_beams, filtered_fluxes, label=label, marker=marker, s=msize, facecolor='white', edgecolors='black')\n",
    "            \n",
    "            if f'{10**np.min(nfreq_group):.0f}'==f'{10**np.max(nfreq_group):.0f}':\n",
    "                ax.set_title(f'{source}: {10**np.min(nfreq_group):.0f}GHz')\n",
    "            else:\n",
    "                ax.set_title(f'{source}: {10**np.min(nfreq_group):.0f}-{10**np.max(nfreq_group):.0f}GHz')\n",
    "            ax.set_xlabel(\"Resolution [kPc]\")\n",
    "            ax.set_ylabel(r'Flux [mJy][Beam]$^{-1}$')\n",
    "\n",
    "            nicename=f'{source} {round(10**np.mean(np.mean(nfreq_group)))}GHz.pdf'\n",
    "            if not os.path.exists(f'Beam Mismatch/'):\n",
    "                os.makedirs(f'Beam Mismatch/')\n",
    "            if os.path.exists(f'Beam Mismatch/{nicename}'):\n",
    "                os.remove(f'Beam Mismatch/{nicename}')\n",
    "\n",
    "            pylab.savefig(f'Beam Mismatch/{nicename}', bbox_inches='tight', dpi=300)\n",
    "            pylab.show()\n",
    "            pylab.clf() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spectral Plots\n",
    "\n",
    "insetter=True\n",
    "msize=10\n",
    "\n",
    "path = f'SpectraGraphs'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "freqs=[]\n",
    "fluxs=[]\n",
    "beams=[]\n",
    "\n",
    "findwithprocessor=0\n",
    "\n",
    "#redshifts\n",
    "noprocessor=[\n",
    "    ['4258' , 0.0306 , 0.0012],\n",
    "    ['1194' , 0.268 , 0.011],\n",
    "    ['1068' , 0.0746 , 0.0030],\n",
    "    ['5765' , 0.546 , 0.022],\n",
    "    ['2273' , 0.121 , 0.005],\n",
    "    ['3393' , 0.251 , 0.010],\n",
    "    ['Circinus' , 0.02040 , 0.00002],\n",
    "    ['074-064' , 0.454 , 0.018],\n",
    "    ['6264' , 0.668 , 0.027],\n",
    "    ['3789' , 0.214 , 0.009],\n",
    "    ['4388' , 0.166 , 0.007],\n",
    "    ['4945' , 0.0369, 0.0015],\n",
    "    ['6093' , 0.709 , 0.029],\n",
    "    ['3079' , 0.0726 , 0.0029],\n",
    "    ['2960' , 0.325 , 0.013],\n",
    "    ['558' , 0.500 , 0.020],\n",
    "    ['1320' , 0.183 , 0.007],\n",
    "    ['2560' , 0.192 , 0.008],\n",
    "    ['6323' , 0.514 , 0.008],\n",
    "    ['0437' , 0.316 , 0.013],\n",
    "    ['1029' , 0.595 , 0.024]\n",
    "]\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    jfin=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        jfin=jfin+1 \n",
    "\n",
    "grouped_data = {}\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    for line in infile:\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        \n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in source.lower():\n",
    "                breaker=0\n",
    "        if breaker==1:\n",
    "            continue\n",
    "        j=j+1\n",
    "        \n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            beams=line[5].split('-')\n",
    "            beamavg=(float(beams[0])+float(beams[1]))/2\n",
    "            beam=np.log10(beamavg)\n",
    "\n",
    "\n",
    "        if source not in grouped_data:\n",
    "            grouped_data[source] = {\n",
    "                'sfreqs': [], 'sfluxs': [], 'sbeams': [], 'sdates': [],\n",
    "                'sfreqs2': [], 'sfluxs2': [], 'sbeams2': [], 'sdates2': [],\n",
    "            }\n",
    "\n",
    "        if j==0:\n",
    "            minfreq=freq\n",
    "            maxfreq=freq\n",
    "            minflux=flux\n",
    "            maxflux=flux\n",
    "            minbeam=beam\n",
    "            maxbeam=beam\n",
    "        if j!=0:\n",
    "            if freq>maxfreq:\n",
    "                maxfreq=freq\n",
    "            if freq<minfreq:\n",
    "                minfreq=freq\n",
    "            if flux>maxflux:\n",
    "                maxflux=flux\n",
    "            if flux<minflux:\n",
    "                minflux=flux\n",
    "            if beam>maxbeam:\n",
    "                maxbeam=beam\n",
    "            if beam<minbeam:\n",
    "                minbeam=beam\n",
    "\n",
    "minfreqp=round_down_to_half_integer(minfreq)\n",
    "maxfreqp=round_up_to_half_integer(maxfreq)\n",
    "\n",
    "minfluxp=round_down_to_half_integer(minflux)\n",
    "maxfluxp=round_up_to_half_integer(maxflux)\n",
    "\n",
    "minbeamp=round_down_to_half_integer(minbeam)\n",
    "maxbeamp=round_up_to_half_integer(maxbeam)\n",
    "\n",
    "interval = maxfreqp - minfreqp\n",
    "ten_percent = interval * 0.05\n",
    "minfreq = minfreqp - ten_percent\n",
    "maxfreq = maxfreqp + ten_percent\n",
    "\n",
    "interval = maxfluxp - minfluxp\n",
    "ten_percent = interval * 0.05\n",
    "minflux = minfluxp - ten_percent\n",
    "maxflux = maxfluxp + ten_percent\n",
    "\n",
    "interval = maxbeamp - minbeamp\n",
    "ten_percent = interval * 0.05\n",
    "minbeam = minbeamp - ten_percent\n",
    "maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "x_tick_positions=np.arange(minfreqp, maxfreqp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5, 0.5)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "stick_positions = np.arange(minbeamp, maxbeamp + 1, 1)  # 6 evenly spaced ticks\n",
    "stick_labels = [f\"{pos:.2f}\" for pos in stick_positions]  # Convert log to linear\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "\n",
    "sourcedone=[]\n",
    "sources=[]\n",
    "\n",
    "oldsources=[]\n",
    "oldsource='NA'\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    j2=-1\n",
    "    for line in infile:\n",
    "        j2=j2+1 \n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        line=eval(line)\n",
    "\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in source.lower() or source.lower() in i:\n",
    "                breaker=0\n",
    "        if breaker==1:\n",
    "            continue\n",
    "        j=j+1\n",
    "\n",
    "        if j==0:\n",
    "            sbeamsizes=[]\n",
    "            sdates=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sbeamsizes2=[]\n",
    "            sdates2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "\n",
    "            \n",
    "        breaker=0\n",
    "\n",
    "        sources.append(source)\n",
    "        sources=list(set(sources))\n",
    "\n",
    "\n",
    "        if len(sources)-len(oldsources)!=0 and j!=0:\n",
    "            source=oldsource\n",
    "\n",
    "            for isource in sourcedone:\n",
    "                if source==isource:\n",
    "                    breaker=1\n",
    "            if breaker==1:\n",
    "                continue\n",
    "            sourcedone.append(source)\n",
    "\n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            pylab.grid(True)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeamp, vmax=maxbeamp), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            if os.path.exists(txtnamesandcoords):\n",
    "                with open(txtnamesandcoords, 'r') as infile:\n",
    "                    for line2 in infile:\n",
    "\n",
    "                        # Parse the line into a list of name-coordinate pairs\n",
    "                        params = ast.literal_eval(line2)\n",
    "                        for inamecoords in params:                \n",
    "                            source_name = inamecoords[0][0]\n",
    "                            if not source.lower() in source_name.lower():\n",
    "                                continue\n",
    "                            ra = inamecoords[1][1]\n",
    "                            dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                            if findwithprocessor==1:\n",
    "                                findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                                distanceMPc=findvals[0][0]\n",
    "                                distanceMPc_uncer=findvals[0][1]\n",
    "\n",
    "                                arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "                                arcsectopc=arcsectokpc*1000\n",
    "\n",
    "                                arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "                                arcsectopc_unc=arcsectokpc_error*1000\n",
    "                            else:\n",
    "                                finder=0\n",
    "                                for findsource,dist,distunc in noprocessor:\n",
    "                                    if findsource.lower() in source.lower():\n",
    "                                        arcsectokpc=dist\n",
    "                                        arcsectokpc_error=distunc\n",
    "                                        finder=1\n",
    "                                if finder==0:\n",
    "                                    input(f\"ERROR for {isource} not found in noprocessor list\")\n",
    "\n",
    "            else:\n",
    "                print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "            if insetter==True:\n",
    "                if arcsectokpc_error!='NA': \n",
    "                    if 'circinus' in source.lower():\n",
    "                        pylab.text(maxfreqp, maxfluxp, f'Arcsecond to Kiloparsec Scale Conversion: {arcsectokpc:.5f} ± {arcsectokpc_error:.5f}', style='italic', bbox={'facecolor': 'grey', 'alpha': 0.2}, horizontalalignment='right', verticalalignment='top', fontsize=7.5)\n",
    "                    else:\n",
    "                        pylab.text(maxfreqp, maxfluxp, f'Arcsecond to Kiloparsec Scale Conversion: {arcsectokpc} ± {arcsectokpc_error}', style='italic', bbox={'facecolor': 'grey', 'alpha': 0.2}, horizontalalignment='right', verticalalignment='top', fontsize=7.5)\n",
    "                else:  \n",
    "                    pylab.text(maxfreqp, maxfluxp, f'Arcsecond to Kiloparsec Scale Conversion: {arcsectokpc}', style='italic', bbox={'facecolor': 'grey', 'alpha': 0.2}, horizontalalignment='right', verticalalignment='top', fontsize=7.5)\n",
    "\n",
    "\n",
    "\n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source} Spectra')\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs'):\n",
    "                os.makedirs(f'SpectraGraphs')\n",
    "            if os.path.exists(f'SpectraGraphs/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{nicename}')\n",
    "            pylab.savefig(f'SpectraGraphs/{nicename}', dpi=300)\n",
    "            pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "            sbeamsizes=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sdates=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "            sdates2=[]\n",
    "\n",
    "\n",
    "        flux_upperb=0\n",
    "        if len(str(line[3]).split('*'))>1:\n",
    "            flux_upperb=1\n",
    "\n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        odate=line[4]\n",
    "        if odate!='NA':\n",
    "            odate=odate.split('/')\n",
    "            date=float(odate[0]) + float(odate[1]) / 12 + float(odate[2]) / 365\n",
    "        else:\n",
    "            date='NA'\n",
    "\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            beams=line[5].split('-')\n",
    "            beamavg=(float(beams[0])+float(beams[1]))/2\n",
    "            beam=np.log10(beamavg)\n",
    "\n",
    "\n",
    "\n",
    "        if flux_upperb==0:\n",
    "            sbeamsizes.append(beam)\n",
    "            sfluxs.append(flux)\n",
    "            sfreqs.append(freq)\n",
    "            sdates.append(date)\n",
    "\n",
    "        if flux_upperb==1:\n",
    "            sbeamsizes2.append(beam)\n",
    "            sfluxs2.append(flux)\n",
    "            sfreqs2.append(freq)\n",
    "            sdates2.append(date)\n",
    "\n",
    "        oldsources=copy.deepcopy(sources)\n",
    "        oldsource=source\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
