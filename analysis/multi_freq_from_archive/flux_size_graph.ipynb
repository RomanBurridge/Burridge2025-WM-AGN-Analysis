{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Here for Making Flux Size Graphs\n",
    "#format beamsize number\n",
    "import os\n",
    "os.chdir('/home/peacesea/Burridge2025_WM_AGN/Public/analysis/multi_freq_from_archive')\n",
    "def format_number(number):\n",
    "        # Case 1: If the number is less than 1 (e.g., 0.004567)\n",
    "        if number < 0:\n",
    "                # Format the positive part of the number and prepend the negative sign\n",
    "                return \"-\" + format_number(abs(number))\n",
    "        if number < 1:\n",
    "                # Convert the number to a string with high precision\n",
    "                num_str = f\"{number:.16g}\"\n",
    "\n",
    "                # Identify the leading zeros and decimal point\n",
    "                leading_part = []\n",
    "                for char in num_str:\n",
    "                        if char == '0' or char == '.':\n",
    "                                leading_part.append(char)\n",
    "                        else:\n",
    "                                break\n",
    "\n",
    "                # Remove leading zeros and the decimal point for significant digits\n",
    "                significant_digits = \"\".join(char for char in num_str if char.isdigit() and char != \"0\")\n",
    "\n",
    "                # Extract the first two non-zero digits\n",
    "                if len(significant_digits) >= 2:\n",
    "                        first_two = significant_digits[:2]\n",
    "                elif len(significant_digits) == 1:\n",
    "                        first_two = significant_digits + \"0\"  # Pad with zero if only one significant digit exists\n",
    "                else:\n",
    "                        first_two = \"00\"  # Handle edge case like 0\n",
    "\n",
    "                # Combine the leading zeros and the first two non-zero digits\n",
    "                return \"\".join(leading_part) + first_two\n",
    "\n",
    "        # Case 2: If the number is greater than or equal to 1\n",
    "        else:\n",
    "                # Format to two decimal places\n",
    "                return f\"{number:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spectral Plots\n",
    "import matplotlib.pyplot as pylab\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import matplotlib.cm as cmx\n",
    "import math\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import copy\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "msize=10\n",
    "\n",
    "path = f'SpectraGraphs'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "freqs=[]\n",
    "fluxs=[]\n",
    "beams=[]\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    jfin=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        jfin=jfin+1 \n",
    "\n",
    "grouped_data = {}\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    for line in infile:\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        \n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "        j=j+1\n",
    "        \n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "        if source not in grouped_data:\n",
    "            grouped_data[source] = {\n",
    "                'sfreqs': [], 'sfluxs': [], 'sbeams': [], 'sdates': [],\n",
    "                'sfreqs2': [], 'sfluxs2': [], 'sbeams2': [], 'sdates2': [],\n",
    "            }\n",
    "\n",
    "        if j==0:\n",
    "            minfreq=freq\n",
    "            maxfreq=freq\n",
    "            minflux=flux\n",
    "            maxflux=flux\n",
    "            minbeam=beam\n",
    "            maxbeam=beam\n",
    "        if j!=0:\n",
    "            if freq>maxfreq:\n",
    "                maxfreq=freq\n",
    "            if freq<minfreq:\n",
    "                minfreq=freq\n",
    "            if flux>maxflux:\n",
    "                maxflux=flux\n",
    "            if flux<minflux:\n",
    "                minflux=flux\n",
    "            if beam>maxbeam:\n",
    "                maxbeam=beam\n",
    "            if beam<minbeam:\n",
    "                minbeam=beam\n",
    "\n",
    "minfreqp=round_down_to_half_integer(minfreq)\n",
    "maxfreqp=round_up_to_half_integer(maxfreq)\n",
    "\n",
    "minfluxp=round_down_to_half_integer(minflux)\n",
    "maxfluxp=round_up_to_half_integer(maxflux)\n",
    "\n",
    "minbeamp=round_down_to_half_integer(minbeam)\n",
    "maxbeamp=round_up_to_half_integer(maxbeam)\n",
    "\n",
    "interval = maxfreqp - minfreqp\n",
    "ten_percent = interval * 0.05\n",
    "minfreq = minfreqp - ten_percent\n",
    "maxfreq = maxfreqp + ten_percent\n",
    "\n",
    "interval = maxfluxp - minfluxp\n",
    "ten_percent = interval * 0.05\n",
    "minflux = minfluxp - ten_percent\n",
    "maxflux = maxfluxp + ten_percent\n",
    "\n",
    "interval = maxbeamp - minbeamp\n",
    "ten_percent = interval * 0.05\n",
    "minbeam = minbeamp - ten_percent\n",
    "maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "\n",
    "x_tick_positions=np.arange(minfreqp, maxfreqp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5, 0.5)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "stick_positions = np.arange(minbeamp, maxbeamp + 1, 1)  # 6 evenly spaced ticks\n",
    "stick_labels = [f\"{pos:.2f}\" for pos in stick_positions]  # Convert log to linear\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "\n",
    "sourcedone=[]\n",
    "sources=[]\n",
    "\n",
    "oldsources=[]\n",
    "oldsource='NA'\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    j2=-1\n",
    "    for line in infile:\n",
    "        j2=j2+1 \n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        line=eval(line)\n",
    "\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "        j=j+1\n",
    "\n",
    "        if j==0:\n",
    "            sbeamsizes=[]\n",
    "            sdates=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sbeamsizes2=[]\n",
    "            sdates2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "\n",
    "            \n",
    "        breaker=0\n",
    "\n",
    "        sources.append(source)\n",
    "        sources=list(set(sources))\n",
    "\n",
    "        if len(sources)-len(oldsources)!=0 and j!=0:\n",
    "            source=oldsource\n",
    "\n",
    "            for isource in sourcedone:\n",
    "                if source==isource:\n",
    "                    breaker=1\n",
    "            if breaker==1:\n",
    "                continue\n",
    "            sourcedone.append(source)\n",
    "\n",
    "            fig, ax = pylab.subplots()\n",
    "            cm2 = pylab.get_cmap('jet')   \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source}',fontsize=20)\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "                os.makedirs(f'SpectraGraphs/{source}')\n",
    "            if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.savefig(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "            sbeamsizes=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sdates=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "            sdates2=[]\n",
    "\n",
    "        if j2==jfin-1:\n",
    "            if line=='\\n':\n",
    "                continue\n",
    " \n",
    "            fig, ax = pylab.subplots()\n",
    "            cm2 = pylab.get_cmap('jet')   \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source}',fontsize=20)\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "                os.makedirs(f'SpectraGraphs/{source}')\n",
    "            if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.savefig(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "        oldsource=source\n",
    "\n",
    "        flux_upperb=0\n",
    "        if len(str(line[3]).split('*'))>1:\n",
    "            flux_upperb=1\n",
    "\n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        odate=line[4]\n",
    "        if odate!='NA':\n",
    "            odate=odate.split('/')\n",
    "            date=float(odate[0]) + float(odate[1]) / 12 + float(odate[2]) / 365\n",
    "        else:\n",
    "            date='NA'\n",
    "            \n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if flux_upperb==0:\n",
    "            sbeamsizes.append(beam)\n",
    "            sfluxs.append(flux)\n",
    "            sfreqs.append(freq)\n",
    "            sdates.append(date)\n",
    "\n",
    "        if flux_upperb==1:\n",
    "            sbeamsizes2.append(beam)\n",
    "            sfluxs2.append(flux)\n",
    "            sfreqs2.append(freq)\n",
    "            sdates2.append(date)\n",
    "\n",
    "        oldsources=copy.deepcopy(sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functino to Group frequencies dynamically\n",
    "def group_by_frequency(freqs, fluxes, beams, dates, tolerance):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    current_group_freqs, current_group_fluxes, current_group_beams, current_group_dates = [], [], [], []\n",
    "\n",
    "    sorted_data = sorted(zip(freqs, fluxes, beams, dates), key=lambda x: x[0])\n",
    "    for freq, flux, beam, date in sorted_data:\n",
    "        if not current_group_freqs or abs(freq - current_group_freqs[0]) <= tolerance:\n",
    "            current_group_freqs.append(freq)\n",
    "            current_group_fluxes.append(flux)\n",
    "            current_group_beams.append(beam)\n",
    "            current_group_dates.append(date)\n",
    "        else:\n",
    "            grouped_freqs.append(current_group_freqs)\n",
    "            grouped_fluxes.append(current_group_fluxes)\n",
    "            grouped_beams.append(current_group_beams)\n",
    "            grouped_dates.append(current_group_dates)\n",
    "            current_group_freqs = [freq]\n",
    "            current_group_fluxes = [flux]\n",
    "            current_group_beams = [beam]\n",
    "            current_group_dates = [date]\n",
    "\n",
    "    if current_group_freqs:\n",
    "        grouped_freqs.append(current_group_freqs)\n",
    "        grouped_fluxes.append(current_group_fluxes)\n",
    "        grouped_beams.append(current_group_beams)\n",
    "        grouped_dates.append(current_group_dates)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define frequency ranges for VLA and ALMA bands\n",
    "vla_bands = [\n",
    "    (0.0,0.054) ,     #for Rounding \n",
    "    (0.054, 0.086),  # 4 Band\n",
    "    (0.230, 0.470),  # P Band\n",
    "    (1, 2),          # L Band\n",
    "    (2, 4),          # S Band\n",
    "    (4, 8),          # C Band\n",
    "    (8, 12),         # X Band\n",
    "    (12, 18),        # Ku Band\n",
    "    (18, 26.5),      # K Band\n",
    "    (26.5, 40),      # Ka Band\n",
    "    (40, 50),        # Q Band\n",
    "]\n",
    "\n",
    "alma_bands = [\n",
    "    (31.3, 45),   # Band 1\n",
    "    (67, 90),     # Band 2\n",
    "    (84, 116),    # Band 3\n",
    "    (125, 163),   # Band 4\n",
    "    (163, 211),   # Band 5\n",
    "    (211, 275),   # Band 6\n",
    "    (275, 373),   # Band 7\n",
    "    (385, 500),   # Band 8\n",
    "    (602, 720),   # Band 9\n",
    "    (787, 950),   # Band 10\n",
    "]\n",
    "\n",
    "# Combine all boundaries and create continuous intervals\n",
    "all_boundaries = sorted(set([freq for band in vla_bands + alma_bands for freq in band]))\n",
    "non_overlapping_intervals = [(all_boundaries[i], all_boundaries[i + 1]) for i in range(len(all_boundaries) - 1)]\n",
    "\n",
    "# Remove gaps by ensuring no holes\n",
    "continuous_intervals = []\n",
    "for i, (start, end) in enumerate(non_overlapping_intervals):\n",
    "    if i > 0 and start > continuous_intervals[-1][1]:\n",
    "        # Fill the gap between the previous interval and the current one\n",
    "        continuous_intervals.append((continuous_intervals[-1][1], start))\n",
    "    continuous_intervals.append((start, end))\n",
    "\n",
    "# Function to check if a frequency is in any interval\n",
    "def is_frequency_in_intervals(frequency, intervals):\n",
    "    for start, end in intervals:\n",
    "        if start <= frequency < end:  # Check if frequency is in the interval\n",
    "            return True, (start, end)\n",
    "    return False, None\n",
    "\n",
    "# Print all intervals for verification\n",
    "print(\"\\nAll continuous intervals:\")\n",
    "for i, interval in enumerate(continuous_intervals):\n",
    "    print(f\"Interval {i + 1}: {interval[0]}–{interval[1]} GHz\")\n",
    "\n",
    "def group_by_band(freqs, fluxes, beams, dates, intervals):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    interval_mapping = {interval: ([], [], [], []) for interval in intervals}\n",
    "\n",
    "    for freq, flux, beam, date in zip(freqs, fluxes, beams, dates):\n",
    "        found, assigned_interval = is_frequency_in_intervals(freq, intervals)\n",
    "        if found:\n",
    "            interval_mapping[assigned_interval][0].append(freq)\n",
    "            interval_mapping[assigned_interval][1].append(flux)\n",
    "            interval_mapping[assigned_interval][2].append(beam)\n",
    "            interval_mapping[assigned_interval][3].append(date)\n",
    "\n",
    "    for interval, (freq_list, flux_list, beam_list, date_list) in interval_mapping.items():\n",
    "        if freq_list:\n",
    "            grouped_freqs.append(freq_list)\n",
    "            grouped_fluxes.append(flux_list)\n",
    "            grouped_beams.append(beam_list)\n",
    "            grouped_dates.append(date_list)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Statistical Spectral Plots\n",
    "# Define tolerance for grouping frequencies (log space)\n",
    "tolerance = .05\n",
    "\n",
    "#define if it should be grouped dynamicall or by band\n",
    "grouper='byband'\n",
    "#grouper='bydynam'\n",
    "\n",
    "# Generate consistent x-axis and y-axis tick positions\n",
    "x_tick_positions = np.linspace(minfreq, maxfreq, num=6)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{10**pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.linspace(minflux, maxflux, num=6)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{10**pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "# Apply grouping to all sources\n",
    "for source, data in grouped_data.items():\n",
    "    if grouper=='bydynam':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_frequency(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'],data['sdates'],tolerance\n",
    "        )\n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_frequency(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'],tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_band(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'], continuous_intervals\n",
    "        )\n",
    "        \n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_band(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'], continuous_intervals\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize combined arrays\n",
    "combined_freqs = []  # Combined frequencies\n",
    "combined_fluxes = []  # Combined fluxes\n",
    "combined_beams = []  # Combined beam sizes\n",
    "\n",
    "for source, data in grouped_data.items():\n",
    "    # Combine all frequency, flux, and beam data for the current source\n",
    "    combined_freqs = data['sfreqs'] \n",
    "    combined_fluxes = data['sfluxs'] \n",
    "    combined_beams = data['sbeams'] \n",
    "    combined_dates = data['sdates'] \n",
    "\n",
    "    combined_freqs_2 = data['sfreqs2']\n",
    "    combined_fluxes_2 = data['sfluxs2'] \n",
    "    combined_beams_2 = data['sbeams2'] \n",
    "    combined_dates_2 = data['sdates2'] \n",
    "\n",
    "    # Group the combined data dynamically for the current source\n",
    "    if grouper=='bydynam':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_frequency(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_band(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, continuous_intervals\n",
    "        )\n",
    "\n",
    "    # Iterate over grouped combined data\n",
    "    for freq_group, flux_group, beam_group in zip(grouped_freqs, grouped_fluxes, grouped_beams):\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        if group_size >= 4:\n",
    "            pylab.boxplot(flux_group, positions=[central_freq],widths=0.1,\n",
    "            showfliers=False)  # Customize outliers\n",
    "        elif group_size == 3:\n",
    "            # Vertical line with caps at min and max\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = np.median(flux_group)\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5,  # Length of caps\n",
    "                color='k'\n",
    "            )\n",
    "            # Add a horizontal line at the median_flux\n",
    "            pylab.hlines(\n",
    "                y=median_flux,  # Position of the horizontal line\n",
    "                xmin=central_freq - 0.05,  # Adjust as needed for length\n",
    "                xmax=central_freq + 0.05, \n",
    "                color='r',  # Color of the line\n",
    "                linewidth=1  # Thickness of the horizontal line\n",
    "            )\n",
    "        elif group_size == 2:\n",
    "            # Vertical line with caps at min and max (no median)\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = (min_flux + max_flux) / 2  # Just for centering the line\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5, \n",
    "                color='k'\n",
    "            )\n",
    "\n",
    "        elif group_size == 1:\n",
    "            pylab.scatter([central_freq], [flux_group[0]], c='b', marker='o', s=10)\n",
    "\n",
    "    if combined_fluxes_2:  # Ensure '2' fluxes exist\n",
    "        if not combined_fluxes or min(combined_fluxes_2) < min(combined_fluxes):\n",
    "            # If main fluxes are empty OR '2' minimum is lower\n",
    "            min_flux_2 = min(combined_fluxes_2)\n",
    "            min_flux_2_index = combined_fluxes_2.index(min_flux_2)\n",
    "            min_freq_2 = combined_freqs_2[min_flux_2_index]\n",
    "            # Mark the lowest value with a downward triangle\n",
    "            pylab.scatter([min_freq_2], [min_flux_2], c='black', marker='v', s=7, label='Min Flux from 2')\n",
    "\n",
    "\n",
    "    # Set consistent x and y limits for all plots\n",
    "    pylab.xlim(minfreq - 0.1, maxfreq + 0.1)  # Add slight padding\n",
    "    pylab.ylim(minflux - 0.1, maxflux + 0.1)  # Add slight padding\n",
    "    # Set consistent x-axis ticks and labels\n",
    "    # Set consistent x-axis and y-axis ticks and labels\n",
    "    pylab.xticks(x_tick_positions, x_tick_labels)\n",
    "    pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "\n",
    "    # Add labels and title\n",
    "    pylab.xlabel('Frequency [GHz]')\n",
    "    pylab.ylabel(r'Flux [mJy][Beam]$^{-1}$')\n",
    "    pylab.title(f'{source}')\n",
    "\n",
    "    nicename=f'{source} statistical spectra.pdf'\n",
    "    if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "        os.makedirs(f'SpectraGraphs/{source}')\n",
    "    if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "        os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "    #pylab.savefig(f'SpectraGraphs/{source}/{nicename}')\n",
    "    #pylab.show()\n",
    "    pylab.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW make function to get distances\n",
    "def process_sourcenew(source_name):\n",
    "    found=0\n",
    "    for idist in totdist:\n",
    "        if idist[0].lower() in source_name.lower():\n",
    "            dist=idist[1]\n",
    "            dist_uncer=idist[2]\n",
    "            found=found+1\n",
    "    if found!=1:\n",
    "        print(found)\n",
    "        input(f'error with finding distance for {source_name}')\n",
    "    #return in MPc\n",
    "    return([dist,dist_uncer])\n",
    "\n",
    "#distances for Pesce, 2018 ordered to Burridge, 2025\n",
    "import numpy as np\n",
    "\n",
    "totdist=[]\n",
    "\n",
    "hubble=73.9\n",
    "hubbleerr=3.0\n",
    "\n",
    "val=466.87\n",
    "valerr=0.49\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC4258\",dist,disterr])\n",
    "print(f\"NGC 4258: {dist:.2f} ± {disterr:.2f}\")\n",
    "\n",
    "val=4088.8\n",
    "valerr=5.3\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC1194\",dist,disterr])\n",
    "print(f\"NGC1194: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "val=8322.22\n",
    "valerr=1.13\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC5765b\",dist,disterr])\n",
    "print(f\"NGC 5765b: {dist:.0f} ± {disterr:.0f}\")\n",
    "\n",
    "val=1850.8\n",
    "valerr1=13.5\n",
    "valerr2=13.9\n",
    "dist=val/hubble\n",
    "disterr1=np.sqrt((valerr1/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "disterr2=np.sqrt((valerr2/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "disterr=(disterr1+disterr2)/2\n",
    "totdist.append([\"NGC2273\",dist,disterr])\n",
    "print(f\"NGC2273: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "val=10189.26\n",
    "valerr=1.20\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC6264\",dist,disterr])\n",
    "print(f\"NGC6264: {dist:.0f} ± {disterr:.0f}\")\n",
    "\n",
    "val=3259.75\n",
    "valerr=1.00\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"UGC3789\",dist,disterr])\n",
    "print(f\"UGC3789: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "val=4954.5\n",
    "valerr=15\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC2960\",dist,disterr])\n",
    "print(f\"NGC2960: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "val=7618.2\n",
    "valerr=14.0\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"ESO558\",dist,disterr])\n",
    "print(f\"ESO558: {dist:.0f} ± {disterr:.0f}\")\n",
    "\n",
    "val=7834.28\n",
    "valerr1=2.1\n",
    "valerr2=2.2\n",
    "dist=val/hubble\n",
    "disterr1=np.sqrt((valerr1/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "disterr2=np.sqrt((valerr2/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "disterr=(disterr1+disterr2)/2\n",
    "totdist.append([\"NGC6323\",dist,disterr])\n",
    "print(f\"NGC6323: {dist:.0f} ± {disterr:.0f}\")\n",
    "\n",
    "val=4818\n",
    "valerr=10.5\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"J0437\",dist,disterr])\n",
    "print(f\"J0437: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#distance for other sources \n",
    "\n",
    "#NGC 1068 \n",
    "#Baer-Way, 2024\n",
    "#2024ApJ...964..172B\n",
    "val=1137\n",
    "valerr=3\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC1068\",dist,disterr])\n",
    "print(f\"NGC1068: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#NGC 3393 \n",
    "#Koss, 2022\n",
    "#2022ApJS..261....6K\n",
    "val=3833\n",
    "valerr=5\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC3393\",dist,disterr])\n",
    "print(f\"NGC3393: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#Circinus\n",
    "#Tully, 2022\n",
    "#2009AJ....138..323T\n",
    "mM=28.12\n",
    "mMerr=0.36\n",
    "dist=10**((mM+5)/5)/10**6\n",
    "disterr=np.log(10)/5*dist*mMerr\n",
    "totdist.append([\"Circinus\",dist,disterr])\n",
    "print(f\"Circinus: {dist:.3f} ± {disterr:.3f}\")\n",
    "\n",
    "#CGCG 074-06\n",
    "#Albareti, 2017\n",
    "#2016SDSSD.C...0000:\n",
    "val=6915\n",
    "valerr=3\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"CGCG074-06\",dist,disterr])\n",
    "print(f\"CGCG074-06: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#NGC 4388\n",
    "#Lu, 1993\n",
    "#1993ApJS...88..383L\n",
    "val=2524\n",
    "valerr=1\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC4388\",dist,disterr])\n",
    "print(f\"NGC4388: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#NGC 4945\n",
    "#Kanehisa, 2023\n",
    "#2023MNRAS.519.6184K\n",
    "val=563\n",
    "valerr=3\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC4945\",dist,disterr])\n",
    "print(f\"NGC4945: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#UGC 6093\n",
    "#Albareti, 2017\n",
    "#2016SDSSD.C...0000:\n",
    "val=10803\n",
    "valerr=3\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"UGC6093\",dist,disterr])\n",
    "print(f\"UGC6093: {dist:.0f} ± {disterr:.0f}\")\n",
    "\n",
    "#NGC 3079\n",
    "#Springbob, 2005\n",
    "#2005ApJS..160..149S\n",
    "val=1106\n",
    "valerr=1\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC3079\",dist,disterr])\n",
    "print(f\"NGC3079: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#NGC 1320\n",
    "#Theureau, 2017\n",
    "#2017A&A...599A.104T\n",
    "val=2783\n",
    "valerr=10\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"NGC1320\",dist,disterr])\n",
    "print(f\"NGC1320: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#IC 2560\n",
    "#Pesce, 2015\n",
    "#2015ApJ...810...65P\n",
    "val=2925\n",
    "valerr=2\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"IC2560\",dist,disterr])\n",
    "print(f\"IC2560: {dist:.1f} ± {disterr:.1f}\")\n",
    "\n",
    "#Mrk 1029\n",
    "#Huchra, 1999\n",
    "#1999ApJS..121..287H\n",
    "val=9076\n",
    "valerr=32\n",
    "dist=val/hubble\n",
    "disterr=np.sqrt((valerr/hubble)**2+(hubbleerr*val/hubble**2)**2)\n",
    "totdist.append([\"Mrk1029\",dist,disterr])\n",
    "print(f\"Mrk1029: {dist:.0f} ± {disterr:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD make function to get distances\n",
    "\n",
    "import os\n",
    "from astroquery.ned import Ned\n",
    "import ast  # For safely parsing text file data\n",
    "\n",
    "import os\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "from scipy import constants\n",
    "c=constants.c\n",
    "\n",
    "def is_subsequence(small, large):\n",
    "    it = iter(large)\n",
    "    return all(char in it for char in small)\n",
    "\n",
    "def decompose_string(s):\n",
    "    parts = re.findall(r\"[A-Za-z]+|\\d+\", s)  # Finds all letter and number sequences\n",
    "    return parts if parts else [s]\n",
    "\n",
    "# Input file with source names and coordinates\n",
    "txtnamesandcoords = 'namesandcoords.txt'\n",
    "\n",
    "# List of desired reference codes\n",
    "#2018ApJ...863.. (Pesce2018) is the only one found\n",
    "wantrefs = ['2018ApJ...863..', '2023ApJ...948..', '2020ApJ...890..', '2020ApJ...891..']\n",
    "\n",
    "def getdistsold(newnames):\n",
    "    newrefs=[]\n",
    "    if not os.path.exists('distancetable.csv'):\n",
    "        url = 'https://ned.ipac.caltech.edu/Archive/Distances/NED30.5.1-D-17.1.2-20200415.csv'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open('distancetable.csv', \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            return(f\"Failed to download. Status code: {response.status_code}\")\n",
    "    \n",
    "    maserdist=[]\n",
    "    otherdist=[]\n",
    "    j1=-1\n",
    "    j2=-1\n",
    "    with open('distancetable.csv', \"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            textsource=row[3]\n",
    "            if len(textsource)==0:\n",
    "                continue\n",
    "            textdistmm=row[4]\n",
    "            textdistmmerr=row[5]\n",
    "\n",
    "            textdistMpc=row[6]\n",
    "            textmethod=row[7]\n",
    "            refcode=row[8]\n",
    "\n",
    "\n",
    "            textsource=textsource.replace(' ','')\n",
    "\n",
    "            findred=0\n",
    "            for i in newnames:\n",
    "                checkers=[]\n",
    "                for ii in i:\n",
    "                    ii=ii.split('Galaxy')[0]\n",
    "                    if is_subsequence(ii, textsource):\n",
    "                        checkers.append(ii)\n",
    "                if len(checkers)==len(i):\n",
    "                    if row[10]:\n",
    "                        findred=1\n",
    "                        redshift=row[10]\n",
    "                        Hubble=row[11]\n",
    "                        newdist=c*float(redshift)/float(Hubble)*c\n",
    "                    \n",
    "                    if textdistmmerr:\n",
    "                        if float(textdistmmerr)>0:\n",
    "                            if 'maser' in textmethod.lower():\n",
    "                                j1=j1+1\n",
    "                                newrefs.append(refcode)\n",
    "                                if j1==0:\n",
    "                                        maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                        maserdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<maserdisuncer:\n",
    "                                    maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                            else:\n",
    "                                j2=j2+1\n",
    "                                if j2==0:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                    otherdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<otherdisuncer:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "\n",
    "    return(maserdist,otherdist,refcode,findred,newrefs)\n",
    "\n",
    "# Function to process each source\n",
    "def process_sourceold(source_name, wantrefs, ra, dec,threshold, secondarynames):\n",
    "  \n",
    "    \"\"\"Query NED for redshift data and filter based on references and uncertainties.\"\"\"\n",
    "    # Skip excluded sources\n",
    "\n",
    "    # Query the redshift table from NED\n",
    "    distances_table = Ned.get_table(source_name, table='redshifts')\n",
    "\n",
    "    # Extract relevant columns\n",
    "    redshifts = distances_table['Published Redshift']\n",
    "    uncertainties = distances_table['Published Redshift Uncertainty']\n",
    "    refcodes = distances_table['Refcode']\n",
    "\n",
    "    # Combine into tuples\n",
    "    entries = [\n",
    "        (redshift, uncertainty, refcode)\n",
    "        for redshift, uncertainty, refcode in zip(redshifts, uncertainties, refcodes)\n",
    "    ]\n",
    "\n",
    "    # Filter for entries with desired references\n",
    "    desired_entries = [\n",
    "        entry for entry in entries if any(ref in entry[2] for ref in wantrefs)\n",
    "    ]\n",
    "\n",
    "    entries_with_reference = []\n",
    "    entries_without_reference = []\n",
    "\n",
    "    for redshift, uncertainty, refcode in desired_entries:\n",
    "        if any(ref in refcode for ref in wantrefs):  # Check if refcode contains a wanted reference\n",
    "            entries_with_reference.append((redshift, uncertainty, refcode))\n",
    "        else:\n",
    "            entries_without_reference.append((redshift, uncertainty, refcode))\n",
    "\n",
    "\n",
    "    reduced_entries = {}\n",
    "\n",
    "    # Step 2a: Prioritize entries from `entries_with_reference`\n",
    "    if entries_with_reference:\n",
    "        for redshift, uncertainty, refcode in entries_with_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "    if len(reduced_entries)==0:\n",
    "        # Step 2b: If `entries_with_reference` is empty, use `entries_without_reference`\n",
    "        for redshift, uncertainty, refcode in entries_without_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "\n",
    "\n",
    "    # Print results based on the filtering\n",
    "    redshift='NA'\n",
    "    uncertainty='NA'\n",
    "\n",
    "    newnames=[]\n",
    "    newlist=decompose_string(secondarynames[0][0])\n",
    "\n",
    "    newnames.append(newlist)\n",
    "    if len(secondarynames[0][1])!=0:\n",
    "        if secondarynames[0][1][0]!='NA':\n",
    "            for i in secondarynames[0][1]:\n",
    "                if not is_subsequence(secondarynames[0][0], i):\n",
    "                    newlist=decompose_string(i)\n",
    "                    newnames.append(newlist)\n",
    "\n",
    "    maserdists, otherdists, inewrefs, findred, newrefs = getdistsold(newnames)\n",
    "\n",
    "    if reduced_entries:\n",
    "        for irefcode, (iredshift, iuncertainty) in reduced_entries.items():\n",
    "            redshift=iredshift\n",
    "            ynfindref='y'\n",
    "            refcode=irefcode\n",
    "            if iuncertainty>0:\n",
    "                uncertainty=iuncertainty\n",
    "            else:\n",
    "                input(f'No uncertainty for chosen referencecode: {refcode} , {source}')\n",
    "                uncertainty='NA'\n",
    "    else:\n",
    "\n",
    "        # If no desired references, and no maser distances, find valid entries with uncertainties\n",
    "        valid_entries = [entry for entry in entries if entry[1] > 0]\n",
    "        if valid_entries:\n",
    "            # Select the entry with the lowest uncertainty\n",
    "            lowest_uncertainty_entry = min(valid_entries, key=lambda x: x[1])\n",
    "            lowest_redshift, lowest_uncertainty, reference_code = lowest_uncertainty_entry\n",
    "            redshift=lowest_redshift\n",
    "            uncertainty= lowest_uncertainty\n",
    "            refcode=reference_code\n",
    "            ynfindref='n'\n",
    "        else:\n",
    "            input(f\"No valid redshift entries found for {source_name} (1)\\n\")\n",
    "        if len(maserdists)!=0:\n",
    "            z_observed = redshift\n",
    "            if z_observed >= threshold:\n",
    "                if len(maserdists)!=0 and findred==1:\n",
    "                        input('new maser source found... adjust accordingly (1)')\n",
    "        \n",
    "    z_observed = redshift\n",
    "    z_uncer=uncertainty\n",
    "\n",
    "    if z_observed <= threshold:\n",
    "        if len(maserdists)!=0:\n",
    "            input('new maser source found... adjust accordingly (2)')\n",
    "        if len(maserdists)==0:\n",
    "            textdistmm=float(otherdists[1])\n",
    "            textdistmmerr=float(otherdists[2])\n",
    "            textdistMpc=float(otherdists[3])\n",
    "\n",
    "            newdist=10**((textdistmm)/5-5)\n",
    "            newdist_uncer=np.log(10)/5*newdist*textdistmmerr\n",
    "            textmethod=otherdists[4]\n",
    "            refcode=otherdists[5]\n",
    "\n",
    "            return([newdist,newdist_uncer],textmethod,'NA',refcode,'DISTANCE',newrefs)\n",
    "\n",
    "    # Calculate heliocentric velocity\n",
    "    c = 299792.458  # Speed of light in km/s\n",
    "    v_helio = z_observed * c\n",
    "    v_helio_uncer = z_uncer * c\n",
    "\n",
    "    #Hubble Constant\n",
    "    #Pesce, APJ 891:L1\n",
    "    H = 73.9\n",
    "    H_uncer = 3\n",
    "    dist=v_helio/H\n",
    "    dist_uncer=np.sqrt((v_helio_uncer/H)**2 + (v_helio/H**2*H_uncer)**2)\n",
    "\n",
    "    return([dist,dist_uncer],'NA',ynfindref,refcode,'REDSHIFT', newrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on local computer to SMBH mass\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parent\n",
    "Greenepath=f'{parent_dir}/CountingBHS_and_Spectra/Greene_params/Greene_params.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date format\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def decimal_year_to_date(decimal_year):\n",
    "    year = int(decimal_year)  # Extract the year\n",
    "    fraction = decimal_year - year  # Extract the decimal part\n",
    "\n",
    "    # Convert the decimal part to days (assuming 365 days in a year)\n",
    "    days_elapsed = int(round(fraction * 365))  \n",
    "\n",
    "    # Compute the actual date by adding days to January 1st of that year\n",
    "    date = datetime(year, 1, 1) + timedelta(days=days_elapsed)\n",
    "\n",
    "    # Format as YY.MM.DD\n",
    "    return f\"{date.year }/{date.month:02}/{date.day:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get SMBH size\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "def linear_to_log_uncertainty(x, delta_x):\n",
    "    return delta_x / (x * np.log(10))\n",
    "\n",
    "def log_to_linear_uncertainty(x, delta_x):\n",
    "    return x * np.log(10) * delta_x\n",
    "\n",
    "def getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc):\n",
    "    mass=10**float(log_BH_mass_solar)*mass_sun\n",
    "    mass_unc=mass*np.log(10)*float(log_BH_mass_solar_uncer)\n",
    "    mass_fracerror=(mass_unc/mass)*100\n",
    "\n",
    "    distance=distanceMPc*pc*10**6\n",
    "    distance_uncer=distanceMPc_uncer*pc*10**6\n",
    "    dist_fracerror=(distance_uncer/distance)*100\n",
    "    \n",
    "    if arcsectopc=='NA':\n",
    "        m_d=mass/distance\n",
    "        m_d_unc=np.sqrt((m_d/mass*mass_unc)**2+(m_d/distance*distance_uncer)**2)\n",
    "        m_d_fracerror=(m_d_unc/m_d)*100\n",
    "        diam_bhs_microarcsec_fracerror = m_d_fracerror\n",
    "\n",
    "        diam_bhs_rad=2*np.sqrt(27)*G/(c**2)*m_d\n",
    "        diam_bhs_deg=diam_bhs_rad*360/(2*pi)\n",
    "        diam_bhs_arcsec=diam_bhs_deg*60*60\n",
    "        diam_bhs_microarcsec=diam_bhs_arcsec*10**6\n",
    "\n",
    "        diam_bhs_microarcsec_unc=diam_bhs_microarcsec/(m_d)*m_d_unc\n",
    "\n",
    "\n",
    "        return(log_BH_mass_solar, log_BH_mass_solar_uncer, mass_fracerror, distanceMPc, distanceMPc_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "        \n",
    "    diam_bhs=2*np.sqrt(27)*G/(c**2)*mass\n",
    "    diam_bhs_unc = 2*np.sqrt(27)*G/(c**2)*mass_unc\n",
    "    \n",
    "    diam_bhspc=diam_bhs/pc\n",
    "    diam_bhspc_unc=diam_bhs_unc/pc\n",
    "\n",
    "    diam_bhs_arsec=diam_bhspc/arcsectopc\n",
    "    diam_bhs_microarcsec=diam_bhs_arsec*10**6\n",
    "\n",
    "    diam_bhs_arsec_unc=np.sqrt(\n",
    "                                (diam_bhspc_unc/arcsectopc)**2\n",
    "                                + ((-1)*diam_bhspc/arcsectopc**2*arcsectopc_unc)**2\n",
    "                                )\n",
    "    \n",
    "    diam_bhs_microarcsec_unc=diam_bhs_arsec_unc*10**6\n",
    "    diam_bhs_microarcsec_fracerror = (diam_bhs_microarcsec_unc/diam_bhs_microarcsec)*100\n",
    "\n",
    "    return(mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "\n",
    "sizeIC1459=8.9\n",
    "sizeNGC4594=7.0\n",
    "logIC1459flux=np.log10(220)\n",
    "logNGC4594flux=np.log10(200)\n",
    "\n",
    "logIC1459fluxunc=linear_to_log_uncertainty(220, 21)\n",
    "logNGC4594fluxunc=linear_to_log_uncertainty(200, 10)\n",
    "\n",
    "#IC1459\n",
    "distanceMPc=29\n",
    "distanceMPc_uncer=3.7\n",
    "\n",
    "log_BH_mass_solar=9.4\n",
    "log_BH_mass_solar_uncer_up=0.077\n",
    "log_BH_mass_solar_uncer_down=0.035\n",
    "\n",
    "mass, mass_unc_up, mass_fracerror_up, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer_up,distanceMPc,distanceMPc_uncer,'NA','NA')\n",
    "mass, mass_unc_down, mass_fracerror_down, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer_down,distanceMPc,distanceMPc_uncer,'NA','NA')\n",
    "\n",
    "logIC1459sizeunc_up=linear_to_log_uncertainty(diam_bhs_microarcsec, diam_bhs_microarcsec_uncup)\n",
    "logIC1459sizeunc_down=linear_to_log_uncertainty(diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown)\n",
    "logIC1459sizeunc=np.array([[logIC1459sizeunc_down], [logIC1459sizeunc_up]])\n",
    "sizeIC1459=diam_bhs_microarcsec\n",
    "\n",
    "#NGC4594\n",
    "distanceMPc=9.9\n",
    "distanceMPc_uncer=0.82\n",
    "\n",
    "log_BH_mass_solar=8.8\n",
    "log_BH_mass_solar_uncer_up=0.025\n",
    "log_BH_mass_solar_uncer_down=0.027\n",
    "\n",
    "mass, mass_unc_up, mass_fracerror_up, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer_up,distanceMPc,distanceMPc_uncer,'NA','NA')\n",
    "mass, mass_unc_down, mass_fracerror_down, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer_down,distanceMPc,distanceMPc_uncer,'NA','NA')\n",
    "\n",
    "logNGC4594sizeunc_up=linear_to_log_uncertainty(diam_bhs_microarcsec, diam_bhs_microarcsec_uncup)\n",
    "logNGC4594sizeunc_down=linear_to_log_uncertainty(diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown)\n",
    "logNGC4594sizeunc=np.array([[logNGC4594sizeunc_down], [logNGC4594sizeunc_up]])\n",
    "sizeNGC4594=diam_bhs_microarcsec\n",
    "\n",
    "\n",
    "\n",
    "m87size=diam_bhs_microarcsec\n",
    "m87sizeunc_down=diam_bhs_microarcsec_uncdown\n",
    "m87sizeunc_up=diam_bhs_microarcsec_uncup\n",
    "logm87sizeunc_down=linear_to_log_uncertainty(m87size, m87sizeunc_down)\n",
    "logm87sizeunc_up=linear_to_log_uncertainty(m87size, m87sizeunc_up)\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sagmass=6.6\n",
    "sagmass_unc_up=.12\n",
    "sagmass_unc_down=.07\n",
    "sagdist=8.15*10**(-3)\n",
    "sagdist_unc=.15*10**(-3)\n",
    "\n",
    "distanceMPc=sagdist\n",
    "distanceMPc_uncer=sagdist_unc\n",
    "\n",
    "log_BH_mass_solar=sagmass\n",
    "log_BH_mass_solar_uncerup=sagmass_unc_up\n",
    "log_BH_mass_solar_uncerdown=sagmass_unc_down\n",
    "\n",
    "mass, mass_uncup, mass_fracerrorup, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(sagmass,sagmass_unc_up,sagdist,sagdist_unc,'NA','NA')\n",
    "mass, mass_uncdown, mass_fracerrordown, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(sagmass,sagmass_unc_down,sagdist,sagdist_unc,'NA','NA')\n",
    "\n",
    "sagsize=diam_bhs_microarcsec\n",
    "sagsizeunc_down=diam_bhs_microarcsec_uncdown\n",
    "sagsizeunc_up=diam_bhs_microarcsec_uncup\n",
    "logsagsizeunc_down=linear_to_log_uncertainty(sagsize, sagsizeunc_down)\n",
    "logsagsizeunc_up=linear_to_log_uncertainty(sagsize, sagsizeunc_up)\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'SagA*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} ± {format_number(distanceMPc_uncer)} MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "log_BH_mass_solar_uncerup=format_number(float(log_BH_mass_solar_uncerup))\n",
    "log_BH_mass_solar_uncerdown=format_number(float(log_BH_mass_solar_uncerdown))\n",
    "mass_fracerror=(mass_fracerrorup+mass_fracerrordown)/2\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} $^{{+{log_BH_mass_solar_uncerup}}}_{{-{log_BH_mass_solar_uncerdown}}}$ log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles1=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "fig, ax = pylab.subplots()\n",
    "\n",
    "m87mass=9.81\n",
    "m87mass_unc=0.06\n",
    "m87dist=16.8\n",
    "m87dist_uncup=.8\n",
    "m87dist_uncdown=.7\n",
    "\n",
    "distanceMPc=m87dist\n",
    "distanceMPc_uncerup=m87dist_uncup\n",
    "distanceMPc_uncerdown=m87dist_uncdown\n",
    "\n",
    "log_BH_mass_solar=m87mass\n",
    "log_BH_mass_solar_uncer=m87mass_unc\n",
    "\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerup, dist_fracerrorup, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncup,'NA','NA')\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerdown, dist_fracerrordown, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncdown,'NA','NA')\n",
    "\n",
    "m87size=diam_bhs_microarcsec\n",
    "m87sizeunc_down=diam_bhs_microarcsec_uncdown\n",
    "m87sizeunc_up=diam_bhs_microarcsec_uncup\n",
    "logm87sizeunc_down=linear_to_log_uncertainty(m87size, m87sizeunc_down)\n",
    "logm87sizeunc_up=linear_to_log_uncertainty(m87size, m87sizeunc_up)\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'M87*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "dist_fracerror=(distanceMPc_uncerup+distanceMPc_uncerdown)/2\n",
    "distanceMPc_uncerup=format_number(float(distanceMPc_uncerup))\n",
    "distanceMPc_uncerdown=format_number(float(distanceMPc_uncerdown))\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} $^{{+{distanceMPc_uncerup}}}_{{-{distanceMPc_uncerdown}}}$ MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} ±{log_BH_mass_solar_uncerdown} log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles2=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "legend1=ax.legend(handles=handles2, loc='upper center')   \n",
    "ax.add_artist(legend1)\n",
    "ax.legend(handles=handles1, loc='lower center')   \n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xticks([])  # Remove x-axis ticks\n",
    "ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "# Remove tick labels\n",
    "ax.set_xticklabels([])  # Remove x-axis labels\n",
    "ax.set_yticklabels([])  # Remove y-axis labels\n",
    "if not os.path.exists('Extras'):\n",
    "    os.makedirs('Extras')\n",
    "#pylab.savefig(f'Extras/SMBH of SagA* and M87')\n",
    "pylab.clf() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather data for BHS vs Flux Graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "findwithprocessor=0\n",
    "\n",
    "noprocessor=[\n",
    "    ['4258',0.617,0.049],\n",
    "    ['1194',0.131,0.016],\n",
    "    ['1068',0.111,0.0005],\n",
    "    ['5765b',0.0398,0.0049],\n",
    "    ['2273',0.0349,0.0035],\n",
    "    ['3393',0.0314,0.0239],\n",
    "    ['circinus',0.0280,0.0079],\n",
    "    ['074-064',0.0265,0.0026],\n",
    "    ['6264',0.0230,0.0028],\n",
    "    ['3789',0.0227,0.0048],\n",
    "    ['4388',0.0218,0.0022],\n",
    "    ['4945',0.0186,0.0077],\n",
    "    ['6093',0.0180,0.0011],\n",
    "    ['3079',0.0172,0.0021],\n",
    "    ['558',0.0165,0.0013],\n",
    "    ['2960',0.0164,0.0020],\n",
    "    ['0437',0.0157,0.0023],\n",
    "    ['1320',0.0150,0.0056],\n",
    "    ['2560',0.0113,0.0016],\n",
    "    ['6323',0.00968,0.00118],\n",
    "    ['1029',0.00159,0.00048]\n",
    "    ]\n",
    "\n",
    "chooser=False\n",
    "choosesource='1029'\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "def find_flux_with_smallest_beam(arrays):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    arrays = np.array(arrays)\n",
    "    index_of_smallest_beam = np.argmin(arrays[:, 2].astype(float))\n",
    "    flux = arrays[index_of_smallest_beam, 0]\n",
    "    fluxunc = arrays[index_of_smallest_beam, 1]\n",
    "    return flux, fluxunc\n",
    "\n",
    "def find_sma(arrays):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    arrays = np.array(arrays)\n",
    "    index_of_smallest_beam = np.argmin(arrays[:, 2].astype(float))\n",
    "    flux = arrays[index_of_smallest_beam, 0]\n",
    "    fluxunc = arrays[index_of_smallest_beam, 1]\n",
    "    return flux, fluxunc\n",
    "\n",
    "def linear_to_log_uncertainty(x, delta_x):\n",
    "    return delta_x / (x * np.log(10))\n",
    "\n",
    "graph_array=[]\n",
    "nograph=[]\n",
    "\n",
    "for isource, data in grouped_data.items():\n",
    "    if isource=='NGC5495':\n",
    "        continue\n",
    "    if chooser==True and choosesource not in isource:\n",
    "        continue\n",
    "    # Main loop to read and process sources from the input file\n",
    "    if os.path.exists(txtnamesandcoords):\n",
    "        with open(txtnamesandcoords, 'r') as infile:\n",
    "            for line in infile:\n",
    "\n",
    "                # Parse the line into a list of name-coordinate pairs\n",
    "                params = ast.literal_eval(line)\n",
    "                for inamecoords in params:                \n",
    "                    source_name = inamecoords[0][0]\n",
    "                    if not isource.lower() in source_name.lower():\n",
    "                        continue\n",
    "                    source = source_name\n",
    "                    ra = inamecoords[1][1]\n",
    "                    dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                    distanceMPc, distanceMPc_uncer = process_sourcenew(source_name)\n",
    "\n",
    "                    method='NA'\n",
    "                    ynfindref='NA'\n",
    "                    refcode='NA'\n",
    "                    red_depend='NA'\n",
    "\n",
    "                    #OLD METHOD \n",
    "                    #findvals=process_sourceold(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                    #method=findvals[1]\n",
    "                    #ynfindref=findvals[2]\n",
    "                    #refcode=findvals[3]\n",
    "                    #red_depend=findvals[4]\n",
    "\n",
    "                    #print(isource)\n",
    "                    #print(findvals[3])\n",
    "                    #print(f\"{distanceMPc:.1f}\")\n",
    "    else:\n",
    "        print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "    arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "    arcsectopc=arcsectokpc*1000\n",
    "\n",
    "    arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "    arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "    arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "    distance='NA'\n",
    "    with open(Greenepath, 'r') as infile:\n",
    "        j=-1\n",
    "        breaker=1\n",
    "        for line in infile:\n",
    "            j=j+1\n",
    "            if j>20:\n",
    "                continue\n",
    "            source_name=line.split(' ')[0]\n",
    "            source_name=source_name.replace(\"−\",\"-\")\n",
    "            if isource=='WISEAJ043703':\n",
    "                isource='J0437'\n",
    "            if isource.lower() in source_name.lower():\n",
    "                log_BH_mass_solar=line.split(' ')[3]\n",
    "                log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                breaker=0\n",
    "            if 'cgcg' in isource.lower():\n",
    "                log_BH_mass_solar=7.38\n",
    "                log_BH_mass_solar_offset=0.012\n",
    "                breaker=0\n",
    "        if breaker!=1:\n",
    "            if findwithprocessor==1:\n",
    "                mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "            else:\n",
    "                finder=0\n",
    "                for findsource,bhs,bhsunc in noprocessor:\n",
    "                    if findsource.lower() in isource.lower():\n",
    "                        diam_bhs_microarcsec=bhs\n",
    "                        diam_bhs_microarcsec_unc=bhsunc\n",
    "                        finder=1\n",
    "                if finder==0:\n",
    "                    input(f\"ERROR for {isource} not found in noprocessor list\")\n",
    "        else:\n",
    "            print(f'{source} not found')\n",
    "        \n",
    "\n",
    "        fluxs=[]\n",
    "        fluxsuplim=[]\n",
    "        teles=[]\n",
    "        with open(source_text, 'r') as infile:\n",
    "            j=-1\n",
    "            for line in infile:\n",
    "                if line=='\\n':\n",
    "                    continue\n",
    "                line=eval(line)\n",
    "                source=line[0]\n",
    "                if isource in source:\n",
    "                    snr=line[6].split('\\n')[0]\n",
    "\n",
    "                    freq=np.log10(float(line[2]))\n",
    "                    flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "                    if snr!='NA':\n",
    "                        linflux=float(line[3].split('*')[0])\n",
    "                        linfluxunc=float(linflux)/float(snr)\n",
    "                        #def linear_to_log_uncertainty(x, delta_x):\n",
    "\n",
    "                        fluxunc=linear_to_log_uncertainty(linflux,linfluxunc)\n",
    "                    else:\n",
    "                        fluxunc='NA'\n",
    "                        \n",
    "                    if '-' not in line[5]:\n",
    "                        beam=np.log10(float(line[5]))\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    lim=[200,400]\n",
    "\n",
    "                    if 10**freq<lim[1] and 10**freq>lim[0]:\n",
    "                        fluxs.append([flux,fluxunc,beam])\n",
    "\n",
    "                    tele=line[1]\n",
    "\n",
    "                    if tele=='SMA':\n",
    "                        teles.append([flux,fluxunc])\n",
    "        if fluxs:      \n",
    "            graph_array.append(isource)\n",
    "            flux_with_smallest_beam = find_flux_with_smallest_beam(fluxs)\n",
    "            sma_flux = find_sma(fluxs)\n",
    "            graph_array.append(flux_with_smallest_beam)\n",
    "            if diam_bhs_microarcsec_unc!='NA':\n",
    "                log_diam_bhs_microarcsec_unc = linear_to_log_uncertainty(diam_bhs_microarcsec,diam_bhs_microarcsec_unc)\n",
    "            else:\n",
    "                log_diam_bhs_microarcsec_unc = 'NA'\n",
    "            log_diam_bhs_microarcsec = np.log10(diam_bhs_microarcsec)\n",
    "            bhs=[log_diam_bhs_microarcsec,log_diam_bhs_microarcsec_unc]\n",
    "            graph_array.append(bhs)\n",
    "            smasize=np.size(teles)\n",
    "            if smasize==4 and '4258'in isource:\n",
    "              graph_array.append(teles)\n",
    "              print('test')\n",
    "            elif smasize==2:\n",
    "              graph_array.append(teles)\n",
    "              pass\n",
    "            elif smasize==0:\n",
    "              graph_array.append(['NA','NA'])\n",
    "              pass\n",
    "            else:\n",
    "                print(source)\n",
    "                print(smasize)\n",
    "        else:\n",
    "            log_diam_bhs_microarcsec_unc = linear_to_log_uncertainty(diam_bhs_microarcsec,diam_bhs_microarcsec_unc)\n",
    "            log_diam_bhs_microarcsec = np.log10(diam_bhs_microarcsec)\n",
    "            bhs=[log_diam_bhs_microarcsec,log_diam_bhs_microarcsec_unc]\n",
    "            nograph.append([isource,bhs])\n",
    "            smasize=np.size(teles)\n",
    "            if smasize==2:\n",
    "              input('error')\n",
    "            elif smasize==0:\n",
    "              nograph.append(['NA','NA'])\n",
    "              pass\n",
    "            else:\n",
    "                input('error2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make BHS vs Flux Graph\n",
    "\n",
    "sourcesofinterest=('4258','1194','3079','4945','Circinus','1068')\n",
    "allsourcesofinterest=False\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "earthdiamval=12756\n",
    "earthradval=earthdiamval/2\n",
    "\n",
    "\n",
    "#in km\n",
    "#https://www.nasa.gov/wp-content/uploads/2009/07/180561main_ETM.Distance.Moon_.pdf\n",
    "#average moon\n",
    "moondist = ['Moon',382500+earthradval]\n",
    "#at the equator\n",
    "#https://imagine.gsfc.nasa.gov/features/cosmic/earth_info.html\n",
    "earthdiam = ['Earth',earthdiamval]\n",
    "#https://science.nasa.gov/mission/webb/orbit/#:~:text=A%20Solar%20Orbit&text=Webb%20orbits%20the%20sun%201.5,second%20Lagrange%20point%20or%20L2.\n",
    "l2dist = ['L2',1.5*10**6+earthradval]\n",
    "#https://science.nasa.gov/mars/facts/\n",
    "marsdist = ['Mars',228*10**6+earthradval]\n",
    "bhex = ['BHEX', 20200+earthradval]\n",
    "\n",
    "sun_dist_l3  = ['L3', 300*10**6+earthradval]\n",
    "l45  = ['L4/L5', 150*10**6+earthradval]\n",
    "\n",
    "#in GHz\n",
    "operfreq=230\n",
    "\n",
    "baselines=[moondist,earthdiam,l2dist,bhex,l45]\n",
    "\n",
    "baselinesize=[]\n",
    "for ibase in baselines:\n",
    "    operfreq_Hz=operfreq*10**9\n",
    "    wavelength=c/operfreq_Hz\n",
    "    bl_size=wavelength/(ibase[1]*1000)\n",
    "    bl_size=bl_size*180/pi*3600*10**6\n",
    "    baselinesize.append([ibase[0],bl_size])\n",
    "\n",
    "\n",
    "\n",
    "fluxthresh=[0.1,1,10,100]\n",
    "\n",
    "\n",
    "# Organizing data into a dictionary\n",
    "data=graph_array\n",
    "\n",
    "\n",
    "galaxy_data = {}\n",
    "for i in range(0, len(data), 4):\n",
    "    galaxy_name = data[i]\n",
    "    flux_beam = data[i+1]\n",
    "    log_diam_unc = data[i+2]\n",
    "    sma_data = data[i+3]\n",
    "\n",
    "\n",
    "    \n",
    "    # Assuming flux is always the first element in the tuple and the logarithmic diameter is the first element in the list\n",
    "    #if flux_beam[1] != 'NA':  # Skip entries where beam size is 'NA'\n",
    "\n",
    "    log_diam = float(log_diam_unc[0])  # Use logarithmic diameter\n",
    "    log_diamunc = float(log_diam_unc[1])\n",
    "    if galaxy_name not in galaxy_data:\n",
    "        galaxy_data[galaxy_name] = {'flux': [], 'log_diameter': [], 'fluxunc': [], 'sizeunc': [], 'smaflux': [], 'smafluxunc': []}\n",
    "    flux=float(flux_beam[0])\n",
    "    galaxy_data[galaxy_name]['flux'].append(flux)\n",
    "    galaxy_data[galaxy_name]['log_diameter'].append(log_diam)\n",
    "    galaxy_data[galaxy_name]['sizeunc'].append(log_diamunc)\n",
    "    if flux_beam[1] != 'NA':\n",
    "        fluxunc = float(flux_beam[1])\n",
    "        galaxy_data[galaxy_name]['fluxunc'].append(fluxunc)\n",
    "    else:\n",
    "        galaxy_data[galaxy_name]['fluxunc'].append('NA')\n",
    "\n",
    "    size = np.size(sma_data[0])\n",
    "    if not size==1:\n",
    "        galaxy_data[galaxy_name]['smaflux'].append(sma_data[0][0])\n",
    "        if sma_data[0][1]!='NA':\n",
    "            galaxy_data[galaxy_name]['smafluxunc'].append(sma_data[0][1])\n",
    "        else:\n",
    "            galaxy_data[galaxy_name]['smafluxunc'].append('NA')\n",
    "    else:\n",
    "        galaxy_data[galaxy_name]['smaflux'].append('NA')\n",
    "        galaxy_data[galaxy_name]['smafluxunc'].append('NA')\n",
    "\n",
    "\n",
    "# Step 2: Plotting\n",
    "\n",
    "min_flux = float('inf')  # Initialize min_flux to a very large number\n",
    "max_flux = float('-inf')  # Initialize max_flux to a very small number\n",
    "min_log_diam = float('inf')  # Initialize min_log_diam to a very large number\n",
    "max_log_diam = float('-inf')  # Initialize max_log_diam to a very small number\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "\n",
    "for galaxy, measurements in galaxy_data.items():\n",
    "\n",
    "    # Check and update the min/max for flux\n",
    "    if min(measurements['flux']) < min_flux:\n",
    "        min_flux = min(measurements['flux'])\n",
    "    if max(measurements['flux']) > max_flux:\n",
    "        max_flux = max(measurements['flux'])\n",
    "    \n",
    "    # Check and update the min/max for log_diameter\n",
    "    if min(measurements['log_diameter']) < min_log_diam:\n",
    "        min_log_diam = min(measurements['log_diameter'])\n",
    "    if max(measurements['log_diameter']) > max_log_diam:\n",
    "        max_log_diam = max(measurements['log_diameter'])\n",
    "\n",
    "    for flux, log_diam, fluxunc, sizeunc, sma, smaunc in zip(measurements['flux'], measurements['log_diameter'], measurements['fluxunc'], measurements['sizeunc'], measurements['smaflux'], measurements['smafluxunc']):\n",
    "        print(galaxy)\n",
    "        if fluxunc!='NA':\n",
    "            plt.errorbar(log_diam, flux, color='blue', markersize=3.5, marker='o',yerr=fluxunc ,xerr=sizeunc, elinewidth=0.5,capsize=1, capthick=0.5)\n",
    "        else: \n",
    "            plt.errorbar(log_diam, flux, color='red', markersize=3.5, marker='v', xerr=sizeunc, elinewidth=0.5,capsize=1, capthick=0.5)\n",
    "        if sma!='NA':\n",
    "            if smaunc!='NA'and fluxunc=='NA':\n",
    "                input('ERROR')\n",
    "            elif sma==flux and smaunc==fluxunc:\n",
    "              if smaunc!='NA':\n",
    "                  pass\n",
    "                  #plt.errorbar(log_diam, sma, color='white', markersize=1, marker='x')\n",
    "              else: \n",
    "                  pass\n",
    "                  #plt.errorbar(log_diam, sma, color='white', markersize=1, marker='x')\n",
    "            else:\n",
    "                pass\n",
    "                #print(galaxy)\n",
    "        if allsourcesofinterest==False:\n",
    "            for i in sourcesofinterest:\n",
    "                if i in galaxy:\n",
    "                    #print(f\"{galaxy}: {10**log_diam}\")\n",
    "                    if 'Circinus' in galaxy:\n",
    "                        plt.text(log_diam, flux-0.12, galaxy, fontsize=9, ha='center')\n",
    "                    else:\n",
    "                        plt.text(log_diam, flux+0.03, galaxy, fontsize=9, ha='center')\n",
    "        else:\n",
    "            plt.text(log_diam, flux+0.03, galaxy, fontsize=9, ha='center')\n",
    "\n",
    "\n",
    "if  np.log10(sagsize) > max(measurements['log_diameter']):\n",
    "    max_log_diam = np.log10(sagsize)\n",
    "\n",
    "if np.log10(m87size) > max(measurements['log_diameter']):\n",
    "    max_log_diam = np.log10(m87size)\n",
    "\n",
    "\n",
    "m87bright=1.571*1000\n",
    "m87unc=0.261*1000\n",
    "logm87flux=np.log10(m87bright)\n",
    "logm87fluxunc=linear_to_log_uncertainty(m87bright, m87unc)\n",
    "\n",
    "sagbright=3.22*1000\n",
    "sagunc=0.62*1000\n",
    "logsagflux=np.log10(sagbright)\n",
    "logsagfluxunc=linear_to_log_uncertainty(sagbright, sagunc)\n",
    "\n",
    "logsagsizeunc = np.array([[logsagsizeunc_down], [logsagsizeunc_up]])\n",
    "logm87sizeunc = np.array([[logm87sizeunc_down], [logm87sizeunc_up]])\n",
    "\n",
    "if  logm87flux > max_flux:\n",
    "    max_flux = logm87flux\n",
    "\n",
    "if logsagflux > max_flux:\n",
    "    max_flux = logsagflux\n",
    "\n",
    "\n",
    "min_fluxp=round_down_to_half_integer(min_flux)\n",
    "max_fluxp=round_up_to_half_integer(max_flux)\n",
    "min_log_diamp=round_down_to_half_integer(min_log_diam)\n",
    "max_log_diamp=round_up_to_half_integer(max_log_diam)\n",
    "\n",
    "interval =  max_fluxp - min_fluxp\n",
    "ten_percent = interval * 0.05\n",
    "min_flux = min_fluxp - ten_percent\n",
    "max_flux = max_fluxp + ten_percent\n",
    "\n",
    "interval = max_log_diamp - min_log_diamp\n",
    "ten_percent = interval * 0.05\n",
    "min_log_diam = min_log_diamp - ten_percent\n",
    "max_log_diam = max_log_diamp + ten_percent\n",
    "\n",
    "ax.set_xlim([min_log_diam, max_log_diam])\n",
    "ax.set_ylim([min_flux, max_flux])\n",
    "\n",
    "x_tick_positions=np.arange(min_log_diamp, max_log_diamp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{pos:.1f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "ax.set_xticks(x_tick_positions)\n",
    "ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "y_tick_positions = np.arange(min_fluxp, max_fluxp + 0.5, 0.5)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{pos:.1f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "ax.set_yticks(y_tick_positions)\n",
    "ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "x_minor_locator = MultipleLocator(0.1)\n",
    "y_minor_locator = MultipleLocator(0.1)\n",
    "ax.yaxis.set_minor_locator(x_minor_locator)\n",
    "ax.xaxis.set_minor_locator(y_minor_locator)\n",
    "\n",
    "for ibase in baselinesize:\n",
    "    print(f\"{ibase[0]}: {ibase[1]}\")\n",
    "    plt.axvline(x=np.log10(ibase[1]), color='black', linestyle='-', linewidth=1)\n",
    "    plt.text(np.log10(ibase[1])-0.1, max_fluxp, f'{ibase[0]}', verticalalignment='center', color='black', rotation=90)  # Adjust position as needed\n",
    "\n",
    "for iflux in fluxthresh:\n",
    "    plt.axhline(y=np.log10(iflux), color='black', linestyle='-', linewidth=1)\n",
    "    #plt.text(3.1, max(y), 'This is x=3', verticalalignment='center', color='red')  # Adjust position as needed\n",
    "\n",
    "plt.errorbar(np.log10(sagsize), logsagflux, color='green', markersize=3, marker='o',yerr=logsagfluxunc ,xerr=logsagsizeunc, elinewidth=0.5,capsize=1, capthick=0.5)\n",
    "plt.text(np.log10(sagsize)+0.31, logsagflux-0.035, f'Sgr A*', ha='center', color='black')  # Adjust position as needed\n",
    "\n",
    "plt.errorbar(np.log10(m87size), logm87flux, color='green', markersize=3, marker='o',yerr=logm87fluxunc ,xerr=logm87sizeunc, elinewidth=0.5,capsize=1, capthick=0.5)\n",
    "plt.text(np.log10(m87size)+0.21, logm87flux-0.035, f'M87*', ha='center', color='black')  # Adjust position as needed\n",
    "\n",
    "#plt.errorbar(np.log10(sizeIC1459), logIC1459flux, color='green', markersize=3, marker='o',yerr=logIC1459fluxunc,xerr=logIC1459sizeunc, elinewidth=0.5,capsize=1, capthick=0.5)\n",
    "#plt.text(np.log10(sizeIC1459), logIC1459flux+0.07, f'IC 1459', ha='center', color='black', fontsize=9)  # Adjust position as needed\n",
    "\n",
    "#plt.errorbar(np.log10(sizeNGC4594), logNGC4594flux, color='green', markersize=3, marker='o',yerr=logNGC4594fluxunc,xerr=logNGC4594sizeunc, elinewidth=0.5,capsize=1, capthick=0.5)\n",
    "#plt.text(np.log10(sizeNGC4594), logNGC4594flux-0.15, f'NGC 4594', ha='center', color='black', fontsize=9)  # Adjust position as needed\n",
    "\n",
    "for ino in nograph:\n",
    "    name=ino[0]\n",
    "    if name=='J0437':\n",
    "        name='WISEAJ043703\\n+245607.0'\n",
    "    pass\n",
    "    #plt.axvline(x=ino[1][0], color='black', linestyle='-', linewidth=1, ymin=0, ymax=0.15)\n",
    "    #plt.text(ino[1][0]+0.05, min_fluxp + 0.15, f'{name}', verticalalignment='center', color='black', rotation=90, fontsize=7)  # Adjust position as needed\n",
    "\n",
    "plt.xlabel(r'log$_{10}$ Shadow Size ($\\mu$\")')\n",
    "plt.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "plt.title(f'BHS vs Flux at 200-400 GHz')\n",
    "plt.grid(False)\n",
    "plt.savefig('BHS_Flux_Graph', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
