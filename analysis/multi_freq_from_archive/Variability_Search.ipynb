{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Here for Making Beam-Date Graphs\n",
    "import os\n",
    "os.chdir('analysis/multi_freq_from_archive')\n",
    "#format beamsize number\n",
    "def format_number(number):\n",
    "        # Case 1: If the number is less than 1 (e.g., 0.004567)\n",
    "        if number < 0:\n",
    "                # Format the positive part of the number and prepend the negative sign\n",
    "                return \"-\" + format_number(abs(number))\n",
    "        if number < 1:\n",
    "                # Convert the number to a string with high precision\n",
    "                num_str = f\"{number:.16g}\"\n",
    "\n",
    "                # Identify the leading zeros and decimal point\n",
    "                leading_part = []\n",
    "                for char in num_str:\n",
    "                        if char == '0' or char == '.':\n",
    "                                leading_part.append(char)\n",
    "                        else:\n",
    "                                break\n",
    "\n",
    "                # Remove leading zeros and the decimal point for significant digits\n",
    "                significant_digits = \"\".join(char for char in num_str if char.isdigit() and char != \"0\")\n",
    "\n",
    "                # Extract the first two non-zero digits\n",
    "                if len(significant_digits) >= 2:\n",
    "                        first_two = significant_digits[:2]\n",
    "                elif len(significant_digits) == 1:\n",
    "                        first_two = significant_digits + \"0\"  # Pad with zero if only one significant digit exists\n",
    "                else:\n",
    "                        first_two = \"00\"  # Handle edge case like 0\n",
    "\n",
    "                # Combine the leading zeros and the first two non-zero digits\n",
    "                return \"\".join(leading_part) + first_two\n",
    "\n",
    "        # Case 2: If the number is greater than or equal to 1\n",
    "        else:\n",
    "                # Format to two decimal places\n",
    "                return f\"{number:.2f}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_to_log_uncertainty(x, delta_x):\n",
    "    if x == 0:\n",
    "        return np.nan   # or 0, depending on what makes sense\n",
    "    return delta_x / (x * np.log(10))\n",
    "\n",
    "def log_to_linear_uncertainty(logx, delta_logx):\n",
    "    \"\"\"Convert log10 uncertainty Δlogx back to linear uncertainty Δx.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    logx : float or array\n",
    "        Value in log10-space.\n",
    "    delta_logx : float or array\n",
    "        Uncertainty in log10(x).\n",
    "    \"\"\"\n",
    "    x = 10**logx\n",
    "    return x * np.log(10) * delta_logx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spectral Plots\n",
    "import matplotlib.pyplot as pylab\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import matplotlib.cm as cmx\n",
    "import math\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import copy\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "def round_down_to_tenth_integer(num):\n",
    "    return math.floor(num * 10) / 10\n",
    "\n",
    "def round_up_to_tenth_integer(num):\n",
    "    return math.ceil(num * 10) / 10\n",
    "\n",
    "msize=10\n",
    "\n",
    "path = f'SpectraGraphs'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "freqs=[]\n",
    "fluxs=[]\n",
    "beams=[]\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    jfin=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        jfin=jfin+1 \n",
    "\n",
    "grouped_data = {}\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    for line in infile:\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        \n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "\n",
    "        j=j+1\n",
    "        \n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "\n",
    "        nobeam=0\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            beam='NA'\n",
    "            nobeam=1\n",
    "\n",
    "\n",
    "        if source not in grouped_data:\n",
    "            grouped_data[source] = {\n",
    "                'sfreqs': [], 'sfluxs': [], 'sbeams': [], 'sdates': [], \n",
    "                'sfreqs2': [], 'sfluxs2': [], 'sbeams2': [], 'sdates2': [],\n",
    "                'sfiles': [], 'sfiles2': []\n",
    "            }\n",
    "\n",
    "            sbeamsizes=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sdates=[]\n",
    "            sfiles=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "            sdates2=[]\n",
    "            sfiles2=[]\n",
    "\n",
    "        if j==0:\n",
    "            minfreq=freq\n",
    "            maxfreq=freq\n",
    "            minflux=flux\n",
    "            maxflux=flux\n",
    "            if nobeam==0:\n",
    "                minbeam=beam\n",
    "                maxbeam=beam\n",
    "        if j!=0:\n",
    "            if freq>maxfreq:\n",
    "                maxfreq=freq\n",
    "            if freq<minfreq:\n",
    "                minfreq=freq\n",
    "            if flux>maxflux:\n",
    "                maxflux=flux\n",
    "            if flux<minflux:\n",
    "                minflux=flux\n",
    "            if nobeam==0:\n",
    "                if beam>maxbeam:\n",
    "                    maxbeam=beam\n",
    "                if beam<minbeam:\n",
    "                    minbeam=beam\n",
    "\n",
    "minfreqp=round_down_to_half_integer(minfreq)\n",
    "maxfreqp=round_up_to_half_integer(maxfreq)\n",
    "\n",
    "minfluxp=round_down_to_half_integer(minflux)\n",
    "maxfluxp=round_up_to_half_integer(maxflux)\n",
    "\n",
    "minbeamp=round_down_to_half_integer(float(minbeam))\n",
    "maxbeamp=round_up_to_half_integer(float(maxbeam))\n",
    "\n",
    "interval = maxfreqp - minfreqp\n",
    "ten_percent = interval * 0.05\n",
    "minfreq = minfreqp - ten_percent\n",
    "maxfreq = maxfreqp + ten_percent\n",
    "\n",
    "interval = maxfluxp - minfluxp\n",
    "ten_percent = interval * 0.05\n",
    "minflux = minfluxp - ten_percent\n",
    "maxflux = maxfluxp + ten_percent\n",
    "\n",
    "interval = maxbeamp - minbeamp\n",
    "ten_percent = interval * 0.05\n",
    "minbeam = minbeamp - ten_percent\n",
    "maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "\n",
    "x_tick_positions=np.arange(minfreqp, maxfreqp + 0.5 , 0.5)  \n",
    "x_tick_labels = [f\"{pos:.2f}\" for pos in x_tick_positions] \n",
    "\n",
    "y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5, 0.5)  \n",
    "y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  \n",
    "\n",
    "stick_positions = np.arange(minbeamp, maxbeamp + 1, 1)  \n",
    "stick_labels = [f\"{pos:.2f}\" for pos in stick_positions] \n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "\n",
    "sourcedone=[]\n",
    "sources=[]\n",
    "\n",
    "oldsources=[]\n",
    "oldsource='NA'\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    j2=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        j2=j2+1 \n",
    "        line=eval(line)\n",
    "\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "        j=j+1\n",
    "\n",
    "        if j==0:\n",
    "            sbeamsizes=[]\n",
    "            sdates=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            \n",
    "            sfiles=[]\n",
    "            sfiles2=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sdates2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "\n",
    "        sources.append(source)\n",
    "        sources=list(set(sources))\n",
    "\n",
    "        if len(sources)-len(oldsources)!=0 and j!=0:\n",
    "            source=oldsource\n",
    "            sourcedone.append(source)\n",
    "\n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            cm2 = pylab.get_cmap('jet')   \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    if isinstance(size, list):\n",
    "                        size = size[0]\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                flux_vals = [float(f[0]) for f in sfluxs]\n",
    "                unc_vals  = [float(f[1]) for f in sfluxs]\n",
    "\n",
    "                for f, fl, err, c in zip(sfreqs, flux_vals, unc_vals, colors):\n",
    "                    pylab.errorbar(f, fl,\n",
    "                                    yerr=err,\n",
    "                                    fmt='o', color=c,\n",
    "                                    markersize=2, capsize=0)\n",
    "\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeamp, vmax=maxbeamp), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source}',fontsize=20)\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs'):\n",
    "                os.makedirs(f'SpectraGraphs')\n",
    "            if os.path.exists(f'SpectraGraphs/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{nicename}')\n",
    "            pylab.savefig(f'SpectraGraphs/{nicename}', dpi=300)\n",
    "            pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                grouped_data[source]['sfreqs']=sfreqs\n",
    "                grouped_data[source]['sfluxs']=sfluxs\n",
    "                grouped_data[source]['sbeams']=sbeamsizes\n",
    "                grouped_data[source]['sdates']=sdates\n",
    "                grouped_data[source]['sfiles']=sfiles\n",
    "\n",
    "                grouped_data[source]['sfreqs2']=sfreqs2\n",
    "                grouped_data[source]['sfluxs2']=sfluxs2\n",
    "                grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "                grouped_data[source]['sdates2']=sdates2\n",
    "                grouped_data[source]['sfiles2']=sfiles2\n",
    "\n",
    "\n",
    "            sbeamsizes=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sdates=[]\n",
    "\n",
    "            sfiles=[]\n",
    "            sfiles2=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "            sdates2=[]\n",
    "\n",
    "        oldsource=source\n",
    "\n",
    "        flux_upperb=0\n",
    "        if len(str(line[3]).split('*'))>1:\n",
    "            flux_upperb=1\n",
    "\n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        fluxunc=line[6]\n",
    "        if fluxunc!='NA':\n",
    "            fluxunc=float(line[3])/float(line[6])\n",
    "            fluxunc=linear_to_log_uncertainty(float(line[3]),float(fluxunc))\n",
    "        odate=line[4]\n",
    "        filename=line[7]\n",
    "        if odate!='NA':\n",
    "            odate=odate.split('/')\n",
    "            date=float(odate[0]) + (float(odate[1])-1) / 12 + (float(odate[2])-1) / 365\n",
    "        else:\n",
    "            date='NA'\n",
    "\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            beams=line[5].split('-')\n",
    "            beamavg=(float(beams[0])+float(beams[1]))/2\n",
    "            oldbeam=f'{np.log10(float(beams[0]))} - {np.log10(float(beams[1]))}'\n",
    "            beam=[beamavg,oldbeam]\n",
    "\n",
    "        if flux_upperb==0:\n",
    "            sbeamsizes.append(beam)\n",
    "            sfluxs.append([flux,fluxunc])\n",
    "            sfreqs.append(freq)\n",
    "            sdates.append(date)\n",
    "            sfiles.append(filename)\n",
    "            \n",
    "\n",
    "        if flux_upperb==1:\n",
    "            sbeamsizes2.append(beam)\n",
    "            sfluxs2.append(flux)\n",
    "            sfreqs2.append(freq)\n",
    "            sdates2.append(date)\n",
    "            sfiles2.append(filename)\n",
    "\n",
    "        oldsources=copy.deepcopy(sources)\n",
    "\n",
    "        if j2==jfin:\n",
    "            source=line[0]\n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            cm2 = pylab.get_cmap('jet')   \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    if isinstance(size, list):\n",
    "                        size = size[0]\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source}',fontsize=20)\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs'):\n",
    "                os.makedirs('SpectraGraphs')\n",
    "            if os.path.exists(f'SpectraGraphs/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{nicename}')\n",
    "            pylab.savefig(f'SpectraGraphs/{nicename}', dpi=300)\n",
    "            pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                grouped_data[source]['sfreqs']=sfreqs\n",
    "                grouped_data[source]['sfluxs']=sfluxs\n",
    "                grouped_data[source]['sbeams']=sbeamsizes\n",
    "                grouped_data[source]['sdates']=sdates\n",
    "                grouped_data[source]['sfiles']=sfiles\n",
    "\n",
    "                grouped_data[source]['sfreqs2']=sfreqs2\n",
    "                grouped_data[source]['sfluxs2']=sfluxs2\n",
    "                grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "                grouped_data[source]['sdates2']=sdates2\n",
    "                grouped_data[source]['sfiles2']=sfiles2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functino to Group frequencies dynamically\n",
    "def group_by_frequency(freqs, fluxes, beams, dates, tolerance):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    current_group_freqs, current_group_fluxes, current_group_beams, current_group_dates = [], [], [], []\n",
    "\n",
    "    sorted_data = sorted(zip(freqs, fluxes, beams, dates), key=lambda x: x[0])\n",
    "    for freq, flux, beam, date in sorted_data:\n",
    "        if not current_group_freqs or abs(freq - current_group_freqs[0]) <= tolerance:\n",
    "            current_group_freqs.append(freq)\n",
    "            current_group_fluxes.append(flux)\n",
    "            current_group_beams.append(beam)\n",
    "            current_group_dates.append(date)\n",
    "        else:\n",
    "            grouped_freqs.append(current_group_freqs)\n",
    "            grouped_fluxes.append(current_group_fluxes)\n",
    "            grouped_beams.append(current_group_beams)\n",
    "            grouped_dates.append(current_group_dates)\n",
    "            current_group_freqs = [freq]\n",
    "            current_group_fluxes = [flux]\n",
    "            current_group_beams = [beam]\n",
    "            current_group_dates = [date]\n",
    "\n",
    "    if current_group_freqs:\n",
    "        grouped_freqs.append(current_group_freqs)\n",
    "        grouped_fluxes.append(current_group_fluxes)\n",
    "        grouped_beams.append(current_group_beams)\n",
    "        grouped_dates.append(current_group_dates)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define frequency ranges for VLA and ALMA bands\n",
    "vla_bands = [\n",
    "    (0.0,0.054) ,     #for Rounding \n",
    "    (0.054, 0.086),  # 4 Band\n",
    "    (0.230, 0.470),  # P Band\n",
    "    (1, 2),          # L Band\n",
    "    (2, 4),          # S Band\n",
    "    (4, 8),          # C Band\n",
    "    (8, 12),         # X Band\n",
    "    (12, 18),        # Ku Band\n",
    "    (18, 26.5),      # K Band\n",
    "    (26.5, 40),      # Ka Band\n",
    "    (40, 50),        # Q Band\n",
    "]\n",
    "\n",
    "alma_bands = [\n",
    "    (31.3, 45),   # Band 1\n",
    "    (67, 90),     # Band 2\n",
    "    (84, 116),    # Band 3\n",
    "    (125, 163),   # Band 4\n",
    "    (163, 211),   # Band 5\n",
    "    (211, 275),   # Band 6\n",
    "    (275, 373),   # Band 7\n",
    "    (385, 500),   # Band 8\n",
    "    (602, 720),   # Band 9\n",
    "    (787, 950),   # Band 10\n",
    "]\n",
    "\n",
    "allfluxs=[]\n",
    "\n",
    "# Combine all boundaries and create continuous intervals\n",
    "all_boundaries = sorted(set([freq for band in vla_bands + alma_bands for freq in band]))\n",
    "non_overlapping_intervals = [(all_boundaries[i], all_boundaries[i + 1]) for i in range(len(all_boundaries) - 1)]\n",
    "\n",
    "# Remove gaps by ensuring no holes\n",
    "continuous_intervals = []\n",
    "for i, (start, end) in enumerate(non_overlapping_intervals):\n",
    "    if i > 0 and start > continuous_intervals[-1][1]:\n",
    "        # Fill the gap between the previous interval and the current one\n",
    "        continuous_intervals.append((continuous_intervals[-1][1], start))\n",
    "    continuous_intervals.append((start, end))\n",
    "\n",
    "# Function to check if a frequency is in any interval\n",
    "def is_frequency_in_intervals(frequency, intervals):\n",
    "    for start, end in intervals:\n",
    "        if start <= frequency < end:  # Check if frequency is in the interval\n",
    "            return True, (start, end)\n",
    "    return False, None\n",
    "\n",
    "# Print all intervals for verification\n",
    "print(\"\\nAll continuous intervals:\")\n",
    "for i, interval in enumerate(continuous_intervals):\n",
    "    print(f\"Interval {i + 1}: {interval[0]}–{interval[1]} GHz\")\n",
    "\n",
    "def group_by_band(freqs, fluxes, beams, dates, intervals):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    interval_mapping = {interval: ([], [], [], []) for interval in intervals}\n",
    "\n",
    "    for freq, flux, beam, date in zip(freqs, fluxes, beams, dates):\n",
    "        found, assigned_interval = is_frequency_in_intervals(freq, intervals)\n",
    "        if found:\n",
    "            interval_mapping[assigned_interval][0].append(freq)\n",
    "            interval_mapping[assigned_interval][1].append(flux)\n",
    "            interval_mapping[assigned_interval][2].append(beam)\n",
    "            interval_mapping[assigned_interval][3].append(date)\n",
    "\n",
    "    for interval, (freq_list, flux_list, beam_list, date_list) in interval_mapping.items():\n",
    "        if freq_list:\n",
    "            grouped_freqs.append(freq_list)\n",
    "            grouped_fluxes.append(flux_list)\n",
    "            grouped_beams.append(beam_list)\n",
    "            grouped_dates.append(date_list)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Statistical Spectral Plots\n",
    "# Define tolerance for grouping frequencies (log space)\n",
    "tolerance = .05\n",
    "\n",
    "#define if it should be grouped dynamicall or by band\n",
    "grouper='byband'\n",
    "#grouper='bydynam'\n",
    "\n",
    "# Generate consistent x-axis and y-axis tick positions\n",
    "x_tick_positions = np.linspace(minfreq, maxfreq, num=6)  \n",
    "x_tick_labels = [f\"{10**pos:.2f}\" for pos in x_tick_positions]  \n",
    "\n",
    "y_tick_positions = np.linspace(minflux, maxflux, num=6) \n",
    "y_tick_labels = [f\"{10**pos:.2f}\" for pos in y_tick_positions]  \n",
    "\n",
    "# Apply grouping to all sources\n",
    "for source, data in grouped_data.items():\n",
    "    if grouper=='bydynam':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_frequency(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'],data['sdates'],tolerance\n",
    "        )\n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_frequency(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'],tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_band(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'], continuous_intervals\n",
    "        )\n",
    "        \n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_band(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'], continuous_intervals\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize combined arrays\n",
    "combined_freqs = []  # Combined frequencies\n",
    "combined_fluxes = []  # Combined fluxes\n",
    "combined_beams = []  # Combined beam sizes\n",
    "\n",
    "for source, data in grouped_data.items():\n",
    "    # Combine all frequency, flux, and beam data for the current source\n",
    "    combined_freqs = data['sfreqs'] \n",
    "    combined_fluxes = data['sfluxs'] \n",
    "    combined_fluxes = [float(f[0]) for f in combined_fluxes ]\n",
    "    combined_beams = data['sbeams'] \n",
    "    combined_dates = data['sdates'] \n",
    "\n",
    "    combined_freqs_2 = data['sfreqs2']\n",
    "    combined_fluxes_2 = data['sfluxs2'] \n",
    "    combined_beams_2 = data['sbeams2'] \n",
    "    combined_dates_2 = data['sdates2'] \n",
    "\n",
    "    # Group the combined data dynamically for the current source\n",
    "    if grouper=='bydynam':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_frequency(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_band(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, continuous_intervals\n",
    "        )\n",
    "\n",
    "    # Iterate over grouped combined data\n",
    "    for freq_group, flux_group, beam_group in zip(grouped_freqs, grouped_fluxes, grouped_beams):\n",
    "        #unc_group  = [float(f[1]) for f in flux_group]\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        if group_size >= 4:\n",
    "            pylab.boxplot(flux_group, positions=[central_freq],widths=0.1,\n",
    "            showfliers=False)  # Customize outliers\n",
    "        elif group_size == 3:\n",
    "            # Vertical line with caps at min and max\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = np.median(flux_group)\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5,  # Length of caps\n",
    "                color='k'\n",
    "            )\n",
    "            # Add a horizontal line at the median_flux\n",
    "            pylab.hlines(\n",
    "                y=median_flux,  # Position of the horizontal line\n",
    "                xmin=central_freq - 0.05,  # Adjust as needed for length\n",
    "                xmax=central_freq + 0.05, \n",
    "                color='r',  # Color of the line\n",
    "                linewidth=1  # Thickness of the horizontal line\n",
    "            )\n",
    "        elif group_size == 2:\n",
    "            # Vertical line with caps at min and max (no median)\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = (min_flux + max_flux) / 2  # Just for centering the line\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5, \n",
    "                color='k'\n",
    "            )\n",
    "\n",
    "        elif group_size == 1:\n",
    "            pylab.scatter([central_freq], [flux_group[0]], c='b', marker='o', s=10)\n",
    "\n",
    "    if combined_fluxes_2:  # Ensure '2' fluxes exist\n",
    "        if not combined_fluxes or min(combined_fluxes_2) < min(combined_fluxes):\n",
    "            # If main fluxes are empty OR '2' minimum is lower\n",
    "            min_flux_2 = min(combined_fluxes_2)\n",
    "            min_flux_2_index = combined_fluxes_2.index(min_flux_2)\n",
    "            min_freq_2 = combined_freqs_2[min_flux_2_index]\n",
    "            # Mark the lowest value with a downward triangle\n",
    "            pylab.scatter([min_freq_2], [min_flux_2], c='black', marker='v', s=7, label='Min Flux from 2')\n",
    "\n",
    "\n",
    "    # Set consistent x and y limits for all plots\n",
    "    pylab.xlim(minfreq - 0.1, maxfreq + 0.1)  # Add slight padding\n",
    "    pylab.ylim(minflux - 0.1, maxflux + 0.1)  # Add slight padding\n",
    "    # Set consistent x-axis ticks and labels\n",
    "    # Set consistent x-axis and y-axis ticks and labels\n",
    "    pylab.xticks(x_tick_positions, x_tick_labels)\n",
    "    pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "\n",
    "    # Add labels and title\n",
    "    pylab.xlabel('Frequency [GHz]')\n",
    "    pylab.ylabel(r'Flux [mJy][Beam]$^{-1}$')\n",
    "    pylab.title(f'{source}')\n",
    "\n",
    "    nicename=f'{source} statistical spectra.pdf'\n",
    "    if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "        os.makedirs(f'SpectraGraphs/{source}')\n",
    "    if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "        os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "    pylab.savefig(f'SpectraGraphs/{source}/{nicename}', dpi=300)\n",
    "    pylab.show()\n",
    "    pylab.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make function to get distances\n",
    "\n",
    "import os\n",
    "from astroquery.ned import Ned\n",
    "import ast  # For safely parsing text file data\n",
    "\n",
    "import os\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "from scipy import constants\n",
    "c=constants.c\n",
    "\n",
    "def is_subsequence(small, large):\n",
    "    it = iter(large)\n",
    "    return all(char in it for char in small)\n",
    "\n",
    "def decompose_string(s):\n",
    "    parts = re.findall(r\"[A-Za-z]+|\\d+\", s)  # Finds all letter and number sequences\n",
    "    return parts if parts else [s]\n",
    "\n",
    "# Input file with source names and coordinates\n",
    "txtnamesandcoords = 'namesandcoords.txt'\n",
    "\n",
    "# List of desired reference codes\n",
    "wantrefs = ['2018ApJ...863..', '2023ApJ...948..', '2020ApJ...890..', '2020ApJ...891..']\n",
    "\n",
    "def getdists(newnames):\n",
    "    newrefs=[]\n",
    "    if not os.path.exists('distancetable.csv'):\n",
    "        url = 'https://ned.ipac.caltech.edu/Archive/Distances/NED30.5.1-D-17.1.2-20200415.csv'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open('distancetable.csv', \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            return(f\"Failed to download. Status code: {response.status_code}\")\n",
    "    \n",
    "    maserdist=[]\n",
    "    otherdist=[]\n",
    "    j1=-1\n",
    "    j2=-1\n",
    "    with open('distancetable.csv', \"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            textsource=row[3]\n",
    "            if len(textsource)==0:\n",
    "                continue\n",
    "            textdistmm=row[4]\n",
    "            textdistmmerr=row[5]\n",
    "\n",
    "            textdistMpc=row[6]\n",
    "            textmethod=row[7]\n",
    "            refcode=row[8]\n",
    "\n",
    "\n",
    "            textsource=textsource.replace(' ','')\n",
    "\n",
    "            findred=0\n",
    "            for i in newnames:\n",
    "                checkers=[]\n",
    "                for ii in i:\n",
    "                    ii=ii.split('Galaxy')[0]\n",
    "                    if is_subsequence(ii, textsource):\n",
    "                        checkers.append(ii)\n",
    "                if len(checkers)==len(i):\n",
    "                    if row[10]:\n",
    "                        findred=1\n",
    "                        redshift=row[10]\n",
    "                        Hubble=row[11]\n",
    "                        newdist=c*float(redshift)/float(Hubble)*c\n",
    "                    \n",
    "                    if textdistmmerr:\n",
    "                        if float(textdistmmerr)>0:\n",
    "                            if 'maser' in textmethod.lower():\n",
    "                                j1=j1+1\n",
    "                                newrefs.append(refcode)\n",
    "                                if j1==0:\n",
    "                                        maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                        maserdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<maserdisuncer:\n",
    "                                    maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                            else:\n",
    "                                j2=j2+1\n",
    "                                if j2==0:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                    otherdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<otherdisuncer:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "\n",
    "    return(maserdist,otherdist,refcode,findred,newrefs)\n",
    "\n",
    "# Function to process each source\n",
    "def process_source(source_name, wantrefs, ra, dec,threshold, secondarynames):\n",
    "  \n",
    "    \"\"\"Query NED for redshift data and filter based on references and uncertainties.\"\"\"\n",
    "    # Skip excluded sources\n",
    "\n",
    "    # Query the redshift table from NED\n",
    "    distances_table = Ned.get_table(source_name, table='redshifts')\n",
    "\n",
    "    # Extract relevant columns\n",
    "    redshifts = distances_table['Published Redshift']\n",
    "    uncertainties = distances_table['Published Redshift Uncertainty']\n",
    "    refcodes = distances_table['Refcode']\n",
    "\n",
    "    # Combine into tuples\n",
    "    entries = [\n",
    "        (redshift, uncertainty, refcode)\n",
    "        for redshift, uncertainty, refcode in zip(redshifts, uncertainties, refcodes)\n",
    "    ]\n",
    "\n",
    "    # Filter for entries with desired references\n",
    "    desired_entries = [\n",
    "        entry for entry in entries if any(ref in entry[2] for ref in wantrefs)\n",
    "    ]\n",
    "\n",
    "    entries_with_reference = []\n",
    "    entries_without_reference = []\n",
    "\n",
    "    for redshift, uncertainty, refcode in desired_entries:\n",
    "        if any(ref in refcode for ref in wantrefs):  # Check if refcode contains a wanted reference\n",
    "            entries_with_reference.append((redshift, uncertainty, refcode))\n",
    "        else:\n",
    "            entries_without_reference.append((redshift, uncertainty, refcode))\n",
    "\n",
    "\n",
    "    reduced_entries = {}\n",
    "\n",
    "    # Step 2a: Prioritize entries from `entries_with_reference`\n",
    "    if entries_with_reference:\n",
    "        for redshift, uncertainty, refcode in entries_with_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "    if len(reduced_entries)==0:\n",
    "        # Step 2b: If `entries_with_reference` is empty, use `entries_without_reference`\n",
    "        for redshift, uncertainty, refcode in entries_without_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "\n",
    "\n",
    "    # Print results based on the filtering\n",
    "    redshift='NA'\n",
    "    uncertainty='NA'\n",
    "\n",
    "    newnames=[]\n",
    "    newlist=decompose_string(secondarynames[0][0])\n",
    "\n",
    "    newnames.append(newlist)\n",
    "    if len(secondarynames[0][1])!=0:\n",
    "        if secondarynames[0][1][0]!='NA':\n",
    "            for i in secondarynames[0][1]:\n",
    "                if not is_subsequence(secondarynames[0][0], i):\n",
    "                    newlist=decompose_string(i)\n",
    "                    newnames.append(newlist)\n",
    "\n",
    "    maserdists, otherdists, inewrefs, findred, newrefs = getdists(newnames)\n",
    "\n",
    "    if reduced_entries:\n",
    "        for irefcode, (iredshift, iuncertainty) in reduced_entries.items():\n",
    "            redshift=iredshift\n",
    "            ynfindref='y'\n",
    "            refcode=irefcode\n",
    "            if iuncertainty>0:\n",
    "                uncertainty=iuncertainty\n",
    "            else:\n",
    "                input(f'No uncertainty for chosen referencecode: {refcode} , {source}')\n",
    "                uncertainty='NA'\n",
    "    else:\n",
    "\n",
    "        # If no desired references, and no maser distances, find valid entries with uncertainties\n",
    "        valid_entries = [entry for entry in entries if entry[1] > 0]\n",
    "        if valid_entries:\n",
    "            # Select the entry with the lowest uncertainty\n",
    "            lowest_uncertainty_entry = min(valid_entries, key=lambda x: x[1])\n",
    "            lowest_redshift, lowest_uncertainty, reference_code = lowest_uncertainty_entry\n",
    "            redshift=lowest_redshift\n",
    "            uncertainty= lowest_uncertainty\n",
    "            refcode=reference_code\n",
    "            ynfindref='n'\n",
    "        else:\n",
    "            input(f\"No valid redshift entries found for {source_name} (1)\\n\")\n",
    "        if len(maserdists)!=0:\n",
    "            z_observed = redshift\n",
    "            if z_observed >= threshold:\n",
    "                if len(maserdists)!=0 and findred==1:\n",
    "                        input('new maser source found... adjust accordingly (1)')\n",
    "        \n",
    "    z_observed = redshift\n",
    "    z_uncer=uncertainty\n",
    "\n",
    "    if z_observed <= threshold:\n",
    "        if len(maserdists)!=0:\n",
    "            input('new maser source found... adjust accordingly (2)')\n",
    "        if len(maserdists)==0:\n",
    "            textdistmm=float(otherdists[1])\n",
    "            textdistmmerr=float(otherdists[2])\n",
    "            textdistMpc=float(otherdists[3])\n",
    "\n",
    "            newdist=10**((textdistmm)/5-5)\n",
    "            newdist_uncer=np.log(10)/5*newdist*textdistmmerr\n",
    "            textmethod=otherdists[4]\n",
    "            refcode=otherdists[5]\n",
    "\n",
    "            return([newdist,newdist_uncer],textmethod,'NA',refcode,'DISTANCE',newrefs)\n",
    "\n",
    "    # Calculate heliocentric velocity\n",
    "    c = 299792.458  # Speed of light in km/s\n",
    "    v_helio = z_observed * c\n",
    "    v_helio_uncer = z_uncer * c\n",
    "\n",
    "    #Hubble Constant\n",
    "    #Pesce, APJ 891:L1\n",
    "    H = 73.9\n",
    "    H_uncer = 3\n",
    "    dist=v_helio/H\n",
    "    dist_uncer=np.sqrt((v_helio_uncer/H)**2 + (v_helio/H**2*H_uncer)**2)\n",
    "\n",
    "    return([dist,dist_uncer],'NA',ynfindref,refcode,'REDSHIFT', newrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on local computer to SMBH mass\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parent\n",
    "Greenepath=f'{parent_dir}/CountingBHS_and_Spectra/Greene_params/Greene_params.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date format\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def decimal_year_to_date(decimal_year):\n",
    "    if decimal_year == 'NA':\n",
    "        return 'NA'\n",
    "\n",
    "    year = int(decimal_year)\n",
    "    yearremainder = decimal_year - year\n",
    "\n",
    "    # First extract the month\n",
    "    decmonth = yearremainder * 12 + 1\n",
    "    month = int(decmonth)\n",
    "    monthremainder = decmonth - month\n",
    "\n",
    "    day = int(round(monthremainder/12*365+1))\n",
    "\n",
    "\n",
    "    return f\"{year}/{month:02}/{day:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get SMBH size\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "def getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc):\n",
    "    mass=10**float(log_BH_mass_solar)*mass_sun\n",
    "    mass_unc=mass*np.log(10)*float(log_BH_mass_solar_uncer)\n",
    "    mass_fracerror=(mass_unc/mass)*100\n",
    "\n",
    "    distance=distanceMPc*pc*10**6\n",
    "    distance_uncer=distanceMPc_uncer*pc*10**6\n",
    "    dist_fracerror=(distance_uncer/distance)*100\n",
    "    \n",
    "    if arcsectopc=='NA':\n",
    "        m_d=mass/distance\n",
    "        m_d_unc=np.sqrt((m_d/mass*mass_unc)**2+(m_d/distance*distance_uncer)**2)\n",
    "        m_d_fracerror=(m_d_unc/m_d)*100\n",
    "        diam_bhs_microarcsec_fracerror = m_d_fracerror\n",
    "\n",
    "        diam_bhs_rad=2*np.sqrt(27)*G/(c**2)*m_d\n",
    "        diam_bhs_deg=diam_bhs_rad*360/(2*pi)\n",
    "        diam_bhs_arcsec=diam_bhs_deg*60*60\n",
    "        diam_bhs_microarcsec=diam_bhs_arcsec*10**6\n",
    "\n",
    "        diam_bhs_microarcsec_unc=diam_bhs_microarcsec/(m_d)*m_d_unc\n",
    "\n",
    "\n",
    "        return(log_BH_mass_solar, log_BH_mass_solar_uncer, mass_fracerror, distanceMPc, distanceMPc_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "        \n",
    "    diam_bhs=2*np.sqrt(27)*G/(c**2)*mass\n",
    "    diam_bhs_unc = 2*np.sqrt(27)*G/(c**2)*mass_unc\n",
    "    \n",
    "    diam_bhspc=diam_bhs/pc\n",
    "    diam_bhspc_unc=diam_bhs_unc/pc\n",
    "\n",
    "    diam_bhs_arsec=diam_bhspc/arcsectopc\n",
    "    diam_bhs_microarcsec=diam_bhs_arsec*10**6\n",
    "\n",
    "    diam_bhs_arsec_unc=np.sqrt((diam_bhspc_unc/arcsectopc)**2\n",
    "                               + ((-1)*diam_bhspc/arcsectopc**2*arcsectopc_unc)**2\n",
    "                               )\n",
    "    \n",
    "    diam_bhs_microarcsec_unc=diam_bhs_arsec_unc*10**6\n",
    "    diam_bhs_microarcsec_fracerror = (diam_bhs_microarcsec_unc/diam_bhs_microarcsec)*100\n",
    "\n",
    "    return(mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "sagmass=6.6\n",
    "sagmass_unc_up=.12\n",
    "sagmass_unc_down=.07\n",
    "sagdist=8.15*10**(-3)\n",
    "sagdist_unc=.15*10**(-3)\n",
    "\n",
    "distanceMPc=sagdist\n",
    "distanceMPc_uncer=sagdist_unc\n",
    "\n",
    "log_BH_mass_solar=sagmass\n",
    "log_BH_mass_solar_uncerup=sagmass_unc_up\n",
    "log_BH_mass_solar_uncerdown=sagmass_unc_down\n",
    "\n",
    "mass, mass_uncup, mass_fracerrorup, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(sagmass,sagmass_unc_up,sagdist,sagdist_unc,'NA','NA')\n",
    "mass, mass_uncdown, mass_fracerrordown, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(sagmass,sagmass_unc_down,sagdist,sagdist_unc,'NA','NA')\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'SagA*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} ± {format_number(distanceMPc_uncer)} MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "log_BH_mass_solar_uncerup=format_number(float(log_BH_mass_solar_uncerup))\n",
    "log_BH_mass_solar_uncerdown=format_number(float(log_BH_mass_solar_uncerdown))\n",
    "mass_fracerror=(mass_fracerrorup+mass_fracerrordown)/2\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} $^{{+{log_BH_mass_solar_uncerup}}}_{{-{log_BH_mass_solar_uncerdown}}}$ log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles1=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "fig, ax = pylab.subplots(dpi=300)\n",
    "\n",
    "m87mass=9.81\n",
    "m87mass_unc=0.06\n",
    "m87dist=16.8\n",
    "m87dist_uncup=.8\n",
    "m87dist_uncdown=.7\n",
    "\n",
    "distanceMPc=m87dist\n",
    "distanceMPc_uncerup=m87dist_uncup\n",
    "distanceMPc_uncerdown=m87dist_uncdown\n",
    "\n",
    "log_BH_mass_solar=m87mass\n",
    "log_BH_mass_solar_uncer=m87mass_unc\n",
    "\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerup, dist_fracerrorup, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncup,'NA','NA')\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerdown, dist_fracerrordown, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncdown,'NA','NA')\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'M87*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "dist_fracerror=(distanceMPc_uncerup+distanceMPc_uncerdown)/2\n",
    "distanceMPc_uncerup=format_number(float(distanceMPc_uncerup))\n",
    "distanceMPc_uncerdown=format_number(float(distanceMPc_uncerdown))\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} $^{{+{distanceMPc_uncerup}}}_{{-{distanceMPc_uncerdown}}}$ MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} ±{log_BH_mass_solar_uncerdown} log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles2=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "legend1=ax.legend(handles=handles2, loc='upper center')   \n",
    "ax.add_artist(legend1)\n",
    "ax.legend(handles=handles1, loc='lower center')   \n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xticks([])  # Remove x-axis ticks\n",
    "ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "# Remove tick labels\n",
    "ax.set_xticklabels([])  # Remove x-axis labels\n",
    "ax.set_yticklabels([])  # Remove y-axis labels\n",
    "if not os.path.exists('Extras'):\n",
    "    os.makedirs('Extras')\n",
    "pylab.savefig(f'Extras/SMBH of SagA* and M87')\n",
    "pylab.clf() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print All Correlations\n",
    "write=True\n",
    "#write=False\n",
    "printall=True\n",
    "#colorbarvar='time'\n",
    "#for variability avg val is flux and for compactness it is beam\n",
    "#Actually it will give the lower value\n",
    "colorbarvar='avgval'\n",
    "\n",
    "def percentage_difference(x, y):\n",
    "    return (x - y) / ((x + y) / 2) * 100\n",
    "\n",
    "def percentage_difference_unc(x, y, x_unc, y_unc):\n",
    "    \n",
    "    term1 = 4*y/(x+y)**2 * x_unc * 100\n",
    "    term2 = 4*x/(x+y)**2 * y_unc * 100\n",
    "\n",
    "    return np.sqrt(term1**2 + term2**2)\n",
    "\n",
    "import ast\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "import sys\n",
    "import matplotlib.pyplot as pylab\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "allfluxs=[]\n",
    "\n",
    "def format_val(val):\n",
    "    if val==0:\n",
    "        return '0'\n",
    "    if np.isnan(val):\n",
    "        return np.nan\n",
    "    places = max(1,  -int(math.floor(math.log10(abs(val))))+1) \n",
    "    #return f'{val:.{places}f}'\n",
    "    if val >1:\n",
    "        val=f'{val:.1f}' \n",
    "    elif val >0.1:\n",
    "        val=f'{val:.2f}' \n",
    "    elif val >0.01:\n",
    "        val=f'{val:.3f}'\n",
    "    elif val >0.001:\n",
    "        val=f'{val:.4f}'\n",
    "    else:\n",
    "        val=f\"{val:.{places}f}\"\n",
    "    return val\n",
    "\n",
    "def format_val2(val):\n",
    "    if val==0:\n",
    "        return '0'\n",
    "    if val<0.1:\n",
    "        val=f'{val:.4f}'\n",
    "    elif val<1:\n",
    "        val=f'{val:.3f}'\n",
    "    elif val<10:\n",
    "        val=f'{val:.2f}'\n",
    "    elif val<100:\n",
    "        val=f'{val:.1f}'\n",
    "    else:\n",
    "        input(f'problem with beam {val}')\n",
    "    return val\n",
    "\n",
    "cm2 = pylab.get_cmap('jet')  \n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "c=constants.c\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "txtnamesandcoords='namesandcoords.txt'\n",
    "path='Beam Mismatch'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "spacings=[13, 8, 8, 10, 9, 9, 10, 10, 10, 15, 15, 15, 10]\n",
    "tot = 0\n",
    "for i in spacings:\n",
    "    tot=tot+i\n",
    "source='target'\n",
    "\n",
    "sfreqs1='freq1'\n",
    "sfreqs2='freq2'\n",
    "freqper='[sep %]'\n",
    "\n",
    "sbeams1='beam1'\n",
    "sbeams2='beam2'\n",
    "beamper='[sep %]'\n",
    "\n",
    "sfluxes1='flux1'\n",
    "sfluxes2='flux2'\n",
    "fluxper='[sep %]'\n",
    "\n",
    "sdates1='year1'\n",
    "sdates2='year2'\n",
    "datesep='[sep yrs]'\n",
    "\n",
    "if printall==True:\n",
    "    corr_table='machinetables/correlations_machine.txt'\n",
    "\n",
    "with open(corr_table, 'w') as file:\n",
    "    if write==True:\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = file\n",
    "    print(f'{source.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "\n",
    "    newrefs=[]\n",
    "    indextot=-1\n",
    "    for isource, data in grouped_data.items():\n",
    "        if isource!='NGC1194':\n",
    "            #continue\n",
    "            pass\n",
    "        # Main loop to read and process sources from the input file\n",
    "        if os.path.exists(txtnamesandcoords):\n",
    "            with open(txtnamesandcoords, 'r') as infile:\n",
    "                for line in infile:\n",
    "                    # Parse the line into a list of name-coordinate pairs\n",
    "                    params = ast.literal_eval(line)\n",
    "                    for inamecoords in params:              \n",
    "                        source_name = inamecoords[0][0]\n",
    "                        if not isource.lower() in source_name.lower():\n",
    "                            continue\n",
    "                        source=source_name\n",
    "                        if source=='CircinusGalaxy':\n",
    "                            source='Circinus'    \n",
    "                        ra = inamecoords[1][1]\n",
    "                        dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                        findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                        distanceMPc=findvals[0][0]\n",
    "                        distanceMPc_uncer=findvals[0][1]\n",
    "                        method=findvals[1]\n",
    "                        ynfindref=findvals[2]\n",
    "                        refcode=findvals[3]\n",
    "                        red_depend=findvals[4]\n",
    "                        if len(findvals[5])!=0:\n",
    "                            for i in findvals[5]:\n",
    "                                newrefs.append(i)\n",
    "        else:\n",
    "            print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "        arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "        arcsectopc=arcsectokpc*1000\n",
    "\n",
    "        arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "        arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "        arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "        distance='NA'\n",
    "        with open(Greenepath, 'r') as infile:\n",
    "            j=-1\n",
    "            breaker=1\n",
    "            for line in infile:\n",
    "                j=j+1\n",
    "                if j>20:\n",
    "                    continue\n",
    "                source_name=line.split(' ')[0]\n",
    "                source_name=source_name.replace(\"−\",\"-\")\n",
    "                if \"WISEA\" in isource:\n",
    "                    isource=isource.split(\"WISEA\")[0]\n",
    "                if isource.lower() in source_name.lower():\n",
    "                    log_BH_mass_solar=line.split(' ')[3]\n",
    "                    log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                    breaker=0\n",
    "            if breaker!=1:\n",
    "                mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "\n",
    "        # Filter out elements where date == 'NA'\n",
    "        valid_sfreqs = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'])]\n",
    "        valid_sfreqs2 = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'])]\n",
    "\n",
    "        # Combine all valid data for grouping\n",
    "        combined_data = valid_sfreqs + valid_sfreqs2\n",
    "        \n",
    "        # Unpack valid data\n",
    "        if combined_data:\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates = zip(*combined_data)\n",
    "        else:\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates = [], [], [], []\n",
    "\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [list(combined_freqs)], [list(combined_fluxes)], [list(combined_beams)], [list(combined_dates)]\n",
    "\n",
    "        #print(grouped_fluxes)\n",
    "        # Iterate through frequency groups and create separate plots\n",
    "        donefreq=[]\n",
    "\n",
    "        filtered_freqs='NA'\n",
    "\n",
    "        for freq_group, flux_group, beam_group, date_group in zip(grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates):\n",
    "            if len(date_group) > 0 and len(flux_group) > 0:  # Only plot if there are valid points  \n",
    "\n",
    "                new_valid=[]\n",
    "    \n",
    "                for ivalid_sfreqs in valid_sfreqs:\n",
    "                    ivalid_sfreqs=list(ivalid_sfreqs)\n",
    "                    ivalid_sfreqs.append('detect')\n",
    "                    ivalid_sfreqs=tuple(ivalid_sfreqs)\n",
    "                    new_valid.append(ivalid_sfreqs)\n",
    "\n",
    "                for ivalid_sfreqs in valid_sfreqs2:\n",
    "                    ivalid_sfreqs=list(ivalid_sfreqs)\n",
    "                    ivalid_sfreqs.append('nodetect')\n",
    "                    ivalid_sfreqs=tuple(ivalid_sfreqs)\n",
    "                    new_valid.append(ivalid_sfreqs)\n",
    "\n",
    "\n",
    "                #for valid_data in new_valid:\n",
    "                #for valid_data in [\n",
    "                #    (valid_sfreqs)\n",
    "                #]:  \n",
    "                    #filtered_points = [(d, fl, b, f) for f, fl, b, d in valid_data if f in freq_group]\n",
    "\n",
    "\n",
    "                for valid_data in [new_valid]:\n",
    "                    filtered_points = [(d, fl, b, f, detect) for f, fl, b, d, detect in valid_data if f in freq_group]\n",
    "                    if filtered_points:\n",
    "\n",
    "                        filtered_dates, filtered_fluxes, filtered_beams, filtered_freqs, detect = zip(*filtered_points)\n",
    "\n",
    "                        #filtered_dates, filtered_fluxes, filtered_beams, filtered_freqs = zip(*filtered_points)\n",
    "                        \n",
    "                        #for getting into MPc values\n",
    "                        #filtered_beams = np.array(filtered_beams)\n",
    "                        #filtered_beams = 10**filtered_beams\n",
    "                        #filtered_beams = filtered_beams * (np.pi / (180 * 3600))\n",
    "                        #filtered_beams = filtered_beams * distanceMPc * 1000\n",
    "                        #filtered_beams = np.log10(filtered_beams)\n",
    "                        #filtered_beams = filtered_beams.tolist()\n",
    "\n",
    "                        #filtered_fluxes=10**np.array(filtered_fluxes) * (np.pi / (180 * 3600)) * distanceMPc * 1000\n",
    "                        #filtered_fluxes=filtered_fluxes.tolist()\n",
    "\n",
    "                # Assuming filtered_freqs is already defined and is a list or array\n",
    "                n = len(filtered_freqs)\n",
    "\n",
    "                freq_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                avgfreqij = np.full((n, n), np.nan, dtype=object)\n",
    "                beam_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                avgbeamij = np.full((n, n), np.nan, dtype=object)\n",
    "                flux_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                avgfluxij = np.full((n, n), np.nan, dtype=object)\n",
    "                date_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                detect_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "\n",
    "                for i in range(len(filtered_freqs)):\n",
    "                    for j in range(i + 1, len(filtered_freqs)):\n",
    "                        keep=1\n",
    "                        if detect[i]=='nodetect' and detect[j]=='nodetect':\n",
    "                            keep=0\n",
    "                        elif detect[i]=='nodetect':\n",
    "                            if filtered_fluxes[i]> filtered_fluxes[j][0]:\n",
    "                                keep=0\n",
    "                        elif detect[j]=='nodetect':\n",
    "                            if filtered_fluxes[j] > filtered_fluxes[i][0]:\n",
    "                                keep=0\n",
    "\n",
    "                        if keep==0:\n",
    "                            freq_diffs[i, j] = percentage_difference(10**filtered_freqs[i], 10**filtered_freqs[j])\n",
    "                            avgfreqij[i, j]= (10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "\n",
    "                            if isinstance(filtered_beams[i], list):\n",
    "                                bothi=filtered_beams[i][1].split(' - ')\n",
    "                                beami1=float(bothi[0])\n",
    "                                beami2=float(bothi[1])\n",
    "                                beamdiff1=percentage_difference(beami1, float(filtered_beams[j]))\n",
    "                                beamdiff2=percentage_difference(beami2, float(filtered_beams[j]))\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            elif isinstance(filtered_beams[j], list):\n",
    "                                input(filtered_beams[i])\n",
    "                                bothj=filtered_beams[j][1].split(' - ')\n",
    "                                beamj1=float(bothj[0])\n",
    "                                beamj2=float(bothj[1])\n",
    "                                beamdiff1=percentage_difference(float(filtered_beams[i]), beamj1)\n",
    "                                beamdiff2=percentage_difference(float(filtered_beams[i]), beamj2)\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            else:\n",
    "                                beam_diffs[i, j] = percentage_difference(10**filtered_beams[i], 10**filtered_beams[j])\n",
    "\n",
    "\n",
    "                            if isinstance(filtered_beams[i], list) or isinstance(filtered_beams[j], list):\n",
    "                                avgbeamij[i, j]='NA'\n",
    "                            else:\n",
    "                                if filtered_beams[i] < filtered_beams[j]:\n",
    "                                    avgbeamij[i, j]= 10**filtered_beams[i]\n",
    "                                else:\n",
    "                                    avgbeamij[i, j]= 10**filtered_beams[j]\n",
    "\n",
    "\n",
    "                            flux_diffs[i, j] ='NA'\n",
    "                            avgfluxij[i, j] ='NA'\n",
    "\n",
    "                            if filtered_dates[i]!='NA' and filtered_dates[j]!='NA':\n",
    "                                date_diffs[i, j] = np.abs(filtered_dates[i]-filtered_dates[j])\n",
    "                            else:\n",
    "                                date_diffs[i, j] ='NA'\n",
    "\n",
    "                        if keep==1:\n",
    "                            freq_diffs[i, j] = percentage_difference(10**filtered_freqs[i], 10**filtered_freqs[j])\n",
    "                            avgfreqij[i, j]= (10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "\n",
    "\n",
    "\n",
    "                            if isinstance(filtered_beams[i], list):\n",
    "                                bothi=filtered_beams[i][1].split(' - ')\n",
    "                                beami1=float(bothi[0])\n",
    "                                beami2=float(bothi[1])\n",
    "                                beamdiff1=percentage_difference(beami1, float(filtered_beams[j]))\n",
    "                                beamdiff2=percentage_difference(beami2, float(filtered_beams[j]))\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            elif isinstance(filtered_beams[j], list):\n",
    "                                bothj=filtered_beams[j][1].split(' - ')\n",
    "                                beamj1=float(bothj[0])\n",
    "                                beamj2=float(bothj[1])\n",
    "                                beamdiff1=percentage_difference(float(filtered_beams[i]), beamj1)\n",
    "                                beamdiff2=percentage_difference(float(filtered_beams[i]), beamj2)\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            else:\n",
    "                                beam_diffs[i, j] = percentage_difference(10**filtered_beams[i], 10**filtered_beams[j])\n",
    "\n",
    "                            #avgbeamij[i, j]= (10**filtered_beams[i] + 10**filtered_beams[j])/2\n",
    "                            if isinstance(filtered_beams[i], list) or isinstance(filtered_beams[j], list):\n",
    "                                avgbeamij[i, j]='NA'\n",
    "                            else:\n",
    "                                if filtered_beams[i] < filtered_beams[j]:\n",
    "                                    avgbeamij[i, j]= 10**filtered_beams[i]\n",
    "                                else:\n",
    "                                    avgbeamij[i, j]= 10**filtered_beams[j]\n",
    "                                    \n",
    "                            if isinstance(filtered_fluxes[i], list) and isinstance(filtered_fluxes[j], list):\n",
    "                                flux1=10**filtered_fluxes[i][0]\n",
    "                                flux2=10**filtered_fluxes[j][0]\n",
    "                                flux1_unc=log_to_linear_uncertainty(filtered_fluxes[i][0],filtered_fluxes[i][1])\n",
    "                                flux2_unc=log_to_linear_uncertainty(filtered_fluxes[j][0],filtered_fluxes[j][1])\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2),percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "                            elif isinstance(filtered_fluxes[i], list):\n",
    "                                flux1=10**filtered_fluxes[i][0]\n",
    "                                flux2=10**filtered_fluxes[j]\n",
    "                                flux1_unc=log_to_linear_uncertainty(filtered_fluxes[i][0],filtered_fluxes[i][1])\n",
    "                                flux2_unc=0\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2)+percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "                            elif isinstance(filtered_fluxes[j], list):\n",
    "                                flux1=10**filtered_fluxes[i]\n",
    "                                flux2=10**filtered_fluxes[j][0]\n",
    "                                flux1_unc=0\n",
    "                                flux2_unc=log_to_linear_uncertainty(filtered_fluxes[j][0],filtered_fluxes[j][1])\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2)+percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "\n",
    "                            if filtered_dates[i]!='NA' and filtered_dates[j]!='NA':\n",
    "                                date_diffs[i, j] = np.abs(filtered_dates[i]-filtered_dates[j])\n",
    "                            else:\n",
    "                                date_diffs[i, j] = 'NA'\n",
    "\n",
    "        alldiffs=[]\n",
    "        allfluxavg=[]\n",
    "\n",
    "        allbeams=[]\n",
    "        allbeamavg=[]\n",
    "\n",
    "        allfreqs=[]\n",
    "        alldates=[]\n",
    "\n",
    "        nalldiffs=[]\n",
    "        nallfluxavg=[]\n",
    "\n",
    "        nallbeams=[]\n",
    "        nallbeamavg=[]\n",
    "\n",
    "        nallfreqs=[]   \n",
    "\n",
    "        totnum=-1\n",
    "\n",
    "        if filtered_freqs=='NA':\n",
    "            continue\n",
    "    \n",
    "        for i in range(len(filtered_freqs)):\n",
    "            for j in range(i + 1, len(filtered_freqs)):\n",
    "\n",
    "                totnum += 1\n",
    "                if date_diffs[i, j]=='NA' and colorbarvar=='time':\n",
    "                    nalldiffs.append(flux_diffs[i, j])\n",
    "                    nallfluxavg.append(avgfluxij[i, j])\n",
    "\n",
    "                    nallbeams.append(beam_diffs[i, j])\n",
    "                    nallbeamavg.append(avgbeamij[i, j])\n",
    "\n",
    "                    newfreq=(10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "                    nallfreqs.append(newfreq)\n",
    "\n",
    "                    sfreqs1=10**filtered_freqs[i]\n",
    "                    if sfreqs1<10:\n",
    "                        sfreqs1=f'{sfreqs1:.1f}'\n",
    "                    else:\n",
    "                        sfreqs1=f'{sfreqs1:.0f}'\n",
    "\n",
    "                    sfreqs2=10**filtered_freqs[j]\n",
    "                    if sfreqs2<10:\n",
    "                        sfreqs2=f'{sfreqs2:.1f}'\n",
    "                    else:\n",
    "                        sfreqs2=f'{sfreqs2:.0f}'\n",
    "\n",
    "                    if freq_diffs[i, j]<1:\n",
    "                        freqper='[<1]'\n",
    "                    else:\n",
    "                        freqper='['+format_val(freq_diffs[i, j])+']'\n",
    "\n",
    "                    beam1=10**filtered_beams[i]\n",
    "                    beam2=10**filtered_beams[j]\n",
    "                    sbeams1=format_val2(beam1)\n",
    "                    sbeams2=format_val2(beam2)\n",
    "\n",
    "                    if beam_diffs[i,j]<1:\n",
    "                        beamper='[<1]'\n",
    "                    else:\n",
    "                        beamper='['+format_val(beam_diffs[i, j])+']'\n",
    "\n",
    "                    if detect[i]=='nodetect':\n",
    "                        fluxes1=f'{10**filtered_fluxes[i]:.1f}*'\n",
    "                    else:\n",
    "                        fluxes1=f'{10**filtered_fluxes[i]:.1f}'\n",
    "\n",
    "                    if detect[j]=='nodetect':\n",
    "                        fluxes2=f'{10**filtered_fluxes[j]:.1f}*'\n",
    "                    else:\n",
    "                        fluxes2=f'{10**filtered_fluxes[j]:.1f}'\n",
    "\n",
    "                    sfluxes1=f'{fluxes1}'\n",
    "                    sfluxes2=f'{fluxes2}'\n",
    "                    \n",
    "                    if flux_diffs[i, j] == 'NA':\n",
    "                        fluxper = '[NA]'\n",
    "                    else:\n",
    "                        if flux_diffs[i, j][0]<1:\n",
    "                            fluxper='[<1]'\n",
    "                        else:\n",
    "                            if len(flux_diffs[i, j])==2:\n",
    "                                fluxper='['+format_val(flux_diffs[i, j][0]) + '±' + format_val(flux_diffs[i, j][1]) + ']'\n",
    "                            else:\n",
    "                                fluxper='[>'+format_val(flux_diffs[i, j][0])+']'\n",
    "\n",
    "                    if flux_diffs[i, j]!=0:\n",
    "                        allfluxs.append(flux_diffs[i, j])\n",
    "\n",
    "                    if filtered_dates[i] =='NA' and filtered_dates[j] =='NA':\n",
    "                        sdates1='[NA]'\n",
    "                        sdates2='[NA]'\n",
    "                    elif filtered_dates[i] =='NA':\n",
    "                        sdates1='[NA]'\n",
    "                        sdates2=f'{decimal_year_to_date(filtered_dates[j])}'\n",
    "                    elif filtered_dates[j] =='NA':\n",
    "                        sdates1=f'{decimal_year_to_date(filtered_dates[i])}'\n",
    "                        sdates2='[NA]'\n",
    "                    datesep='[NA]'\n",
    "                    #print(f'{source.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "                else:\n",
    "                    alldiffs.append(flux_diffs[i, j])\n",
    "                    allfluxavg.append(avgfluxij[i, j])\n",
    "\n",
    "                    allbeams.append(beam_diffs[i, j])\n",
    "                    allbeamavg.append(avgbeamij[i, j])\n",
    "\n",
    "                    alldates.append(date_diffs[i, j])\n",
    "                    newfreq=(10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "                    allfreqs.append(newfreq)\n",
    "\n",
    "                    sfreqs1=10**filtered_freqs[i]\n",
    "                    if sfreqs1<10:\n",
    "                        sfreqs1=f'{sfreqs1:.1f}'\n",
    "                    else:\n",
    "                        sfreqs1=f'{sfreqs1:.0f}'\n",
    "\n",
    "                    sfreqs2=10**filtered_freqs[j]\n",
    "                    if sfreqs2<10:\n",
    "                        sfreqs2=f'{sfreqs2:.1f}'\n",
    "                    else:\n",
    "                        sfreqs2=f'{sfreqs2:.0f}'\n",
    "                        \n",
    "                    if freq_diffs[i, j]<1:\n",
    "                        freqper='[<1]'\n",
    "                    else:\n",
    "                        freqper='['+format_val(freq_diffs[i, j])+']'\n",
    "\n",
    "                    if isinstance(filtered_beams[i], list):\n",
    "                        bothi=filtered_beams[i][1].split(' - ')\n",
    "                        beami1=10**float(bothi[0])\n",
    "                        beami2=10**float(bothi[1])\n",
    "                        sbeams1=f\"{format_val2(beami1)}-{format_val2(beami2)}\"\n",
    "                    else:\n",
    "                        beam1=10**filtered_beams[i]\n",
    "                        sbeams1=format_val2(beam1)\n",
    "\n",
    "\n",
    "                    if isinstance(filtered_beams[j], list):\n",
    "                        bothj=filtered_beams[j][1].split(' - ')\n",
    "                        beamj1=10**float(bothj[0])\n",
    "                        beamj2=10**float(bothj[1])\n",
    "                        sbeams2=f\"{format_val2(beamj1)}-{format_val2(beamj2)}\"\n",
    "                    else:\n",
    "                        beam2=10**filtered_beams[j]\n",
    "                        sbeams2=format_val2(beam2)\n",
    "\n",
    "                    if isinstance(beam_diffs[i, j], float):\n",
    "                        if beam_diffs[i, j]<1:\n",
    "                            beamper='[<1]'\n",
    "                        else:\n",
    "                            beamper='['+format_val(beam_diffs[i, j])+']'\n",
    "                    else:\n",
    "                        beamper='[NA]'\n",
    "\n",
    "                    if detect[i]=='nodetect':\n",
    "                        fluxes1=f'{10**filtered_fluxes[i]:.1f}*'\n",
    "                    else:\n",
    "                        fluxes1=f'{10**filtered_fluxes[i][0]:.1f}'\n",
    "\n",
    "                    if detect[j]=='nodetect':\n",
    "                        fluxes2=f'{10**filtered_fluxes[j]:.1f}*'\n",
    "                    else:\n",
    "                        fluxes2=f'{10**filtered_fluxes[j][0]:.1f}'\n",
    "                    sfluxes1=f'{fluxes1}'\n",
    "                    sfluxes2=f'{fluxes2}'\n",
    "\n",
    "                    if flux_diffs[i, j]!=0:\n",
    "                        allfluxs.append(flux_diffs[i, j])\n",
    "\n",
    "                    #print(filtered_dates[i])\n",
    "                    #print(filtered_dates[j])\n",
    "                    sdates1=f'{decimal_year_to_date(filtered_dates[i])}'\n",
    "                    sdates2=f'{decimal_year_to_date(filtered_dates[j])}'\n",
    "                    if date_diffs[i, j]!='NA':\n",
    "                        idate_diffs=f\"{date_diffs[i, j]:.3f}\"\n",
    "                    else:\n",
    "                        idate_diffs='NA'\n",
    "                    datesep=f'['+idate_diffs+']'\n",
    "                    if flux_diffs[i, j] == 'NA':\n",
    "                        fluxper = '[NA]'\n",
    "                    else:\n",
    "                        if flux_diffs[i, j][0]<1:\n",
    "                            fluxper='[<1]'\n",
    "                        else:\n",
    "                            if len(flux_diffs[i, j])==2:\n",
    "                                fluxper='['+format_val(flux_diffs[i, j][0]) + '±' + format_val(flux_diffs[i, j][1]) + ']'\n",
    "                            else:\n",
    "                                fluxper='[>'+format_val(flux_diffs[i, j][0])+']'\n",
    "                    '''\n",
    "                    print(sfreqs1)\n",
    "                    print(sfreqs2)\n",
    "                    print(freqper)\n",
    "                    print(sbeams1)\n",
    "                    print(sbeams2)\n",
    "                    print(beamper)\n",
    "                    print(sfluxes1)\n",
    "                    print(sfluxes2)\n",
    "                    print(fluxper)\n",
    "                    print(sdates1)\n",
    "                    print(sdates2)  \n",
    "                    print(datesep)\n",
    "                    '''\n",
    "                    sbeams2=format_val2(beam2)\n",
    "        \n",
    "                if printall==True:\n",
    "                    indextot+=1 \n",
    "                    print(f'{isource.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "\n",
    "    if write==True:\n",
    "        sys.stdout = original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Limits for Variability Search\n",
    "\n",
    "import os\n",
    "\n",
    "freqtot=[0,1000]\n",
    "\n",
    "#flux_diff_threshold = 0  \n",
    "freq_sim_threshold = 1.4  # frequency differences less than 5%\n",
    "beam_sim_threshold = 2.6  # beam size differences less than 5%\n",
    "freqthresh=True\n",
    "beamthresh=True\n",
    "fluxthresh=False\n",
    "printall=False\n",
    "    \n",
    "def percentage_difference(x, y):\n",
    "    return np.abs((x - y) / ((x + y) / 2)) * 100\n",
    "\n",
    "\n",
    "import ast\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "\n",
    "\n",
    "totdateslim=[]\n",
    "totfreqslim=[]\n",
    "totdiffslimvar=[]\n",
    "totdiffslimbeam=[]\n",
    "\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "c=constants.c\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "txtnamesandcoords='namesandcoords.txt'\n",
    "path='Beam Mismatch'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "newrefs=[]\n",
    "for isource, data in grouped_data.items():\n",
    "    # Main loop to read and process sources from the input file\n",
    "    if os.path.exists(txtnamesandcoords):\n",
    "        with open(txtnamesandcoords, 'r') as infile:\n",
    "            for line in infile:\n",
    "\n",
    "                # Parse the line into a list of name-coordinate pairs\n",
    "                params = ast.literal_eval(line)\n",
    "                for inamecoords in params:                \n",
    "                    source_name = inamecoords[0][0]\n",
    "                    if not isource.lower() in source_name.lower():\n",
    "                        continue\n",
    "                    source=source_name\n",
    "                    ra = inamecoords[1][1]\n",
    "                    dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                    findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                    distanceMPc=findvals[0][0]\n",
    "                    distanceMPc_uncer=findvals[0][1]\n",
    "                    method=findvals[1]\n",
    "                    ynfindref=findvals[2]\n",
    "                    refcode=findvals[3]\n",
    "                    red_depend=findvals[4]\n",
    "                    if len(findvals[5])!=0:\n",
    "                        for i in findvals[5]:\n",
    "                            newrefs.append(i)\n",
    "    else:\n",
    "        print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "    arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "    arcsectopc=arcsectokpc*1000\n",
    "\n",
    "    arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "    arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "    arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "    distance='NA'\n",
    "    with open(Greenepath, 'r') as infile:\n",
    "        j=-1\n",
    "        breaker=1\n",
    "        for line in infile:\n",
    "            j=j+1\n",
    "            if j>20:\n",
    "                continue\n",
    "            source_name=line.split(' ')[0]\n",
    "            source_name=source_name.replace(\"−\",\"-\")\n",
    "            if \"WISEA\" in isource:\n",
    "                isource=isource.split(\"WISEA\")[0]\n",
    "            if isource.lower() in source_name.lower():\n",
    "                log_BH_mass_solar=line.split(' ')[3]\n",
    "                log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                breaker=0\n",
    "        if breaker!=1:\n",
    "            mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "\n",
    "\n",
    "\n",
    "    # Filter out elements where date == 'NA'\n",
    "    valid_sfreqs = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'])]\n",
    "    valid_sfreqs2 = [(f, fl, b, d) for f, fl, b, d in zip(data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'])]\n",
    "\n",
    "    # Combine all valid data for grouping\n",
    "    combined_data = valid_sfreqs + valid_sfreqs2\n",
    "    \n",
    "    # Unpack valid data\n",
    "    if combined_data:\n",
    "        combined_freqs, combined_fluxes, combined_beams, combined_dates = zip(*combined_data)\n",
    "    else:\n",
    "        combined_freqs, combined_fluxes, combined_beams, combined_dates = [], [], [], []\n",
    "\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [list(combined_freqs)], [list(combined_fluxes)], [list(combined_beams)], [list(combined_dates)]\n",
    "\n",
    "    #print(grouped_fluxes)\n",
    "    # Iterate through frequency groups and create separate plots\n",
    "    donefreq=[]\n",
    "\n",
    "    for freq_group, flux_group, beam_group, date_group in zip(grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates):\n",
    "        if len(date_group) > 0 and len(flux_group) > 0:  # Only plot if there are valid points\n",
    "            \n",
    "            new_valid=[]\n",
    " \n",
    "            for ivalid_sfreqs in valid_sfreqs:\n",
    "                ivalid_sfreqs=list(ivalid_sfreqs)\n",
    "                ivalid_sfreqs.append('detect')\n",
    "                ivalid_sfreqs=tuple(ivalid_sfreqs)\n",
    "                new_valid.append(ivalid_sfreqs)\n",
    "\n",
    "            for ivalid_sfreqs in valid_sfreqs2:\n",
    "                ivalid_sfreqs=list(ivalid_sfreqs)\n",
    "                ivalid_sfreqs.append('nodetect')\n",
    "                ivalid_sfreqs=tuple(ivalid_sfreqs)\n",
    "                new_valid.append(ivalid_sfreqs)\n",
    "\n",
    "\n",
    "\n",
    "            for valid_data in [new_valid]:          \n",
    "                #to filter through points for graphing\n",
    "                filtered_points = [(d, fl, b, f, detect) for f, fl, b, d, detect in valid_data if f in freq_group]\n",
    "                if filtered_points:\n",
    "                    filtered_dates, filtered_fluxes, filtered_beams, filtered_freqs, detect = zip(*filtered_points)\n",
    "                    \n",
    "                    #filtered_dates, filtered_fluxes, filtered_beams, filtered_freqs = zip(*filtered_points)\n",
    "\n",
    "                    #for getting into MPc values\n",
    "                    #filtered_beams = np.array(filtered_beams)\n",
    "                    #for getting into MPc values\n",
    "                    #filtered_beams = 10**filtered_beams\n",
    "                    #filtered_beams = filtered_beams * (np.pi / (180 * 3600))\n",
    "                    #filtered_beams = filtered_beams * distanceMPc * 1000\n",
    "                    #filtered_beams = np.log10(filtered_beams)\n",
    "                    #filtered_beams = filtered_beams.tolist()\n",
    "\n",
    "                    #filtered_fluxes=10**np.array(filtered_fluxes) * (np.pi / (180 * 3600)) * distanceMPc * 1000\n",
    "                    #filtered_fluxes=filtered_fluxes.tolist()\n",
    "\n",
    "            # Assuming filtered_freqs is already defined and is a list or array\n",
    "            n = len(filtered_freqs)\n",
    "\n",
    "            freq_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "            beam_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "            flux_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "            date_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "            detect_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "            avgfluxij = np.full((n, n), np.nan, dtype=object)\n",
    "\n",
    "\n",
    "            for i in range(len(filtered_freqs)):\n",
    "                for j in range(i + 1, len(filtered_freqs)):\n",
    "                    if i!=j:\n",
    "                        keep=1\n",
    "                        if not isinstance(filtered_fluxes[i], list) and not isinstance(filtered_fluxes[j], list):\n",
    "                            keep=0\n",
    "                        elif not isinstance(filtered_fluxes[j], list):\n",
    "                            if filtered_fluxes[j] > filtered_fluxes[i][0]:\n",
    "                                keep=0\n",
    "                        elif not isinstance(filtered_fluxes[i], list):\n",
    "                            if filtered_fluxes[i] > filtered_fluxes[j][0]:\n",
    "                                keep=0\n",
    "\n",
    "                        if keep==1:\n",
    "                            freq_diffs[i, j] = percentage_difference(10**filtered_freqs[i], 10**filtered_freqs[j])\n",
    "                            if isinstance(filtered_beams[i], list):\n",
    "                                bothi=filtered_beams[i][1].split(' - ')\n",
    "                                beami1=float(bothi[0])\n",
    "                                beami2=float(bothi[1])\n",
    "                                beamdiff1=percentage_difference(beami1, float(filtered_beams[j]))\n",
    "                                beamdiff2=percentage_difference(beami2, float(filtered_beams[j]))\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            elif isinstance(filtered_beams[j], list):\n",
    "                                bothj=filtered_beams[j][1].split(' - ')\n",
    "                                beamj1=float(bothj[0])\n",
    "                                beamj2=float(bothj[1])\n",
    "                                beamdiff1=percentage_difference(float(filtered_beams[i]), beamj1)\n",
    "                                beamdiff2=percentage_difference(float(filtered_beams[i]), beamj2)\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            else:\n",
    "                                beam_diffs[i, j] = percentage_difference(10**filtered_beams[i], 10**filtered_beams[j])\n",
    "\n",
    "\n",
    "                            if isinstance(filtered_fluxes[i], list) and isinstance(filtered_fluxes[j], list):\n",
    "                                flux1=10**filtered_fluxes[i][0]\n",
    "                                flux2=10**filtered_fluxes[j][0]\n",
    "                                flux1_unc=log_to_linear_uncertainty(filtered_fluxes[i][0],filtered_fluxes[i][1])\n",
    "                                flux2_unc=log_to_linear_uncertainty(filtered_fluxes[j][0],filtered_fluxes[j][1])\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2),percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "                            elif isinstance(filtered_fluxes[i], list):\n",
    "                                flux1=10**filtered_fluxes[i][0]\n",
    "                                flux2=10**filtered_fluxes[j]\n",
    "                                flux1_unc=log_to_linear_uncertainty(filtered_fluxes[i][0],filtered_fluxes[i][1])\n",
    "                                flux2_unc=0\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2)+percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "                            elif isinstance(filtered_fluxes[j], list):\n",
    "                                flux1=10**filtered_fluxes[i]\n",
    "                                flux2=10**filtered_fluxes[j][0]\n",
    "                                flux1_unc=0\n",
    "                                flux2_unc=log_to_linear_uncertainty(filtered_fluxes[j][0],filtered_fluxes[j][1])\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2)+percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "\n",
    "\n",
    "\n",
    "                            if filtered_dates[i]!='NA' and filtered_dates[j]!='NA':\n",
    "                                date_diffs[i, j] = np.abs(filtered_dates[i]-filtered_dates[j])\n",
    "                            else:\n",
    "                                date_diffs[i, j] = np.nan\n",
    "\n",
    "\n",
    "    allfluxs=[]\n",
    "    allbeams=[]\n",
    "    allfreqs=[]\n",
    "    alldates=[]\n",
    "\n",
    "    nallfluxs=[]\n",
    "    nallbeams=[]\n",
    "    nallfreqs=[]   \n",
    "\n",
    "    totnum=-1\n",
    "    for i in range(len(filtered_freqs)):\n",
    "        for j in range(i + 1, len(filtered_freqs)):\n",
    "            if not isinstance(beam_diffs[i, j], float):\n",
    "                continue\n",
    "            if freq_diffs[i, j] < freq_sim_threshold and beam_diffs[i, j] < beam_sim_threshold:\n",
    "                    breaker=0\n",
    "                    newfreq=(10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "                    if freqtot[0] <= newfreq <= freqtot[1]:\n",
    "                        totnum += 1\n",
    "                        if np.isnan(date_diffs[i, j]):\n",
    "                            nallfluxs.append(flux_diffs[i, j])\n",
    "                            nallbeams.append(beam_diffs[i, j])\n",
    "                            nallfreqs.append(newfreq)\n",
    "                            input('need to impliment NA dates into variability analysis')\n",
    "                        else:\n",
    "                            allfluxs.append(flux_diffs[i, j])\n",
    "                            allbeams.append(beam_diffs[i, j])\n",
    "                            alldates.append(date_diffs[i, j])\n",
    "                            allfreqs.append(newfreq)\n",
    "\n",
    "\n",
    "    if len(allfreqs)!=0:\n",
    "\n",
    "        for iallfreqs, iallfluxs, ialldates,iallbeams in zip(allfreqs, allfluxs, alldates, allbeams):\n",
    "                totfreqslim.append(iallfreqs)\n",
    "                totdateslim.append(ialldates)\n",
    "                totdiffslimvar.append(iallfluxs)\n",
    "                totdiffslimbeam.append(iallbeams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvaldust(Pf,Pb,alpha=2.5):\n",
    "    beamrat=(2-Pb)/(2+Pb)\n",
    "    freqrat=(2-Pf)/(2+Pf)\n",
    "    #fluxrat=(1-beamrat**2*freqrat**alpha)/((1+beamrat**2*freqrat**alpha)/2)\n",
    "    fluxrat=(1-freqrat**alpha)/((1+freqrat**alpha)/2)\n",
    "    return(fluxrat*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variability Search: Plot and Print Variability vs Freq\n",
    "write=True\n",
    "#write=False\n",
    "colorbarvar='time'\n",
    "grapher='variability'\n",
    "#for variability avg val is flux and for compactness it is beam\n",
    "#Actually it will give the lower value\n",
    "#colorbarvar='avgval'\n",
    "from astroquery.ipac.ned import Ned\n",
    "\n",
    "source_labels={}\n",
    "\n",
    "def percentage_difference(x, y):\n",
    "    return np.abs((x - y) / ((x + y) / 2)) * 100\n",
    "\n",
    "import ast\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "import sys\n",
    "import matplotlib.pyplot as pylab\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "allfluxs=[]\n",
    "\n",
    "def format_val(val):\n",
    "    if val==0:\n",
    "        return '0'\n",
    "    if np.isnan(val):\n",
    "        return np.nan\n",
    "    places = max(1,  -int(math.floor(math.log10(abs(val))))+1) \n",
    "    #return f'{val:.{places}f}'\n",
    "    if val >1:\n",
    "        val=f'{val:.1f}' \n",
    "    elif val >0.1:\n",
    "        val=f'{val:.2f}' \n",
    "    elif val >0.01:\n",
    "        val=f'{val:.3f}'\n",
    "    elif val >0.001:\n",
    "        val=f'{val:.4f}'\n",
    "    else:\n",
    "        val=f\"{val:.{places}f}\"\n",
    "    return val\n",
    "\n",
    "def format_val2(val):\n",
    "    if val==0:\n",
    "        return '0'\n",
    "    if val<0.1:\n",
    "        val=f'{val:.4f}'\n",
    "    elif val<1:\n",
    "        val=f'{val:.3f}'\n",
    "    elif val<10:\n",
    "        val=f'{val:.2f}'\n",
    "    elif val<100:\n",
    "        val=f'{val:.1f}'\n",
    "    else:\n",
    "        input(f'problem with beam {val}')\n",
    "    return val\n",
    "\n",
    "cm2 = pylab.get_cmap('jet')  \n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "c=constants.c\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "txtnamesandcoords='namesandcoords.txt'\n",
    "path='Beam Mismatch'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "spacings=[13, 8, 8, 10, 9, 9, 10, 10, 10, 15, 15, 15, 10]\n",
    "tot = 0\n",
    "for i in spacings:\n",
    "    tot=tot+i\n",
    "source='target'\n",
    "\n",
    "sfreqs1='freq1'\n",
    "sfreqs2='freq2'\n",
    "freqper='[sep %]'\n",
    "\n",
    "sbeams1='beam1'\n",
    "sbeams2='beam2'\n",
    "beamper='[sep %]'\n",
    "\n",
    "sfluxes1='flux1'\n",
    "sfluxes2='flux2'\n",
    "fluxper='[sep %]'\n",
    "\n",
    "sdates1='year1'\n",
    "sdates2='year2'\n",
    "datesep='[sep yrs]'\n",
    "\n",
    "if printall==True:\n",
    "    corr_table='machinetables/correlations_machine.txt'\n",
    "elif printall==False:\n",
    "    if grapher=='variability':\n",
    "        corr_table='machinetables/variability_machine.txt'\n",
    "    elif grapher=='compactness':    \n",
    "        corr_table='machinetables/compactness_machine.txt'\n",
    "\n",
    "with open(corr_table, 'w') as file:\n",
    "    if write==True:\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = file\n",
    "    #print(f'{source.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "\n",
    "    newrefs=[]\n",
    "    indextot=-1\n",
    "    for isource, data in grouped_data.items():\n",
    "        if isource!='NGC1194':\n",
    "            #continue\n",
    "            pass\n",
    "        # Main loop to read and process sources from the input file\n",
    "        if os.path.exists(txtnamesandcoords):\n",
    "            with open(txtnamesandcoords, 'r') as infile:\n",
    "                for line in infile:\n",
    "                    # Parse the line into a list of name-coordinate pairs\n",
    "                    params = ast.literal_eval(line)\n",
    "                    for inamecoords in params:              \n",
    "                        source_name = inamecoords[0][0]\n",
    "                        if not isource.lower() in source_name.lower():\n",
    "                            continue\n",
    "                        source=source_name\n",
    "                        if source=='CircinusGalaxy':\n",
    "                            source='Circinus'    \n",
    "                        ra = inamecoords[1][1]\n",
    "                        dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                        findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                        distanceMPc=findvals[0][0]\n",
    "                        distanceMPc_uncer=findvals[0][1]\n",
    "                        method=findvals[1]\n",
    "                        ynfindref=findvals[2]\n",
    "                        refcode=findvals[3]\n",
    "                        red_depend=findvals[4]\n",
    "                        if len(findvals[5])!=0:\n",
    "                            for i in findvals[5]:\n",
    "                                newrefs.append(i)\n",
    "        else:\n",
    "            print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "        arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "        arcsectopc=arcsectokpc*1000\n",
    "\n",
    "        arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "        arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "        arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "        distance='NA'\n",
    "        with open(Greenepath, 'r') as infile:\n",
    "            j=-1\n",
    "            breaker=1\n",
    "            for line in infile:\n",
    "                j=j+1\n",
    "                if j>20:\n",
    "                    continue\n",
    "                source_name=line.split(' ')[0]\n",
    "                source_name=source_name.replace(\"−\",\"-\")\n",
    "                if \"WISEA\" in isource:\n",
    "                    isource=isource.split(\"WISEA\")[0]\n",
    "                if isource.lower() in source_name.lower():\n",
    "                    log_BH_mass_solar=line.split(' ')[3]\n",
    "                    log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                    breaker=0\n",
    "            if breaker!=1:\n",
    "                mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "\n",
    "        # Filter out elements where date == 'NA'\n",
    "        valid_sfreqs = [(f, fl, b, d, fn) for f, fl, b, d, fn in zip(data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'], data['sfiles'])]\n",
    "        valid_sfreqs2 = [(f, fl, b, d, fn) for f, fl, b, d, fn in zip(data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'], data['sfiles2'])]\n",
    "        if len(data['sfreqs']+data['sfreqs2'])==0:\n",
    "            continue\n",
    "\n",
    "        # Combine all valid data for grouping\n",
    "        combined_data = valid_sfreqs + valid_sfreqs2\n",
    "        \n",
    "        # Unpack valid data\n",
    "        if combined_data:\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, combined_names = zip(*combined_data)\n",
    "        else:\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, combined_names = [], [], [], [], []\n",
    "\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates, grouped_names = [list(combined_freqs)], [list(combined_fluxes)], [list(combined_beams)], [list(combined_dates)], [list(combined_names)]\n",
    "\n",
    "        #print(grouped_fluxes)\n",
    "        # Iterate through frequency groups and create separate plots\n",
    "        donefreq=[]\n",
    "        for freq_group, flux_group, beam_group, date_group, name_group in zip(grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates, grouped_names):\n",
    "            if len(date_group) > 0 and len(flux_group) > 0:  # Only plot if there are valid points  \n",
    "\n",
    "                new_valid=[]\n",
    "    \n",
    "                for ivalid_sfreqs in valid_sfreqs:\n",
    "                    ivalid_sfreqs=list(ivalid_sfreqs)\n",
    "                    ivalid_sfreqs.append('detect')\n",
    "                    ivalid_sfreqs=tuple(ivalid_sfreqs)\n",
    "                    new_valid.append(ivalid_sfreqs)\n",
    "\n",
    "                for ivalid_sfreqs in valid_sfreqs2:\n",
    "                    ivalid_sfreqs=list(ivalid_sfreqs)\n",
    "                    ivalid_sfreqs.append('nodetect')\n",
    "                    ivalid_sfreqs=tuple(ivalid_sfreqs)\n",
    "                    new_valid.append(ivalid_sfreqs)\n",
    "\n",
    "\n",
    "                #for valid_data in new_valid:\n",
    "                #for valid_data in [\n",
    "                #    (valid_sfreqs)\n",
    "                #]:  \n",
    "                    #filtered_points = [(d, fl, b, f) for f, fl, b, d in valid_data if f in freq_group]\n",
    "\n",
    "                for valid_data in [new_valid]:\n",
    "                    filtered_points = [(d, fl, b, f, detect, fn) for f, fl, b, d, detect, fn in valid_data if f in freq_group]\n",
    "                    if filtered_points:\n",
    "                        filtered_dates, filtered_fluxes, filtered_beams, filtered_freqs, filenames, detect = zip(*filtered_points)\n",
    "                        #filtered_dates, filtered_fluxes, filtered_beams, filtered_freqs = zip(*filtered_points)\n",
    "                        \n",
    "                        #for getting into MPc values\n",
    "                        #filtered_beams = np.array(filtered_beams)\n",
    "                        #filtered_beams = 10**filtered_beams\n",
    "                        #filtered_beams = filtered_beams * (np.pi / (180 * 3600))\n",
    "                        #filtered_beams = filtered_beams * distanceMPc * 1000\n",
    "                        #filtered_beams = np.log10(filtered_beams)\n",
    "                        #filtered_beams = filtered_beams.tolist()\n",
    "\n",
    "                        #filtered_fluxes=10**np.array(filtered_fluxes) * (np.pi / (180 * 3600)) * distanceMPc * 1000\n",
    "                        #filtered_fluxes=filtered_fluxes.tolist()\n",
    "\n",
    "                # Assuming filtered_freqs is already defined and is a list or array\n",
    "                n = len(filtered_freqs)\n",
    "\n",
    "                freq_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                avgfreqij = np.full((n, n), np.nan, dtype=object)\n",
    "                beam_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                avgbeamij = np.full((n, n), np.nan, dtype=object)\n",
    "                flux_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                avgfluxij = np.full((n, n), np.nan, dtype=object)\n",
    "                date_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                detect_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "                name_diffs = np.full((n, n), np.nan, dtype=object)\n",
    "\n",
    "                totkeep=0\n",
    "\n",
    "                for i in range(len(filtered_freqs)):\n",
    "                    for j in range(i + 1, len(filtered_freqs)):\n",
    "                        keep=1\n",
    "                        if not isinstance(filtered_fluxes[i], list) and not isinstance(filtered_fluxes[j], list):\n",
    "                            keep=0\n",
    "                        elif not isinstance(filtered_fluxes[j], list):\n",
    "                            if filtered_fluxes[j] > filtered_fluxes[i][0]:\n",
    "                                keep=0\n",
    "                        elif not isinstance(filtered_fluxes[i], list):\n",
    "                            if filtered_fluxes[i] > filtered_fluxes[j][0]:\n",
    "                                keep=0\n",
    "                        if i==j:\n",
    "                            keep=0\n",
    "\n",
    "                        if keep==0:\n",
    "                            pass\n",
    "\n",
    "                        if keep==1:\n",
    "                            totkeep=totkeep+1\n",
    "                            freq_diffs[i, j] = percentage_difference(10**filtered_freqs[i], 10**filtered_freqs[j])\n",
    "                            avgfreqij[i, j] = (10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "                            name_diffs[i,j] = [filenames[i],filenames[j]]\n",
    "\n",
    "                            if isinstance(filtered_beams[i], list):\n",
    "                                #input('error1')\n",
    "                                bothi=filtered_beams[i][1].split(' - ')\n",
    "                                beami1=float(bothi[0])\n",
    "                                beami2=float(bothi[1])\n",
    "                                beamdiff1=percentage_difference(beami1, float(filtered_beams[j]))\n",
    "                                beamdiff2=percentage_difference(beami2, float(filtered_beams[j]))\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            elif isinstance(filtered_beams[j], list):\n",
    "                                #print(filtered_beams[i])\n",
    "                                #print(filtered_beams[j])\n",
    "                                #input('error2')\n",
    "                                bothj=filtered_beams[j][1].split(' - ')\n",
    "                                beamj1=float(bothj[0])\n",
    "                                beamj2=float(bothj[1])\n",
    "                                beamdiff1=percentage_difference(float(filtered_beams[i]), beamj1)\n",
    "                                beamdiff2=percentage_difference(float(filtered_beams[i]), beamj2)\n",
    "                                beam_diffs[i, j] = f\"{beamdiff1}-{beamdiff2}\"\n",
    "                            else:\n",
    "                                beam_diffs[i, j] = percentage_difference(10**filtered_beams[i], 10**filtered_beams[j])\n",
    "\n",
    "                            #avgbeamij[i, j]= (10**filtered_beams[i] + 10**filtered_beams[j])/2\n",
    "                            if isinstance(filtered_beams[i], list) or isinstance(filtered_beams[j], list):\n",
    "                                #input('error3')\n",
    "                                avgbeamij[i, j]='NA'\n",
    "                            else:\n",
    "                                if filtered_beams[i] < filtered_beams[j]:\n",
    "                                    avgbeamij[i, j]= 10**filtered_beams[i]\n",
    "                                else:\n",
    "                                    avgbeamij[i, j]= 10**filtered_beams[j]\n",
    "\n",
    "                            if isinstance(filtered_fluxes[i], list) and isinstance(filtered_fluxes[j], list):\n",
    "                                flux1=10**filtered_fluxes[i][0]\n",
    "                                flux2=10**filtered_fluxes[j][0]\n",
    "                                flux1_unc=log_to_linear_uncertainty(filtered_fluxes[i][0],filtered_fluxes[i][1])\n",
    "                                flux2_unc=log_to_linear_uncertainty(filtered_fluxes[j][0],filtered_fluxes[j][1])\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2),percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "                            elif isinstance(filtered_fluxes[i], list):\n",
    "                                flux1=10**filtered_fluxes[i][0]\n",
    "                                flux2=10**filtered_fluxes[j]\n",
    "                                flux1_unc=log_to_linear_uncertainty(filtered_fluxes[i][0],filtered_fluxes[i][1])\n",
    "                                flux2_unc=0\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2)+percentage_difference_unc(flux1,flux2,flux1_unc,flux2_unc)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "                            elif isinstance(filtered_fluxes[j], list):\n",
    "                                flux1=10**filtered_fluxes[i]\n",
    "                                flux2=10**filtered_fluxes[j][0]\n",
    "                                flux1_unc=0\n",
    "                                flux2_unc=log_to_linear_uncertainty(filtered_fluxes[j][0],filtered_fluxes[j][1])\n",
    "                                flux2=flux2+flux2_unc\n",
    "                                flux_diffs[i, j] = [percentage_difference(flux1,flux2)]\n",
    "                                avgfluxij[i, j] = (flux1+flux2)/2 \n",
    "\n",
    "                            if filtered_dates[i]!='NA' and filtered_dates[j]!='NA':\n",
    "                                date_diffs[i, j] = np.abs(filtered_dates[i]-filtered_dates[j])\n",
    "                            else:\n",
    "                                date_diffs[i, j] = 'NA'\n",
    "\n",
    "        alldiffs=[]\n",
    "        allfluxavg=[]\n",
    "\n",
    "        alldiffunchi=[]\n",
    "        alldiffunchi2=[]\n",
    "        alldiffunclo=[]\n",
    "\n",
    "        allbeams=[]\n",
    "        allbeamavg=[]\n",
    "\n",
    "        allfreqs=[]\n",
    "        alldates=[]\n",
    "\n",
    "        allnames=[]\n",
    "\n",
    "        nalldiffs=[]\n",
    "        nallfluxavg=[]\n",
    "\n",
    "        nallbeams=[]\n",
    "        nallbeamavg=[]\n",
    "\n",
    "        nallfreqs=[]   \n",
    "\n",
    "        nallnames=[]\n",
    "\n",
    "        totnum=0\n",
    "        if filtered_freqs=='NA':\n",
    "            continue\n",
    "        for i in range(len(filtered_freqs)):\n",
    "            for j in range(i + 1, len(filtered_freqs)):\n",
    "                if printall==False:\n",
    "                    \n",
    "                    breaker=0\n",
    "                    #if fluxes cannot be known than you cant compare fluxes for y axis variability or ensure they are the same for compactness\n",
    "                    if flux_diffs[i, j]=='NA':\n",
    "                        breaker=1\n",
    "                    #if beams are not known that you cant compare beam sizes for y axis compactness or ensure they are the same for variability\n",
    "                    if beam_diffs[i, j]=='NA' or isinstance(beam_diffs[i,j],str):\n",
    "                        breaker=1\n",
    "                        \n",
    "                    if breaker==1:\n",
    "                        continue\n",
    "\n",
    "                    if freqthresh==True:\n",
    "                        if not freq_diffs[i, j] < freq_sim_threshold:\n",
    "                            breaker=1\n",
    "                    if beamthresh==True:\n",
    "                        if not beam_diffs[i, j] < beam_sim_threshold:\n",
    "                            breaker=1\n",
    " \n",
    "                    if breaker==1:\n",
    "                        continue\n",
    "\n",
    "                    indextot+=1  \n",
    "                    if printall==False and indextot!=0 and totnum!=0:\n",
    "                        print(f'{source.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "                        if '±' in fluxper:\n",
    "                            both=((fluxper.replace('[','').replace(']',''))).split('±')\n",
    "                            flux=both[0]\n",
    "                            totunc=float(flux)/(fluxunc+float(both[1]))\n",
    "                        pass\n",
    "                newfreq=(10**filtered_freqs[i] + 10**filtered_freqs[j])/2\n",
    "                if freqtot[0] <= newfreq <= freqtot[1]:\n",
    "                    totnum += 1\n",
    "                    if date_diffs[i, j]=='NA' and colorbarvar=='time':\n",
    "                        nalldiffs.append(flux_diffs[i, j])\n",
    "                        nallfluxavg.append(avgfluxij[i, j])\n",
    "\n",
    "                        nallbeams.append(beam_diffs[i, j])\n",
    "                        nallbeamavg.append(avgbeamij[i, j])\n",
    "\n",
    "                        nallnames.append(name_diffs[i,j])\n",
    "\n",
    "                        nallfreqs.append(newfreq)\n",
    "\n",
    "                        sfreqs1=10**filtered_freqs[i]\n",
    "                        if sfreqs1<10:\n",
    "                            sfreqs1=f'{sfreqs1:.1f}'\n",
    "                        else:\n",
    "                            sfreqs1=f'{sfreqs1:.0f}'\n",
    "\n",
    "                        sfreqs2=10**filtered_freqs[j]\n",
    "                        if sfreqs2<10:\n",
    "                            sfreqs2=f'{sfreqs2:.1f}'\n",
    "                        else:\n",
    "                            sfreqs2=f'{sfreqs2:.0f}'\n",
    "\n",
    "                        if freq_diffs[i, j]<1:\n",
    "                            freqper='[<1]'\n",
    "                        else:\n",
    "                            freqper='['+format_val(freq_diffs[i, j])+']'\n",
    "\n",
    "                        beam1=10**filtered_beams[i]\n",
    "                        beam2=10**filtered_beams[j]\n",
    "                        sbeams1=format_val2(beam1)\n",
    "                        sbeams2=format_val2(beam2)\n",
    "\n",
    "                        if beam_diffs[i,j]<1:\n",
    "                            beamper='[<1]'\n",
    "                        else:\n",
    "                            beamper='['+format_val(beam_diffs[i, j])+']'\n",
    "\n",
    "                        if detect[i]=='nodetect':\n",
    "                            fluxes1=f'{10**filtered_fluxes[i]:.1f}*'\n",
    "                        else:\n",
    "                            fluxes1=f'{10**filtered_fluxes[i]:.1f}'\n",
    "\n",
    "                        if detect[j]=='nodetect':\n",
    "                            fluxes2=f'{10**filtered_fluxes[j]:.1f}*'\n",
    "                        else:\n",
    "                            fluxes2=f'{10**filtered_fluxes[j]:.1f}'\n",
    "                        \n",
    "                        if flux_diffs[i, j] == 'NA':\n",
    "                            fluxper = '[NA]'\n",
    "                        else:\n",
    "                            if flux_diffs[i, j][0]<1:\n",
    "                                fluxper='[<1]'\n",
    "                            else:\n",
    "                                if len(flux_diffs[i, j])==2:\n",
    "                                    fluxper='['+format_val(flux_diffs[i, j][0]) + '±' + format_val(flux_diffs[i, j][1]) + ']'\n",
    "                                else:\n",
    "                                    fluxper='[>'+format_val(flux_diffs[i, j][0])+']'\n",
    "\n",
    "                        if flux_diffs[i, j]!=0:\n",
    "                            allfluxs.append(flux_diffs[i, j])\n",
    "\n",
    "                        if filtered_dates[i] =='NA' and filtered_dates[j] =='NA':\n",
    "                            sdates1='[NA]'\n",
    "                            sdates2='[NA]'\n",
    "                        elif filtered_dates[i] =='NA':\n",
    "                            sdates1='[NA]'\n",
    "                            sdates2=f'{decimal_year_to_date(filtered_dates[j])}'\n",
    "                        elif filtered_dates[j] =='NA':\n",
    "                            sdates1=f'{decimal_year_to_date(filtered_dates[i])}'\n",
    "                            sdates2='[NA]'\n",
    "                        datesep='[NA]'\n",
    "                        #print(f'{source.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "                    else:\n",
    "                        alldiffs.append(flux_diffs[i, j])\n",
    "                        allfluxavg.append(avgfluxij[i, j])\n",
    "\n",
    "                        allbeams.append(beam_diffs[i, j])\n",
    "                        allbeamavg.append(avgbeamij[i, j])\n",
    "\n",
    "                        alldates.append(date_diffs[i, j])\n",
    "                        allfreqs.append(newfreq)\n",
    "\n",
    "                        allnames.append(name_diffs[i,j])\n",
    "                        #print(allnames[0][0])\n",
    "                        #print(allnames[0][1])\n",
    "\n",
    "\n",
    "\n",
    "                        #flux1 is fluxi and flux2 is fluxj\n",
    "                        '''\n",
    "                        if flux1>flux2:\n",
    "                            lowfreq=10**filtered_freqs[j]\n",
    "                            lowflux=flux2\n",
    "                            highfreq=10**filtered_freqs[i]  \n",
    "                            highflux=flux1\n",
    "                            lowbeam=10**filtered_beams[j]\n",
    "                            highbeam=10**filtered_beams[i]\n",
    "                        elif flux1<flux2:\n",
    "                            lowfreq=10**filtered_freqs[i]\n",
    "                            lowflux=flux1\n",
    "                            highfreq=10**filtered_freqs[j]   \n",
    "                            highflux=flux2\n",
    "                            lowbeam=10**filtered_beams[i]\n",
    "                            highbeam=10**filtered_beams[j]  \n",
    "                        else:\n",
    "                            input(f'{filtered_freqs[i]} {filtered_freqs[j]}')\n",
    "                        '''\n",
    "\n",
    "                        flux1=10**filtered_fluxes[i][0]\n",
    "                        flux2=10**filtered_fluxes[j][0]\n",
    "\n",
    "                        freq1=10**filtered_freqs[i]\n",
    "                        freq2=10**filtered_freqs[j]\n",
    "\n",
    "\n",
    "                        freq1todust=flux1*(freq2/freq1)**(2.5)\n",
    "                        freq2todust=flux2*(freq1/freq2)**(2.5)\n",
    "\n",
    "                        diff1dust=percentage_difference(freq1todust, flux2)\n",
    "                        diff2dust=percentage_difference(freq2todust, flux1)\n",
    "\n",
    "                        freq1tosynch=flux1*(freq2/freq1)**(-0.5)  \n",
    "                        freq2tosynch=flux2*(freq1/freq2)**(-0.5)  \n",
    "                        diff1synch=percentage_difference(freq1tosynch, flux2)\n",
    "                        diff2synch=percentage_difference(freq2tosynch, flux1)\n",
    "\n",
    "                        dustdiff=f'{diff1dust:.1f} - {diff2dust:.1f}'\n",
    "                        synchdiff=f'{diff1synch:.1f} - {diff2synch:.1f}'\n",
    "\n",
    "\n",
    "                        sfreqs1=freq1\n",
    "                        if sfreqs1<10:\n",
    "                            sfreqs1=f'{sfreqs1:.1f}'\n",
    "                        else:\n",
    "                            sfreqs1=f'{sfreqs1:.0f}'\n",
    "\n",
    "                        sfreqs2=freq1\n",
    "                        if sfreqs2<10:\n",
    "                            sfreqs2=f'{sfreqs2:.1f}'\n",
    "                        else:\n",
    "                            sfreqs2=f'{sfreqs2:.0f}'\n",
    "\n",
    "                        freqfrac_sys=freq_diffs[i, j]/100\n",
    "                        beamfrac_sys=beam_diffs[i, j]/100\n",
    "\n",
    "                        fluxunc=getvaldust(freqfrac_sys,beamfrac_sys)\n",
    "\n",
    "                        if len(flux_diffs[i, j])==2:\n",
    "                            lowbound = False\n",
    "                            fluxunc_inst=flux_diffs[i, j][1]\n",
    "                            fluxunc1 = fluxunc_inst + fluxunc\n",
    "                            fluxunc2 = fluxunc_inst - fluxunc\n",
    "\n",
    "                            fluxunclo=linear_to_log_uncertainty(flux_diffs[i, j][0],fluxunc_inst)\n",
    "                            fluxunchi=linear_to_log_uncertainty(flux_diffs[i, j][0],fluxunc1)\n",
    "                            fluxunchi2=linear_to_log_uncertainty(flux_diffs[i, j][0],fluxunc2)\n",
    "\n",
    "                            alldiffunclo.append(fluxunclo)\n",
    "                            alldiffunchi.append(fluxunchi)\n",
    "                            alldiffunchi2.append(fluxunchi2)\n",
    "                        else:\n",
    "                            lowbound=True\n",
    "                            fluxunc_inst='xNA'\n",
    "                            fluxunc1 = fluxunc_inst + fluxunc\n",
    "                            fluxunc2 = fluxunc_inst - fluxunc\n",
    "\n",
    "                            fluxunclo='xNA'\n",
    "                            fluxunchi=linear_to_log_uncertainty(flux_diffs[i, j][0],fluxunc1)\n",
    "                            fluxunchi2=linear_to_log_uncertainty(flux_diffs[i, j][0],fluxunc2)\n",
    "\n",
    "                            alldiffunclo.append(fluxunclo)\n",
    "                            alldiffunchi.append(fluxunchi)\n",
    "                            alldiffunchi2.append(fluxunchi2)\n",
    "                            \n",
    "                        if freq_diffs[i, j]<1:\n",
    "                            freqper='[<1]'\n",
    "                        else:\n",
    "                            freqper='['+format_val(freq_diffs[i, j])+']'\n",
    "\n",
    "                        if isinstance(filtered_beams[i], list):\n",
    "                            bothi=filtered_beams[i][1].split(' - ')\n",
    "                            beami1=10**float(bothi[0])\n",
    "                            beami2=10**float(bothi[1])\n",
    "                            sbeams1=f\"{format_val2(beami1)}-{format_val2(beami2)}\"\n",
    "                        else:\n",
    "                            beam1=10**filtered_beams[i]\n",
    "                            sbeams1=format_val2(beam1)\n",
    "\n",
    "\n",
    "                        if isinstance(filtered_beams[j], list):\n",
    "                            bothj=filtered_beams[j][1].split(' - ')\n",
    "                            beamj1=10**float(bothj[0])\n",
    "                            beamj2=10**float(bothj[1])\n",
    "                            sbeams2=f\"{format_val2(beamj1)}-{format_val2(beamj2)}\"\n",
    "                        else:\n",
    "                            beam2=10**filtered_beams[j]\n",
    "                            sbeams2=format_val2(beam2)\n",
    "\n",
    "                        if isinstance(beam_diffs[i, j], float):\n",
    "                            if beam_diffs[i, j]<1:\n",
    "                                beamper='[<1]'\n",
    "                            else:\n",
    "                                beamper='['+format_val(beam_diffs[i, j])+']'\n",
    "                        else:\n",
    "                            beamper='[NA]'\n",
    "\n",
    "                        if detect[i]=='nodetect':\n",
    "                            fluxes1=f'{10**filtered_fluxes[i]:.1f}*'\n",
    "                        else:\n",
    "                            fluxes1=f'{10**filtered_fluxes[i][0]:.1f}'\n",
    "\n",
    "                        if detect[j]=='nodetect':\n",
    "                            fluxes2=f'{10**filtered_fluxes[j]:.1f}*'\n",
    "                        else:\n",
    "                            fluxes2=f'{10**filtered_fluxes[j][0]:.1f}'\n",
    "                            \n",
    "                        sfluxes1=f'{fluxes1}'\n",
    "                        sfluxes2=f'{fluxes2}'\n",
    "\n",
    "                        if flux_diffs[i, j]!=0:\n",
    "                            allfluxs.append(flux_diffs[i, j])\n",
    "                        if flux_diffs[i, j]!=0 and i+1!=j:\n",
    "                            #print(i)\n",
    "                            #print(j)\n",
    "                            #input('error ij')\n",
    "                            pass\n",
    "\n",
    "                        #print(filtered_dates[i])\n",
    "                        #print(filtered_dates[j])\n",
    "                        sdates1=f'{decimal_year_to_date(filtered_dates[i])}'\n",
    "                        sdates2=f'{decimal_year_to_date(filtered_dates[j])}'\n",
    "                        if date_diffs[i, j]!='NA':\n",
    "                            idate_diffs=f\"{date_diffs[i, j]:.3f}\"\n",
    "                        else:\n",
    "                            idate_diffs='NA'\n",
    "                        datesep=f'['+idate_diffs+']'\n",
    "                        if flux_diffs[i, j] == 'NA':\n",
    "                            fluxper = '[NA]'\n",
    "                        else:\n",
    "                            if flux_diffs[i, j][0]<1:\n",
    "                                fluxper='[<1]'\n",
    "                            else:\n",
    "                                if len(flux_diffs[i, j])==2:\n",
    "                                    fluxper='['+format_val(flux_diffs[i, j][0]) + '±' + format_val(flux_diffs[i, j][1]) + ']'\n",
    "                                else:\n",
    "                                    fluxper='[>'+format_val(flux_diffs[i, j][0])+']'\n",
    "\n",
    "                        #print(dustdiff)\n",
    "                        #print(synchdiff)\n",
    "                        #print(fluxper)\n",
    "                        '''\n",
    "                        print(sfreqs1)\n",
    "                        print(sfreqs2)\n",
    "                        print(freqper)\n",
    "                        print(sbeams1)\n",
    "                        print(sbeams2)\n",
    "                        print(beamper)\n",
    "                        print(sfluxes1)\n",
    "                        print(sfluxes2)\n",
    "                        print(fluxper)\n",
    "                        print(sdates1)\n",
    "                        print(sdates2)  \n",
    "                        print(datesep)\n",
    "                        '''\n",
    "            \n",
    "                    if printall==True:\n",
    "                        indextot+=1 \n",
    "                        print(f'{isource.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "\n",
    "        if len(allfreqs)!=0:\n",
    "            #gets the most recent values:\n",
    "\n",
    "                        \n",
    "            if printall==False:\n",
    "                print(f'{source.ljust(spacings[0])} {sfreqs1.ljust(spacings[1])} {sfreqs2.ljust(spacings[2])} {freqper.ljust(spacings[3])} {sbeams1.ljust(spacings[4])} {sbeams2.ljust(spacings[5])} {beamper.ljust(spacings[6])} {sfluxes1.ljust(spacings[7])} {sfluxes2.ljust(spacings[8])} {fluxper.ljust(spacings[9])} {sdates1.ljust(spacings[10])} {sdates2.ljust(spacings[11])} {datesep.ljust(spacings[12])}')\n",
    "            cm2 = pylab.get_cmap('jet')  \n",
    "\n",
    "\n",
    "            totdates = np.array(alldates)\n",
    "            totfreqs = np.array(allfreqs)\n",
    "\n",
    "            #note these are note averages they are the lower of the 2 values\n",
    "            allfluxavg = np.array(allfluxavg)\n",
    "            allbeamavg = np.array(allbeamavg)\n",
    "\n",
    "            # Create a boolean mask where all fields are valid (i.e., not 'NA')\n",
    "            valid_mask = [\n",
    "                (d != 'NA' and f != 'NA' and fl != 'NA' and b != 'NA')\n",
    "                for d, f, fl, b in zip(totdates, totfreqs, allfluxavg, allbeamavg)\n",
    "            ]\n",
    "\n",
    "            if np.size(totdates[valid_mask]) == 0:\n",
    "                continue\n",
    "\n",
    "            # Apply the mask to each array\n",
    "            totdates = totdates[valid_mask].astype(float)\n",
    "            totfreqs = totfreqs[valid_mask].astype(float)\n",
    "            allfluxavg = allfluxavg[valid_mask].astype(float)\n",
    "            allbeamavg = allbeamavg[valid_mask].astype(float)\n",
    "\n",
    "            allfluxavg=np.log10(allfluxavg.astype(float))\n",
    "            allbeamavg=np.log10(allbeamavg.astype(float))\n",
    "\n",
    "            minfreq=np.log10(np.min(totfreqslim))\n",
    "            maxfreq=np.log10(np.max(totfreqslim))\n",
    "\n",
    "            interval = maxfreq - minfreq\n",
    "            ten_percent = interval * 0.05\n",
    "            #minfreq = minfreq - ten_percent\n",
    "            #maxfreq = maxfreq + ten_percent\n",
    "\n",
    "            #mindate=np.min(totdateslim)\n",
    "            #maxdate=np.max(totdateslim)\n",
    "            #mindate=np.min(totdates)\n",
    "            mindate=0\n",
    "            maxdate=np.max(totdates)\n",
    "            if maxdate<5:\n",
    "                maxdate=5\n",
    "\n",
    "            #interval = maxdate - mindate\n",
    "            #ten_percent = interval * 0.05\n",
    "            #mindate = mindate - ten_percent\n",
    "            #maxdate = maxdate + ten_percent\n",
    "\n",
    "            minfluxavg=np.min(allfluxavg)\n",
    "            #if minfluxavg>0:\n",
    "            #    minfluxavg=0\n",
    "            maxfluxavg=np.max(allfluxavg)\n",
    "            #if maxfluxavg<1:\n",
    "            #    maxfluxavg=1\n",
    "\n",
    "            interval = maxfluxavg - minfluxavg\n",
    "            ten_percent = interval * 0.05\n",
    "            minfluxavg = minfluxavg - ten_percent\n",
    "            maxfluxavg = maxfluxavg + ten_percent\n",
    "\n",
    "            minbeamavg=np.min(allbeamavg)\n",
    "            #if minbeamavg>0:\n",
    "            #    minbeamavg=0\n",
    "            maxbeamavg=np.max(allbeamavg)\n",
    "\n",
    "            interval = maxbeamavg - minbeamavg\n",
    "            ten_percent = interval * 0.05\n",
    "            minbeamavg = minbeamavg - ten_percent\n",
    "            maxbeamavg = maxbeamavg + ten_percent\n",
    "\n",
    "            minfreqp=round_down_to_half_integer(minfreq)\n",
    "            maxfreqp=round_up_to_half_integer(maxfreq)\n",
    "\n",
    "            if not math.isnan(mindate):\n",
    "                mindatep=round_down_to_half_integer(mindate)\n",
    "            if not math.isnan(maxdate):\n",
    "                maxdatep=round_up_to_half_integer(maxdate)\n",
    "\n",
    "            if not math.isnan(minfluxavg):\n",
    "                minfluxavgp=round_down_to_half_integer(minfluxavg)\n",
    "            if not math.isnan(maxfluxavg):\n",
    "                maxfluxavgp=round_up_to_half_integer(maxfluxavg)\n",
    "\n",
    "            if not math.isnan(minbeamavg):\n",
    "                minbeamavgp=round_down_to_half_integer(minbeamavg)\n",
    "            if not math.isnan(maxbeamavg):\n",
    "                maxbeamavgp=round_up_to_half_integer(maxbeamavg)\n",
    "\n",
    "            if grapher=='variability':\n",
    "                #all diffs are flux differences and are on the y axis\n",
    "                totdiffs=alldiffs\n",
    "\n",
    "            elif grapher=='compactness':\n",
    "                #all diffs are beam differences and are on the y axis\n",
    "                totdiffs=allbeams\n",
    "\n",
    "            if colorbarvar=='time':\n",
    "                minnorm=mindatep\n",
    "                #minnorm=0\n",
    "                maxnorm=maxdatep\n",
    "                if maxnorm<5:\n",
    "                    maxnorm=5\n",
    "                totnorm=totdates\n",
    "            elif colorbarvar=='avgval':\n",
    "                if grapher=='variability':\n",
    "                    minnorm=minfluxavgp\n",
    "                    maxnorm=maxfluxavgp\n",
    "                    totnorm=allfluxavg\n",
    "                elif grapher=='compactness':\n",
    "                    minnorm=minbeamavgp\n",
    "                    maxnorm=maxbeamavgp\n",
    "                    totnorm=allbeamavg\n",
    "\n",
    "            norm=matplotlib.colors.Normalize(vmin=minnorm, vmax=maxnorm)\n",
    "            scalar_map = cmx.ScalarMappable(norm=norm, cmap=cm2)\n",
    "            colors = scalar_map.to_rgba(totnorm)\n",
    "            fig, ax = pylab.subplots(dpi=300)\n",
    "            #pylab.scatter(np.log10(totfreqs), np.log10(totdiffs), marker='o', s=5, c=colors)  # You can change the color and marker style\n",
    "            \n",
    "            log_freqs = np.log10(totfreqs)\n",
    "            totnorm[totnorm == 0] = 1/365\n",
    "            totnorm = np.log10(totnorm)\n",
    "\n",
    "            precthresh=1\n",
    "            precthresh=np.log10(precthresh)\n",
    "\n",
    "            # Place a lower arrow for points that have the same flux(for variability) or beam (for compactness)\n",
    "            \n",
    "            valid_mask = []\n",
    "            for x, y, z, k1, k2, k3 in zip(totdiffs, log_freqs, colors, alldiffunchi, alldiffunclo, alldiffunchi2):\n",
    "                def is_invalid(val):\n",
    "                        return (isinstance(val, str) and ('-' in val or val == 'NA')) or np.ndim(val) > 1\n",
    "\n",
    "                if is_invalid(x) or is_invalid(y) or is_invalid(z):\n",
    "                        valid_mask.append(False)\n",
    "                else:\n",
    "                        valid_mask.append(True)\n",
    "\n",
    "            # Apply the validated mask\n",
    "            totdiffs = [float(f[0]) for f in totdiffs]\n",
    "            filtered_diffs = np.array([float(x) for x, keep in zip(totdiffs, valid_mask) if keep])\n",
    "            filtered_freqs = np.array([y for y, keep in zip(log_freqs, valid_mask) if keep])\n",
    "            filtered_colors = np.array([z for z, keep in zip(colors, valid_mask) if keep])\n",
    "            filtered_diffsunchi = np.array([k for k, keep in zip(alldiffunchi, valid_mask) if keep])\n",
    "            filtered_diffsunchi2 = np.array([k for k, keep in zip(alldiffunchi2, valid_mask) if keep])\n",
    "            filtered_diffsunclo = np.array([k for k, keep in zip(alldiffunclo, valid_mask) if keep])\n",
    "            filtered_times = np.array([y for y, keep in zip(totnorm, valid_mask) if keep])\n",
    "\n",
    "\n",
    "            log_diffs = np.maximum(np.log10(np.maximum(filtered_diffs, 1e-10)), precthresh)\n",
    "\n",
    "            normal_mask = log_diffs > precthresh\n",
    "\n",
    "            # Now your original logic applies correctly:\n",
    "            normal_x = filtered_freqs[normal_mask]\n",
    "            normal_y = log_diffs[normal_mask]\n",
    "            #normal_color = filtered_colors[normal_mask]\n",
    "            normal_color = normal_x\n",
    "            normal_yunchi = filtered_diffsunchi[normal_mask]\n",
    "            normal_yunchi2 = filtered_diffsunchi[normal_mask]\n",
    "            normal_yunclo = filtered_diffsunclo[normal_mask]\n",
    "            normal_x_times = filtered_times[normal_mask]\n",
    "\n",
    "            adjusted_x = filtered_freqs[~normal_mask]\n",
    "            adjusted_y = log_diffs[~normal_mask]\n",
    "            #adjusted_color = filtered_colors[~normal_mask]\n",
    "            adjusted_color = adjusted_x\n",
    "            adjusted_x_times = []\n",
    "            adjusted_x_times = filtered_times[~normal_mask]\n",
    "            \n",
    "\n",
    "            if len(nallfreqs)!=0:\n",
    "                ntotfreqs=nallfreqs\n",
    "                ntotdiffs=nalldiffs\n",
    "\n",
    "\n",
    "            #normal_x = log_freqs\n",
    "            #normal_y = log_diffs\n",
    "            #normal_color = colors\n",
    "            #print(f'x: {normal_x}')\n",
    "            #print(f'y: {normal_y}')\n",
    "            #print(f'c: {totnorm}')\n",
    "\n",
    "            vmin = 0\n",
    "            vmax = np.log10(500)\n",
    "\n",
    "            # round down to nearest tenth\n",
    "            vmin_rounded = math.floor(vmin * 10) / 10.0\n",
    "\n",
    "            # round up to nearest tenth\n",
    "            vmax_rounded = math.ceil(vmax * 10) / 10.0\n",
    "\n",
    "            cmap = mpl.cm.viridis\n",
    "            norm = mpl.colors.Normalize(vmin=vmin_rounded,\n",
    "                                        vmax=vmax_rounded)\n",
    "            sm = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)  # for the colorbar\n",
    "\n",
    "            for x, y, ylo, yhi, yhi2, c in zip(normal_x_times, normal_y, normal_yunclo ,normal_yunchi,normal_yunchi2 , normal_color):\n",
    "                #ylo is the error due to flux uncertainty, and yhi is the error due to incoporating frequency effects\n",
    "                #ylo is positive... but yhi may be lower than ylo, and could in fact even be negative\n",
    "                if not y/ylo>3:\n",
    "                    continue\n",
    "                \n",
    "                col = cmap(norm(c))\n",
    "                if ylo=='xNA':\n",
    "                    if c>2.3:\n",
    "                      input('error')\n",
    "                    else:  \n",
    "                        shape = '^'\n",
    "\n",
    "                    if yhi-y<=0:\n",
    "                          pylab.scatter(x, y,\n",
    "                                      facecolors='none', edgecolors=col,\n",
    "                                      marker=shape, s=40)\n",
    "                    else:\n",
    "                          if yhi2>yhi:\n",
    "                              yhival=yhi2\n",
    "                          else:\n",
    "                              yhival=yhi\n",
    "                          ax.errorbar(x, y,\n",
    "                                      yerr=[[yhival], [0]],    \n",
    "                                      fmt=shape, ms=5, linestyle='none',\n",
    "                                      markerfacecolor='none', markeredgecolor=col, ecolor=col, capsize=0)\n",
    "                          \n",
    "                          cap_len = 1 \n",
    "                          ax.hlines(y + yhi, x - cap_len/2, x + cap_len/2, colors=col, linewidth=0.5)\n",
    "                    continue\n",
    "                \n",
    "\n",
    "                if c>2.3:\n",
    "                    shape='o'\n",
    "                else:\n",
    "                    shape='s'\n",
    "                \n",
    "                if y-ylo > 0:\n",
    "                    if yhi>ylo:\n",
    "                        yplot=yhi\n",
    "                    else:\n",
    "                        yplot=ylo\n",
    "                    ax.errorbar(x, y,\n",
    "                                yerr=[[yplot], [yplot]],     # asymmetric: lower=ylo, upper=0\n",
    "                                fmt=shape, ms=5, linestyle='none',\n",
    "                                markerfacecolor='none', markeredgecolor=col, ecolor=col, capsize=0)\n",
    "                    cap_len = 1   # length in data units (tweak as needed)\n",
    "                    ax.hlines(y - yhi2, x - cap_len/2, x + cap_len/2, colors=col, linewidth=0.5,linestyles='--')\n",
    "                    ax.hlines(y + yhi, x - cap_len/2, x + cap_len/2, colors=col, linewidth=0.5,linestyles='--')\n",
    "\n",
    "                    # Now add custom horizontal caps\n",
    "                    cap_len = 1  # length in data units (adjust to taste)\n",
    "                    ax.hlines(y - ylo, x - cap_len/2, x + cap_len/2, colors=col, linewidth=0.5)  # lower cap\n",
    "                    ax.hlines(y + ylo, x - cap_len/2, x + cap_len/2, colors=col, linewidth=0.5)  # lower cap\n",
    "                else:\n",
    "                    input('error ylo')\n",
    "                    #ax.errorbar(x, y,\n",
    "                    #yerr=[[y], [ylo]],     # asymmetric: lower=ylo, upper=0\n",
    "                    #fmt=shape, ms=5, linestyle='none',\n",
    "                    #markerfacecolor='none', markeredgecolor=col, ecolor=col, capsize=4, elinewidth=0.5)\n",
    "                    #ecolor=col\n",
    "\n",
    "                    # add downward arrow at bottom of error bar\n",
    "                    #ax.scatter(x, 0, marker='v', color=col, s=40)   # 'v' = downward triangle\n",
    "                    #ax.scatter(x, yhi-y, marker='_', color=col, s=120)   # 'v' = downward triangle\n",
    "                    #ax.scatter(x, y+yhi, marker='_', color=col, s=120)   # 'v' = downward triangle\n",
    "            \n",
    "\n",
    "            normal_yunchi_clean = [0 if v == 'NA' else v for v in normal_yunchi]\n",
    "            normal_yunchi_clean2 = [0 if v == 'NA' else v for v in normal_yunchi2]\n",
    "            normal_yunclo_clean = [0 if v == 'NA' else v for v in normal_yunclo]\n",
    "\n",
    "            yhi_arr = np.asarray(normal_yunchi_clean, dtype=float)\n",
    "            yhi2_arr = np.asarray(normal_yunchi_clean, dtype=float)\n",
    "            ylo_arr = np.asarray(normal_yunclo_clean, dtype=float)\n",
    "\n",
    "\n",
    "            y_arr   = np.asarray(normal_y,       dtype=float)\n",
    "            c_arr   = np.asarray(normal_color,   dtype=float)\n",
    "\n",
    "            # Base mask (SNR > 3 and finite)\n",
    "            base_mask = np.isfinite(y_arr) & np.isfinite(yhi_arr) & np.isfinite(yhi2_arr) & np.isfinite(ylo_arr) & ((y_arr / ylo_arr) > 3 )\n",
    "\n",
    "\n",
    "            groups = [\n",
    "                (c_arr < 2.3,  \"c < 2.3\",  'black'),\n",
    "                (c_arr >= 2.3, \"c ≥ 2.3\",  'red'),\n",
    "            ]\n",
    "\n",
    "            y_top_hi_black = y_top_lo_black = np.nan\n",
    "            y_top_hi_red   = y_top_lo_red   = np.nan\n",
    "\n",
    "            for cond, label, col in groups:\n",
    "                mask = base_mask & cond\n",
    "                if np.any(mask):\n",
    "                    #yhi is with includes frequenc effects\n",
    "                    #ylow does not\n",
    "\n",
    "                    y_top_hi_array=[]\n",
    "                    y_top_lo_array=[]\n",
    "\n",
    "                    y_top_hi2_array=[]\n",
    "\n",
    "\n",
    "                    for iy, iyhi, iyhi2, iylo in zip(y_arr[mask], yhi_arr[mask], yhi2_arr[mask],  ylo_arr[mask]):\n",
    "                        iyhi_lin = log_to_linear_uncertainty(iy, iyhi)\n",
    "                        iyhi2_lin = log_to_linear_uncertainty(iy, iyhi2)\n",
    "                        iylo_lin = log_to_linear_uncertainty(iy, iylo)\n",
    "                        iy_lin = 10**iy\n",
    "\n",
    "                        y_top_hi_array.append([iy_lin+iyhi_lin,iy+iyhi])\n",
    "\n",
    "                        y_top_hi2_array.append([iy_lin+iyhi2_lin,iy+iyhi2])\n",
    "\n",
    "                        y_top_lo_array.append([iy_lin+iylo_lin,iy+iylo])\n",
    "\n",
    "\n",
    "                    \n",
    "                    y_top_hi, logytop_hi = np.nanmax(np.array(y_top_hi_array), axis=0)\n",
    "                    y_top_lo, logytop_lo = np.nanmax(np.array(y_top_lo_array), axis=0)\n",
    "\n",
    "                      \n",
    "                    if col == 'black':   # <200 GHz\n",
    "                        y_top_hi_black, y_top_lo_black = y_top_hi, y_top_lo\n",
    "                    elif col == 'red':   # ≥200 GHz\n",
    "                        y_top_hi_red, y_top_lo_red = y_top_hi, y_top_lo\n",
    "\n",
    "\n",
    "                    # hi → solid line\n",
    "                    ax.axhline(logytop_hi, color=col, linestyle='--', linewidth=0.6, zorder=10,\n",
    "                            label=f\"max hi {label}\")\n",
    "\n",
    "                    # lo → dashed line\n",
    "                    ax.axhline(logytop_lo, color=col, linestyle='-', linewidth=0.6, zorder=10,\n",
    "                            label=f\"max lo {label}\")\n",
    "\n",
    "\n",
    "            cbar = pylab.colorbar(sm, ax=ax)\n",
    "\n",
    "\n",
    "            #pylab.scatter(normal_x, normal_y, c=normal_color, marker='o', s=5, )\n",
    "            pylab.grid(True)\n",
    "                \n",
    "\n",
    "            for x, y, c in zip(adjusted_x_times, adjusted_y, adjusted_color):\n",
    "                col = cmap(norm(c))\n",
    "                if c>2.3:\n",
    "                    input('error')\n",
    "                    #shape = 'D' if c > 2.3 \n",
    "                else:\n",
    "                    shape='v'\n",
    "                pylab.scatter(x, y,\n",
    "                            facecolors='none', edgecolors=col,\n",
    "                            marker=shape, s=40)\n",
    "\n",
    "\n",
    "            pylab.xlabel(r'log$_{10}$ Time Scale [years]')\n",
    "\n",
    "\n",
    "            legend_elements = []\n",
    "            \n",
    "            # figure out which markers were used\n",
    "            has_diamond = any(c <= 2.3 for c in adjusted_color)\n",
    "            has_triangle = any(c > 2.3 for c in adjusted_color)\n",
    "\n",
    "            if np.isfinite(y_top_hi_black):\n",
    "                legend_elements.append(Line2D([0], [0], marker='s', color='black', markerfacecolor='none',\n",
    "                    markersize=6, linestyle='None', label='<200GHz'))\n",
    "                \n",
    "            if has_diamond:\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], marker='v', linestyle='None',\n",
    "                        markerfacecolor='none', markeredgecolor='black',\n",
    "                        markersize=6, label='<200GHz No Variability (<1%)')\n",
    "                )\n",
    "            if np.isfinite(y_top_lo_black):\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color='black', linewidth=1, linestyle='-',\n",
    "                        label=fr'<200GHz Top Bound Variability $\\alpha=0$: {y_top_lo_black:.1f}%')\n",
    "                )\n",
    "            if np.isfinite(y_top_hi_black):\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color='black', linewidth=1, linestyle='--',\n",
    "                        label=fr'<200GHz Top Bound Variability $\\alpha=+2.5$: {y_top_hi_black:.1f}%')\n",
    "                )\n",
    "            if np.isfinite(y_top_hi_red):\n",
    "                legend_elements.append(Line2D([0], [0], marker='o', color='red', markerfacecolor='none',\n",
    "                    markersize=6, linestyle='None', label='>200GHz'))\n",
    "            if has_triangle:\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], marker='D', linestyle='None',\n",
    "                        markerfacecolor='none', markeredgecolor='black',\n",
    "                        markersize=6, label='>200GHz No Variability (<1%)')\n",
    "                )\n",
    "            if np.isfinite(y_top_lo_red):\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color='red', linewidth=1, linestyle='-',\n",
    "                        label=fr'>200GHz Top Bound Variability $\\alpha=0$: {y_top_lo_red:.1f}%')\n",
    "                )\n",
    "            if np.isfinite(y_top_hi_red):\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color='red', linewidth=1, linestyle='--',\n",
    "                        label=fr'>200GHz Top Bound Variability $\\alpha=+2.5$: {y_top_hi_red:.1f}%')\n",
    "                )\n",
    "\n",
    "            ax.legend(handles=legend_elements, loc=\"best\", frameon=False, fontsize=7)\n",
    "            \n",
    "            # inside your loop, after legend_elements is built\n",
    "            if source not in source_labels:\n",
    "                source_labels[source] = []\n",
    "\n",
    "            for h in legend_elements:\n",
    "                label = h.get_label()\n",
    "                if ':' in label:  # only keep the ones with values\n",
    "                    source_labels[source].append(label)\n",
    "\n",
    "\n",
    "        \n",
    "            if grapher=='variability':\n",
    "                pylab.title(f'{source} Variability')\n",
    "                pylab.ylabel(r'$\\log_{10}\\ \\mathrm{Flux\\ [mJy]\\ [Beam]^{-1}}\\ \\mathrm{Difference\\ [\\%]}$')\n",
    "            elif grapher=='compactness':\n",
    "                pylab.title(f'{source} Compactness')\n",
    "                pylab.ylabel(r'log$_{10}$ Beam Size [\"] Difference [%]')\n",
    "\n",
    "            x_tick_positions = np.arange(-3,1.6, 0.5)  \n",
    "            #x_tick_positions = np.arange(minfreqp, maxfreqp + 0.1 , 0.1) \n",
    "            x_tick_labels =  [f\"{pos:.2f}\" for pos in x_tick_positions] \n",
    "\n",
    "            cbar.set_label(r'log$_{10}$ Frequency [GHz]')  # <-- put your label here\n",
    "\n",
    "            # Suppose you want a tick every 5 units\n",
    "            major_ticks = np.arange(vmin_rounded, vmax_rounded, 1)\n",
    "            cbar.set_ticks(major_ticks)\n",
    "\n",
    "            # (Optional) format the labels\n",
    "            cbar.set_ticklabels([str(t) for t in major_ticks])\n",
    "\n",
    "\n",
    "            # generate candidate minor ticks\n",
    "            step = (major_ticks[1] - major_ticks[0]) / 5\n",
    "            minor_tick_locations_date = np.arange(vmin_rounded, vmax_rounded, step)\n",
    "\n",
    "            # get the major ticks from the colorbar\n",
    "            major_ticks = cbar.get_ticks()\n",
    "\n",
    "            # filter out anything already a major tick\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations_date \n",
    "                                    if tick not in major_ticks]\n",
    "\n",
    "            # apply as minor ticks\n",
    "            cbar.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "\n",
    "\n",
    "            #ax.set_xlim([-2.7, 1])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "\n",
    "            y_tick_positions = np.arange(0, 2.1 , 0.5) \n",
    "            #y_tick_positions = np.arange(miny, maxy + 0.1 , 0.1) \n",
    "            y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  \n",
    "\n",
    "            #ax.set_ylim([-0.1, 1.8]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locatorx = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locatorx)\n",
    "            minor_locatory = MultipleLocator(0.1)\n",
    "            ax.yaxis.set_minor_locator(minor_locatory)\n",
    "\n",
    "            graphtype='Variability'\n",
    "\n",
    "            nicename=f\"{source}_{graphtype}.pdf\"\n",
    "            if not os.path.exists(f'{graphtype}Graphs'):\n",
    "                os.makedirs(f'{graphtype}Graphs')\n",
    "            if os.path.exists(f'{graphtype}Graphs/{nicename}'):\n",
    "                os.remove(f'{graphtype}Graphs/{nicename}')\n",
    "            if printall==False:\n",
    "                pylab.savefig(f'{graphtype}Graphs/{nicename}', bbox_inches='tight', dpi=300)\n",
    "                pylab.savefig(f'{graphtype}Graphs/{nicename}', dpi=300)\n",
    "                pylab.show()\n",
    "            else:\n",
    "             pylab.clf() \n",
    "\n",
    "    if write==True:\n",
    "        sys.stdout = original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source, labels in source_labels.items():\n",
    "    print(source, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#circinus\n",
    "val=14.54/(14.54+0.00132)*13.3+0.00132/(14.54+0.00132)*27.9\n",
    "val=val/100\n",
    "val=(2+val)/(2-val)\n",
    "print(val)\n",
    "print(val*14.54-14.54)\n",
    "print(14.54-14.54/val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
