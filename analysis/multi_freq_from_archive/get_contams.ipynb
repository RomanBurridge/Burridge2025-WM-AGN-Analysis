{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Here for Making Flux Size Graphs\n",
    "\n",
    "import os\n",
    "os.chdir('analysis/multi_freq_from_archive')\n",
    "#format beamsize number\n",
    "def format_number(number):\n",
    "        # Case 1: If the number is less than 1 (e.g., 0.004567)\n",
    "        if number < 0:\n",
    "                # Format the positive part of the number and prepend the negative sign\n",
    "                return \"-\" + format_number(abs(number))\n",
    "        if number < 1:\n",
    "                # Convert the number to a string with high precision\n",
    "                num_str = f\"{number:.16g}\"\n",
    "\n",
    "                # Identify the leading zeros and decimal point\n",
    "                leading_part = []\n",
    "                for char in num_str:\n",
    "                        if char == '0' or char == '.':\n",
    "                                leading_part.append(char)\n",
    "                        else:\n",
    "                                break\n",
    "\n",
    "                # Remove leading zeros and the decimal point for significant digits\n",
    "                significant_digits = \"\".join(char for char in num_str if char.isdigit() and char != \"0\")\n",
    "\n",
    "                # Extract the first two non-zero digits\n",
    "                if len(significant_digits) >= 2:\n",
    "                        first_two = significant_digits[:2]\n",
    "                elif len(significant_digits) == 1:\n",
    "                        first_two = significant_digits + \"0\"  # Pad with zero if only one significant digit exists\n",
    "                else:\n",
    "                        first_two = \"00\"  # Handle edge case like 0\n",
    "\n",
    "                # Combine the leading zeros and the first two non-zero digits\n",
    "                return \"\".join(leading_part) + first_two\n",
    "\n",
    "        # Case 2: If the number is greater than or equal to 1\n",
    "        else:\n",
    "                # Format to two decimal places\n",
    "                return f\"{number:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spectral Plots\n",
    "import matplotlib.pyplot as pylab\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import matplotlib.cm as cmx\n",
    "import math\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import copy\n",
    "\n",
    "def round_down_to_half_integer(num):\n",
    "    return math.floor(num * 2) / 2\n",
    "\n",
    "def round_up_to_half_integer(num):\n",
    "    return math.ceil(num * 2) / 2\n",
    "\n",
    "msize=10\n",
    "\n",
    "path = f'SpectraGraphs'\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "freqs=[]\n",
    "fluxs=[]\n",
    "beams=[]\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    jfin=-1\n",
    "    for line in infile:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        jfin=jfin+1 \n",
    "\n",
    "grouped_data = {}\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    for line in infile:\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        \n",
    "        line=eval(line)\n",
    "        source=line[0]\n",
    "        j=j+1\n",
    "        \n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if source not in grouped_data:\n",
    "            grouped_data[source] = {\n",
    "                'sfreqs': [], 'sfluxs': [], 'sbeams': [], 'sdates': [],\n",
    "                'sfreqs2': [], 'sfluxs2': [], 'sbeams2': [], 'sdates2': [],\n",
    "            }\n",
    "\n",
    "        if j==0:\n",
    "            minfreq=freq\n",
    "            maxfreq=freq\n",
    "            minflux=flux\n",
    "            maxflux=flux\n",
    "            minbeam=beam\n",
    "            maxbeam=beam\n",
    "        if j!=0:\n",
    "            if freq>maxfreq:\n",
    "                maxfreq=freq\n",
    "            if freq<minfreq:\n",
    "                minfreq=freq\n",
    "            if flux>maxflux:\n",
    "                maxflux=flux\n",
    "            if flux<minflux:\n",
    "                minflux=flux\n",
    "            if beam>maxbeam:\n",
    "                maxbeam=beam\n",
    "            if beam<minbeam:\n",
    "                minbeam=beam\n",
    "\n",
    "minfreqp=round_down_to_half_integer(minfreq)\n",
    "maxfreqp=round_up_to_half_integer(maxfreq)\n",
    "\n",
    "minfluxp=round_down_to_half_integer(minflux)\n",
    "maxfluxp=round_up_to_half_integer(maxflux)\n",
    "\n",
    "minbeamp=round_down_to_half_integer(minbeam)\n",
    "maxbeamp=round_up_to_half_integer(maxbeam)\n",
    "\n",
    "interval = maxfreqp - minfreqp\n",
    "ten_percent = interval * 0.05\n",
    "minfreq = minfreqp - ten_percent\n",
    "maxfreq = maxfreqp + ten_percent\n",
    "\n",
    "interval = maxfluxp - minfluxp\n",
    "ten_percent = interval * 0.05\n",
    "minflux = minfluxp - ten_percent\n",
    "maxflux = maxfluxp + ten_percent\n",
    "\n",
    "interval = maxbeamp - minbeamp\n",
    "ten_percent = interval * 0.05\n",
    "minbeam = minbeamp - ten_percent\n",
    "maxbeam = maxbeamp + ten_percent\n",
    "\n",
    "\n",
    "x_tick_positions=np.arange(minfreqp, maxfreqp + 0.5 , 0.5)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.arange(minfluxp, maxfluxp + 0.5, 0.5)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "stick_positions = np.arange(minbeamp, maxbeamp + 1, 1)  # 6 evenly spaced ticks\n",
    "stick_labels = [f\"{pos:.2f}\" for pos in stick_positions]  # Convert log to linear\n",
    "\n",
    "source_text='fitsumfiles/final/fitsummary_final_withextras.txt'\n",
    "\n",
    "sourcedone=[]\n",
    "sources=[]\n",
    "\n",
    "oldsources=[]\n",
    "oldsource='NA'\n",
    "\n",
    "with open(source_text, 'r') as infile:\n",
    "    j=-1\n",
    "    j2=-1\n",
    "    for line in infile:\n",
    "        j2=j2+1 \n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        line=eval(line)\n",
    "\n",
    "        source=line[0]\n",
    "        breaker=1\n",
    "        j=j+1\n",
    "\n",
    "        if j==0:\n",
    "            sbeamsizes=[]\n",
    "            sdates=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sbeamsizes2=[]\n",
    "            sdates2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "\n",
    "            \n",
    "        breaker=0\n",
    "\n",
    "        sources.append(source)\n",
    "        sources=list(set(sources))\n",
    "\n",
    "        if len(sources)-len(oldsources)!=0 and j!=0:\n",
    "            source=oldsource\n",
    "\n",
    "            for isource in sourcedone:\n",
    "                if source==isource:\n",
    "                    breaker=1\n",
    "            if breaker==1:\n",
    "                continue\n",
    "            sourcedone.append(source)\n",
    "\n",
    "            fig, ax = pylab.subplots()\n",
    "            cm2 = pylab.get_cmap('jet')   \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source}',fontsize=20)\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "                os.makedirs(f'SpectraGraphs/{source}')\n",
    "            if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.savefig(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "            sbeamsizes=[]\n",
    "            sfluxs=[]\n",
    "            sfreqs=[]\n",
    "            sdates=[]\n",
    "\n",
    "            sbeamsizes2=[]\n",
    "            sfluxs2=[]\n",
    "            sfreqs2=[]\n",
    "            sdates2=[]\n",
    "\n",
    "        if j2==jfin-1:\n",
    "            if line=='\\n':\n",
    "                continue\n",
    " \n",
    "            fig, ax = pylab.subplots()\n",
    "            cm2 = pylab.get_cmap('jet')   \n",
    "            sNorm = matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam)\n",
    "            scalarMap2 = cmx.ScalarMappable(norm=sNorm, cmap=cm2)\n",
    "\n",
    "            def assign_colors(beamsizes):\n",
    "                colors = []\n",
    "                for size in beamsizes:\n",
    "                    colors.append(scalarMap2.to_rgba(size))  # Use colormap for valid sizes\n",
    "                return colors\n",
    "            \n",
    "            colors2 = assign_colors(sbeamsizes2)\n",
    "            colors = assign_colors(sbeamsizes)\n",
    "\n",
    "            if len(sfreqs2)!=0:\n",
    "                pylab.scatter(sfreqs2,sfluxs2, c=colors2,marker='v',s=msize) \n",
    "\n",
    "            if len(sfreqs)!=0:\n",
    "                pylab.scatter(sfreqs,sfluxs, c=colors,s=msize)\n",
    "\n",
    "            colorbar1 = fig.colorbar(\n",
    "                    cmx.ScalarMappable(norm=matplotlib.colors.Normalize(vmin=minbeam, vmax=maxbeam), cmap=cm2),\n",
    "                    label='Beamsize [\"]',\n",
    "                    ax=ax,\n",
    "                    ticks=stick_positions\n",
    "                    )\n",
    "            \n",
    "            colorbar1.set_label(\n",
    "                r'log$_{10}$ Beamsize [\"]'\n",
    "            )\n",
    "\n",
    "            minor_tick_locations = np.arange(minbeamp, maxbeamp, 0.1)\n",
    "            major_ticks = colorbar1.get_ticks()\n",
    "            filtered_minor_ticks = [tick for tick in minor_tick_locations if tick not in major_ticks]\n",
    "            colorbar1.ax.yaxis.set_ticks(filtered_minor_ticks, minor=True)\n",
    "            \n",
    "            ax = pylab.gca()\n",
    "            ax.set_xlim([minfreq, maxfreq])\n",
    "            ax.set_xticks(x_tick_positions)\n",
    "            ax.set_xticklabels(x_tick_labels)\n",
    "\n",
    "            ax.set_ylim([minflux, maxflux]) \n",
    "            ax.set_yticks(y_tick_positions)\n",
    "            ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "            minor_locator = MultipleLocator(0.1)\n",
    "            ax.xaxis.set_minor_locator(minor_locator)\n",
    "            ax.yaxis.set_minor_locator(minor_locator)\n",
    "                                \n",
    "            pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "            pylab.xlabel(r'log$_{10}$ Frequency [GHz]')\n",
    "            pylab.title(f'{source}',fontsize=20)\n",
    "            pylab.ylabel(r'log$_{10}$ Flux [mJy][Beam]$^{-1}$')\n",
    "            nicename=f'{source} Spectra.pdf'\n",
    "            if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "                os.makedirs(f'SpectraGraphs/{source}')\n",
    "            if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "                os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.savefig(f'SpectraGraphs/{source}/{nicename}')\n",
    "            #pylab.show()\n",
    "            pylab.clf() \n",
    "\n",
    "            grouped_data[source]['sfreqs']=sfreqs\n",
    "            grouped_data[source]['sfluxs']=sfluxs\n",
    "            grouped_data[source]['sbeams']=sbeamsizes\n",
    "            grouped_data[source]['sdates']=sdates\n",
    "\n",
    "            grouped_data[source]['sfreqs2']=sfreqs2\n",
    "            grouped_data[source]['sfluxs2']=sfluxs2\n",
    "            grouped_data[source]['sbeams2']=sbeamsizes2\n",
    "            grouped_data[source]['sdates2']=sdates2\n",
    "\n",
    "\n",
    "        oldsource=source\n",
    "\n",
    "        flux_upperb=0\n",
    "        if len(str(line[3]).split('*'))>1:\n",
    "            flux_upperb=1\n",
    "\n",
    "        freq=np.log10(float(line[2]))\n",
    "        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "        odate=line[4]\n",
    "        if odate!='NA':\n",
    "            odate=odate.split('/')\n",
    "            date=float(odate[0]) + float(odate[1]) / 12 + float(odate[2]) / 365\n",
    "        else:\n",
    "            date='NA'\n",
    "\n",
    "        if '-' not in line[5]:\n",
    "            beam=np.log10(float(line[5]))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if flux_upperb==0:\n",
    "            sbeamsizes.append(beam)\n",
    "            sfluxs.append(flux)\n",
    "            sfreqs.append(freq)\n",
    "            sdates.append(date)\n",
    "\n",
    "        if flux_upperb==1:\n",
    "            sbeamsizes2.append(beam)\n",
    "            sfluxs2.append(flux)\n",
    "            sfreqs2.append(freq)\n",
    "            sdates2.append(date)\n",
    "\n",
    "        oldsources=copy.deepcopy(sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functino to Group frequencies dynamically\n",
    "def group_by_frequency(freqs, fluxes, beams, dates, tolerance):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    current_group_freqs, current_group_fluxes, current_group_beams, current_group_dates = [], [], [], []\n",
    "\n",
    "    sorted_data = sorted(zip(freqs, fluxes, beams, dates), key=lambda x: x[0])\n",
    "    for freq, flux, beam, date in sorted_data:\n",
    "        if not current_group_freqs or abs(freq - current_group_freqs[0]) <= tolerance:\n",
    "            current_group_freqs.append(freq)\n",
    "            current_group_fluxes.append(flux)\n",
    "            current_group_beams.append(beam)\n",
    "            current_group_dates.append(date)\n",
    "        else:\n",
    "            grouped_freqs.append(current_group_freqs)\n",
    "            grouped_fluxes.append(current_group_fluxes)\n",
    "            grouped_beams.append(current_group_beams)\n",
    "            grouped_dates.append(current_group_dates)\n",
    "            current_group_freqs = [freq]\n",
    "            current_group_fluxes = [flux]\n",
    "            current_group_beams = [beam]\n",
    "            current_group_dates = [date]\n",
    "\n",
    "    if current_group_freqs:\n",
    "        grouped_freqs.append(current_group_freqs)\n",
    "        grouped_fluxes.append(current_group_fluxes)\n",
    "        grouped_beams.append(current_group_beams)\n",
    "        grouped_dates.append(current_group_dates)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define frequency ranges for VLA and ALMA bands\n",
    "vla_bands = [\n",
    "    (0.0,0.054) ,     #for Rounding \n",
    "    (0.054, 0.086),  # 4 Band\n",
    "    (0.230, 0.470),  # P Band\n",
    "    (1, 2),          # L Band\n",
    "    (2, 4),          # S Band\n",
    "    (4, 8),          # C Band\n",
    "    (8, 12),         # X Band\n",
    "    (12, 18),        # Ku Band\n",
    "    (18, 26.5),      # K Band\n",
    "    (26.5, 40),      # Ka Band\n",
    "    (40, 50),        # Q Band\n",
    "]\n",
    "\n",
    "alma_bands = [\n",
    "    (31.3, 45),   # Band 1\n",
    "    (67, 90),     # Band 2\n",
    "    (84, 116),    # Band 3\n",
    "    (125, 163),   # Band 4\n",
    "    (163, 211),   # Band 5\n",
    "    (211, 275),   # Band 6\n",
    "    (275, 373),   # Band 7\n",
    "    (385, 500),   # Band 8\n",
    "    (602, 720),   # Band 9\n",
    "    (787, 950),   # Band 10\n",
    "]\n",
    "\n",
    "# Combine all boundaries and create continuous intervals\n",
    "all_boundaries = sorted(set([freq for band in vla_bands + alma_bands for freq in band]))\n",
    "non_overlapping_intervals = [(all_boundaries[i], all_boundaries[i + 1]) for i in range(len(all_boundaries) - 1)]\n",
    "\n",
    "# Remove gaps by ensuring no holes\n",
    "continuous_intervals = []\n",
    "for i, (start, end) in enumerate(non_overlapping_intervals):\n",
    "    if i > 0 and start > continuous_intervals[-1][1]:\n",
    "        # Fill the gap between the previous interval and the current one\n",
    "        continuous_intervals.append((continuous_intervals[-1][1], start))\n",
    "    continuous_intervals.append((start, end))\n",
    "\n",
    "# Function to check if a frequency is in any interval\n",
    "def is_frequency_in_intervals(frequency, intervals):\n",
    "    for start, end in intervals:\n",
    "        if start <= frequency < end:  # Check if frequency is in the interval\n",
    "            return True, (start, end)\n",
    "    return False, None\n",
    "\n",
    "# Print all intervals for verification\n",
    "print(\"\\nAll continuous intervals:\")\n",
    "for i, interval in enumerate(continuous_intervals):\n",
    "    print(f\"Interval {i + 1}: {interval[0]}–{interval[1]} GHz\")\n",
    "\n",
    "def group_by_band(freqs, fluxes, beams, dates, intervals):\n",
    "    grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = [], [], [], []\n",
    "    interval_mapping = {interval: ([], [], [], []) for interval in intervals}\n",
    "\n",
    "    for freq, flux, beam, date in zip(freqs, fluxes, beams, dates):\n",
    "        found, assigned_interval = is_frequency_in_intervals(freq, intervals)\n",
    "        if found:\n",
    "            interval_mapping[assigned_interval][0].append(freq)\n",
    "            interval_mapping[assigned_interval][1].append(flux)\n",
    "            interval_mapping[assigned_interval][2].append(beam)\n",
    "            interval_mapping[assigned_interval][3].append(date)\n",
    "\n",
    "    for interval, (freq_list, flux_list, beam_list, date_list) in interval_mapping.items():\n",
    "        if freq_list:\n",
    "            grouped_freqs.append(freq_list)\n",
    "            grouped_fluxes.append(flux_list)\n",
    "            grouped_beams.append(beam_list)\n",
    "            grouped_dates.append(date_list)\n",
    "\n",
    "    return grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Statistical Spectral Plots\n",
    "# Define tolerance for grouping frequencies (log space)\n",
    "tolerance = .05\n",
    "\n",
    "#define if it should be grouped dynamicall or by band\n",
    "grouper='byband'\n",
    "#grouper='bydynam'\n",
    "\n",
    "# Generate consistent x-axis and y-axis tick positions\n",
    "x_tick_positions = np.linspace(minfreq, maxfreq, num=6)  # 6 evenly spaced ticks\n",
    "x_tick_labels = [f\"{10**pos:.2f}\" for pos in x_tick_positions]  # Convert log to linear\n",
    "\n",
    "y_tick_positions = np.linspace(minflux, maxflux, num=6)  # 6 evenly spaced ticks\n",
    "y_tick_labels = [f\"{10**pos:.2f}\" for pos in y_tick_positions]  # Convert log to linear\n",
    "\n",
    "# Apply grouping to all sources\n",
    "for source, data in grouped_data.items():\n",
    "    if grouper=='bydynam':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_frequency(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'],data['sdates'],tolerance\n",
    "        )\n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_frequency(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'],tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_data[source]['grouped_sfreqs'], grouped_data[source]['grouped_sfluxs'], grouped_data[source]['grouped_sbeams'], grouped_data[source]['grouped_sdates'] = group_by_band(\n",
    "            data['sfreqs'], data['sfluxs'], data['sbeams'], data['sdates'], continuous_intervals\n",
    "        )\n",
    "        \n",
    "        grouped_data[source]['grouped_sfreqs2'], grouped_data[source]['grouped_sfluxs2'], grouped_data[source]['grouped_sbeams2'], grouped_data[source]['grouped_sdates2'] = group_by_band(\n",
    "            data['sfreqs2'], data['sfluxs2'], data['sbeams2'], data['sdates2'], continuous_intervals\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize combined arrays\n",
    "combined_freqs = []  # Combined frequencies\n",
    "combined_fluxes = []  # Combined fluxes\n",
    "combined_beams = []  # Combined beam sizes\n",
    "\n",
    "for source, data in grouped_data.items():\n",
    "    # Combine all frequency, flux, and beam data for the current source\n",
    "    combined_freqs = data['sfreqs'] \n",
    "    combined_fluxes = data['sfluxs'] \n",
    "    combined_beams = data['sbeams'] \n",
    "    combined_dates = data['sdates'] \n",
    "\n",
    "    combined_freqs_2 = data['sfreqs2']\n",
    "    combined_fluxes_2 = data['sfluxs2'] \n",
    "    combined_beams_2 = data['sbeams2'] \n",
    "    combined_dates_2 = data['sdates2'] \n",
    "\n",
    "    # Group the combined data dynamically for the current source\n",
    "    if grouper=='bydynam':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_frequency(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, tolerance\n",
    "        )\n",
    "\n",
    "    if grouper=='byband':\n",
    "        grouped_freqs, grouped_fluxes, grouped_beams, grouped_dates = group_by_band(\n",
    "            combined_freqs, combined_fluxes, combined_beams, combined_dates, continuous_intervals\n",
    "        )\n",
    "\n",
    "    # Iterate over grouped combined data\n",
    "    for freq_group, flux_group, beam_group in zip(grouped_freqs, grouped_fluxes, grouped_beams):\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        group_size = len(flux_group)\n",
    "        central_freq = np.mean(freq_group)\n",
    "        if group_size >= 4:\n",
    "            pylab.boxplot(flux_group, positions=[central_freq],widths=0.1,\n",
    "            showfliers=False)  # Customize outliers\n",
    "        elif group_size == 3:\n",
    "            # Vertical line with caps at min and max\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = np.median(flux_group)\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5,  # Length of caps\n",
    "                color='k'\n",
    "            )\n",
    "            # Add a horizontal line at the median_flux\n",
    "            pylab.hlines(\n",
    "                y=median_flux,  # Position of the horizontal line\n",
    "                xmin=central_freq - 0.05,  # Adjust as needed for length\n",
    "                xmax=central_freq + 0.05, \n",
    "                color='r',  # Color of the line\n",
    "                linewidth=1  # Thickness of the horizontal line\n",
    "            )\n",
    "        elif group_size == 2:\n",
    "            # Vertical line with caps at min and max (no median)\n",
    "            min_flux, max_flux = min(flux_group), max(flux_group)\n",
    "            median_flux = (min_flux + max_flux) / 2  # Just for centering the line\n",
    "            pylab.errorbar(\n",
    "                x=[central_freq], \n",
    "                y=[median_flux], \n",
    "                yerr=[[median_flux - min_flux], [max_flux - median_flux]], \n",
    "                capsize=5, \n",
    "                color='k'\n",
    "            )\n",
    "\n",
    "        elif group_size == 1:\n",
    "            pylab.scatter([central_freq], [flux_group[0]], c='b', marker='o', s=10)\n",
    "\n",
    "    if combined_fluxes_2:  # Ensure '2' fluxes exist\n",
    "        if not combined_fluxes or min(combined_fluxes_2) < min(combined_fluxes):\n",
    "            # If main fluxes are empty OR '2' minimum is lower\n",
    "            min_flux_2 = min(combined_fluxes_2)\n",
    "            min_flux_2_index = combined_fluxes_2.index(min_flux_2)\n",
    "            min_freq_2 = combined_freqs_2[min_flux_2_index]\n",
    "            # Mark the lowest value with a downward triangle\n",
    "            pylab.scatter([min_freq_2], [min_flux_2], c='black', marker='v', s=7, label='Min Flux from 2')\n",
    "\n",
    "\n",
    "    # Set consistent x and y limits for all plots\n",
    "    pylab.xlim(minfreq - 0.1, maxfreq + 0.1)  # Add slight padding\n",
    "    pylab.ylim(minflux - 0.1, maxflux + 0.1)  # Add slight padding\n",
    "    # Set consistent x-axis ticks and labels\n",
    "    # Set consistent x-axis and y-axis ticks and labels\n",
    "    pylab.xticks(x_tick_positions, x_tick_labels)\n",
    "    pylab.yticks(y_tick_positions, y_tick_labels)\n",
    "\n",
    "    # Add labels and title\n",
    "    pylab.xlabel('Frequency [GHz]')\n",
    "    pylab.ylabel(r'Flux [mJy][Beam]$^{-1}$')\n",
    "    pylab.title(f'{source}')\n",
    "\n",
    "    nicename=f'{source} statistical spectra.pdf'\n",
    "    if not os.path.exists(f'SpectraGraphs/{source}'):\n",
    "        os.makedirs(f'SpectraGraphs/{source}')\n",
    "    if os.path.exists(f'SpectraGraphs/{source}/{nicename}'):\n",
    "        os.remove(f'SpectraGraphs/{source}/{nicename}')\n",
    "    #pylab.savefig(f'SpectraGraphs/{source}/{nicename}')\n",
    "    #pylab.show()\n",
    "    pylab.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make function to get distances\n",
    "\n",
    "import os\n",
    "from astroquery.ned import Ned\n",
    "import ast  # For safely parsing text file data\n",
    "\n",
    "import os\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "from scipy import constants\n",
    "c=constants.c\n",
    "\n",
    "def is_subsequence(small, large):\n",
    "    it = iter(large)\n",
    "    return all(char in it for char in small)\n",
    "\n",
    "def decompose_string(s):\n",
    "    parts = re.findall(r\"[A-Za-z]+|\\d+\", s)  # Finds all letter and number sequences\n",
    "    return parts if parts else [s]\n",
    "\n",
    "# Input file with source names and coordinates\n",
    "txtnamesandcoords = 'namesandcoords.txt'\n",
    "\n",
    "# List of desired reference codes\n",
    "wantrefs = ['2018ApJ...863..', '2023ApJ...948..', '2020ApJ...890..', '2020ApJ...891..']\n",
    "\n",
    "def getdists(newnames):\n",
    "    newrefs=[]\n",
    "    if not os.path.exists('distancetable.csv'):\n",
    "        url = 'https://ned.ipac.caltech.edu/Archive/Distances/NED30.5.1-D-17.1.2-20200415.csv'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open('distancetable.csv', \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            return(f\"Failed to download. Status code: {response.status_code}\")\n",
    "    \n",
    "    maserdist=[]\n",
    "    otherdist=[]\n",
    "    j1=-1\n",
    "    j2=-1\n",
    "    with open('distancetable.csv', \"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            textsource=row[3]\n",
    "            if len(textsource)==0:\n",
    "                continue\n",
    "            textdistmm=row[4]\n",
    "            textdistmmerr=row[5]\n",
    "\n",
    "            textdistMpc=row[6]\n",
    "            textmethod=row[7]\n",
    "            refcode=row[8]\n",
    "\n",
    "\n",
    "            textsource=textsource.replace(' ','')\n",
    "\n",
    "            findred=0\n",
    "            for i in newnames:\n",
    "                checkers=[]\n",
    "                for ii in i:\n",
    "                    ii=ii.split('Galaxy')[0]\n",
    "                    if is_subsequence(ii, textsource):\n",
    "                        checkers.append(ii)\n",
    "                if len(checkers)==len(i):\n",
    "                    if row[10]:\n",
    "                        findred=1\n",
    "                        redshift=row[10]\n",
    "                        Hubble=row[11]\n",
    "                        newdist=c*float(redshift)/float(Hubble)*c\n",
    "                    \n",
    "                    if textdistmmerr:\n",
    "                        if float(textdistmmerr)>0:\n",
    "                            if 'maser' in textmethod.lower():\n",
    "                                j1=j1+1\n",
    "                                newrefs.append(refcode)\n",
    "                                if j1==0:\n",
    "                                        maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                        maserdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<maserdisuncer:\n",
    "                                    maserdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                            else:\n",
    "                                j2=j2+1\n",
    "                                if j2==0:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "                                    otherdisuncer=textdistmmerr\n",
    "                                elif textdistmmerr<otherdisuncer:\n",
    "                                    otherdist=[textsource,textdistmm,textdistmmerr,textdistMpc,textmethod,refcode]\n",
    "\n",
    "    return(maserdist,otherdist,refcode,findred,newrefs)\n",
    "\n",
    "# Function to process each source\n",
    "def process_source(source_name, wantrefs, ra, dec,threshold, secondarynames):\n",
    "  \n",
    "    \"\"\"Query NED for redshift data and filter based on references and uncertainties.\"\"\"\n",
    "    # Skip excluded sources\n",
    "\n",
    "    # Query the redshift table from NED\n",
    "    distances_table = Ned.get_table(source_name, table='redshifts')\n",
    "\n",
    "    # Extract relevant columns\n",
    "    redshifts = distances_table['Published Redshift']\n",
    "    uncertainties = distances_table['Published Redshift Uncertainty']\n",
    "    refcodes = distances_table['Refcode']\n",
    "\n",
    "    # Combine into tuples\n",
    "    entries = [\n",
    "        (redshift, uncertainty, refcode)\n",
    "        for redshift, uncertainty, refcode in zip(redshifts, uncertainties, refcodes)\n",
    "    ]\n",
    "\n",
    "    # Filter for entries with desired references\n",
    "    desired_entries = [\n",
    "        entry for entry in entries if any(ref in entry[2] for ref in wantrefs)\n",
    "    ]\n",
    "\n",
    "    entries_with_reference = []\n",
    "    entries_without_reference = []\n",
    "\n",
    "    for redshift, uncertainty, refcode in desired_entries:\n",
    "        if any(ref in refcode for ref in wantrefs):  # Check if refcode contains a wanted reference\n",
    "            entries_with_reference.append((redshift, uncertainty, refcode))\n",
    "        else:\n",
    "            entries_without_reference.append((redshift, uncertainty, refcode))\n",
    "\n",
    "\n",
    "    reduced_entries = {}\n",
    "\n",
    "    # Step 2a: Prioritize entries from `entries_with_reference`\n",
    "    if entries_with_reference:\n",
    "        for redshift, uncertainty, refcode in entries_with_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "    if len(reduced_entries)==0:\n",
    "        # Step 2b: If `entries_with_reference` is empty, use `entries_without_reference`\n",
    "        for redshift, uncertainty, refcode in entries_without_reference:\n",
    "            if uncertainty > 0:  # Ignore entries with zero uncertainty\n",
    "                if refcode not in reduced_entries or uncertainty < reduced_entries[refcode][1]:\n",
    "                    reduced_entries[refcode] = (redshift, uncertainty)\n",
    "\n",
    "\n",
    "\n",
    "    # Print results based on the filtering\n",
    "    redshift='NA'\n",
    "    uncertainty='NA'\n",
    "\n",
    "    newnames=[]\n",
    "    newlist=decompose_string(secondarynames[0][0])\n",
    "\n",
    "    newnames.append(newlist)\n",
    "    if len(secondarynames[0][1])!=0:\n",
    "        if secondarynames[0][1][0]!='NA':\n",
    "            for i in secondarynames[0][1]:\n",
    "                if not is_subsequence(secondarynames[0][0], i):\n",
    "                    newlist=decompose_string(i)\n",
    "                    newnames.append(newlist)\n",
    "\n",
    "    maserdists, otherdists, inewrefs, findred, newrefs = getdists(newnames)\n",
    "\n",
    "    if reduced_entries:\n",
    "        for irefcode, (iredshift, iuncertainty) in reduced_entries.items():\n",
    "            redshift=iredshift\n",
    "            ynfindref='y'\n",
    "            refcode=irefcode\n",
    "            if iuncertainty>0:\n",
    "                uncertainty=iuncertainty\n",
    "            else:\n",
    "                input(f'No uncertainty for chosen referencecode: {refcode} , {source}')\n",
    "                uncertainty='NA'\n",
    "    else:\n",
    "\n",
    "        # If no desired references, and no maser distances, find valid entries with uncertainties\n",
    "        valid_entries = [entry for entry in entries if entry[1] > 0]\n",
    "        if valid_entries:\n",
    "            # Select the entry with the lowest uncertainty\n",
    "            lowest_uncertainty_entry = min(valid_entries, key=lambda x: x[1])\n",
    "            lowest_redshift, lowest_uncertainty, reference_code = lowest_uncertainty_entry\n",
    "            redshift=lowest_redshift\n",
    "            uncertainty= lowest_uncertainty\n",
    "            refcode=reference_code\n",
    "            ynfindref='n'\n",
    "        else:\n",
    "            input(f\"No valid redshift entries found for {source_name} (1)\\n\")\n",
    "        if len(maserdists)!=0:\n",
    "            z_observed = redshift\n",
    "            if z_observed >= threshold:\n",
    "                if len(maserdists)!=0 and findred==1:\n",
    "                        input('new maser source found... adjust accordingly (1)')\n",
    "        \n",
    "    z_observed = redshift\n",
    "    z_uncer=uncertainty\n",
    "\n",
    "    if z_observed <= threshold:\n",
    "        if len(maserdists)!=0:\n",
    "            input('new maser source found... adjust accordingly (2)')\n",
    "        if len(maserdists)==0:\n",
    "            textdistmm=float(otherdists[1])\n",
    "            textdistmmerr=float(otherdists[2])\n",
    "            textdistMpc=float(otherdists[3])\n",
    "\n",
    "            newdist=10**((textdistmm)/5-5)\n",
    "            newdist_uncer=np.log(10)/5*newdist*textdistmmerr\n",
    "            textmethod=otherdists[4]\n",
    "            refcode=otherdists[5]\n",
    "\n",
    "            return([newdist,newdist_uncer],textmethod,'NA',refcode,'DISTANCE',newrefs)\n",
    "\n",
    "    # Calculate heliocentric velocity\n",
    "    c = 299792.458  # Speed of light in km/s\n",
    "    v_helio = z_observed * c\n",
    "    v_helio_uncer = z_uncer * c\n",
    "\n",
    "    #Hubble Constant\n",
    "    #Pesce, APJ 891:L1\n",
    "    H = 73.9\n",
    "    H_uncer = 3\n",
    "    dist=v_helio/H\n",
    "    dist_uncer=np.sqrt((v_helio_uncer/H)**2 + (v_helio/H**2*H_uncer)**2)\n",
    "\n",
    "    return([dist,dist_uncer],'NA',ynfindref,refcode,'REDSHIFT', newrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on local computer to SMBH mass\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parent\n",
    "Greenepath=f'{parent_dir}/CountingBHS_and_Spectra/Greene_params/Greene_params.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date format\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def decimal_year_to_date(decimal_year):\n",
    "    year = int(decimal_year)  # Extract the year\n",
    "    fraction = decimal_year - year  # Extract the decimal part\n",
    "\n",
    "    # Convert the decimal part to days (assuming 365 days in a year)\n",
    "    days_elapsed = int(round(fraction * 365))  \n",
    "\n",
    "    # Compute the actual date by adding days to January 1st of that year\n",
    "    date = datetime(year, 1, 1) + timedelta(days=days_elapsed)\n",
    "\n",
    "    # Format as YY.MM.DD\n",
    "    return f\"{date.year }/{date.month:02}/{date.day:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get SMBH size\n",
    "from scipy import constants\n",
    "from astropy import constants as aconstants\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "pc=aconstants.pc.value\n",
    "mass_sun=aconstants.M_sun.value\n",
    "G=constants.gravitational_constant\n",
    "pi=constants.pi\n",
    "\n",
    "def linear_to_log_uncertainty(lin_x, lin_delta_x):\n",
    "    return lin_delta_x / (lin_x * np.log(10))\n",
    "\n",
    "def log_to_linear_uncertainty(log_x, log_x_uncertainty):\n",
    "    return log_x_uncertainty * 10**log_x * np.log(10)\n",
    "\n",
    "def getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc):\n",
    "    mass=10**float(log_BH_mass_solar)*mass_sun\n",
    "    mass_unc=mass*np.log(10)*float(log_BH_mass_solar_uncer)\n",
    "    mass_fracerror=(mass_unc/mass)*100\n",
    "\n",
    "    distance=distanceMPc*pc*10**6\n",
    "    distance_uncer=distanceMPc_uncer*pc*10**6\n",
    "    dist_fracerror=(distance_uncer/distance)*100\n",
    "    \n",
    "    if arcsectopc=='NA':\n",
    "        m_d=mass/distance\n",
    "        m_d_unc=np.sqrt((m_d/mass*mass_unc)**2+(m_d/distance*distance_uncer)**2)\n",
    "        m_d_fracerror=(m_d_unc/m_d)*100\n",
    "        diam_bhs_microarcsec_fracerror = m_d_fracerror\n",
    "\n",
    "        diam_bhs_rad=2*np.sqrt(27)*G/(c**2)*m_d\n",
    "        diam_bhs_deg=diam_bhs_rad*360/(2*pi)\n",
    "        diam_bhs_arcsec=diam_bhs_deg*60*60\n",
    "        diam_bhs_microarcsec=diam_bhs_arcsec*10**6\n",
    "\n",
    "        diam_bhs_microarcsec_unc=diam_bhs_microarcsec/(m_d)*m_d_unc\n",
    "\n",
    "\n",
    "        return(log_BH_mass_solar, log_BH_mass_solar_uncer, mass_fracerror, distanceMPc, distanceMPc_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "        \n",
    "    diam_bhs=2*np.sqrt(27)*G/(c**2)*mass\n",
    "    diam_bhs_unc = 2*np.sqrt(27)*G/(c**2)*mass_unc\n",
    "    \n",
    "    diam_bhspc=diam_bhs/pc\n",
    "    diam_bhspc_unc=diam_bhs_unc/pc\n",
    "\n",
    "    diam_bhs_arsec=diam_bhspc/arcsectopc\n",
    "    diam_bhs_microarcsec=diam_bhs_arsec*10**6\n",
    "\n",
    "    diam_bhs_arsec_unc=np.sqrt(\n",
    "                                (diam_bhspc_unc/arcsectopc)**2\n",
    "                                + ((-1)*diam_bhspc/arcsectopc**2*arcsectopc_unc)**2\n",
    "                                )\n",
    "    \n",
    "    diam_bhs_microarcsec_unc=diam_bhs_arsec_unc*10**6\n",
    "    diam_bhs_microarcsec_fracerror = (diam_bhs_microarcsec_unc/diam_bhs_microarcsec)*100\n",
    "\n",
    "    return(mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror)\n",
    "\n",
    "sagmass=6.6\n",
    "sagmass_unc_up=.12\n",
    "sagmass_unc_down=.07\n",
    "sagdist=8.15*10**(-3)\n",
    "sagdist_unc=.15*10**(-3)\n",
    "\n",
    "distanceMPc=sagdist\n",
    "distanceMPc_uncer=sagdist_unc\n",
    "\n",
    "log_BH_mass_solar=sagmass\n",
    "log_BH_mass_solar_uncerup=sagmass_unc_up\n",
    "log_BH_mass_solar_uncerdown=sagmass_unc_down\n",
    "\n",
    "mass, mass_uncup, mass_fracerrorup, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(sagmass,sagmass_unc_up,sagdist,sagdist_unc,'NA','NA')\n",
    "mass, mass_uncdown, mass_fracerrordown, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(sagmass,sagmass_unc_down,sagdist,sagdist_unc,'NA','NA')\n",
    "\n",
    "sagsize=diam_bhs_microarcsec\n",
    "sagsizeunc_down=diam_bhs_microarcsec_uncdown\n",
    "sagsizeunc_up=diam_bhs_microarcsec_uncup\n",
    "logsagsizeunc_down=linear_to_log_uncertainty(sagsize, sagsizeunc_down)\n",
    "logsagsizeunc_up=linear_to_log_uncertainty(sagsize, sagsizeunc_up)\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'SagA*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} ± {format_number(distanceMPc_uncer)} MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "log_BH_mass_solar_uncerup=format_number(float(log_BH_mass_solar_uncerup))\n",
    "log_BH_mass_solar_uncerdown=format_number(float(log_BH_mass_solar_uncerdown))\n",
    "mass_fracerror=(mass_fracerrorup+mass_fracerrordown)/2\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} $^{{+{log_BH_mass_solar_uncerup}}}_{{-{log_BH_mass_solar_uncerdown}}}$ log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles1=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "fig, ax = pylab.subplots()\n",
    "\n",
    "m87mass=9.81\n",
    "m87mass_unc=0.06\n",
    "m87dist=16.8\n",
    "m87dist_uncup=.8\n",
    "m87dist_uncdown=.7\n",
    "\n",
    "distanceMPc=m87dist\n",
    "distanceMPc_uncerup=m87dist_uncup\n",
    "distanceMPc_uncerdown=m87dist_uncdown\n",
    "\n",
    "log_BH_mass_solar=m87mass\n",
    "log_BH_mass_solar_uncer=m87mass_unc\n",
    "\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerup, dist_fracerrorup, diam_bhs_microarcsec, diam_bhs_microarcsec_uncup, diam_bhs_microarcsec_fracerrorup=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncup,'NA','NA')\n",
    "mass, mass_unc, mass_fracerror, distance, distance_uncerdown, dist_fracerrordown, diam_bhs_microarcsec, diam_bhs_microarcsec_uncdown, diam_bhs_microarcsec_fracerrordown=getsize(m87mass,m87mass_unc,m87dist,m87dist_uncdown,'NA','NA')\n",
    "\n",
    "m87size=diam_bhs_microarcsec\n",
    "m87sizeunc_down=diam_bhs_microarcsec_uncdown\n",
    "m87sizeunc_up=diam_bhs_microarcsec_uncup\n",
    "logm87sizeunc_down=linear_to_log_uncertainty(m87size, m87sizeunc_down)\n",
    "logm87sizeunc_up=linear_to_log_uncertainty(m87size, m87sizeunc_up)\n",
    "\n",
    "diam_bhs_microarcsec_uncup=format_number(diam_bhs_microarcsec_uncup)\n",
    "diam_bhs_microarcsec_uncdown=format_number(diam_bhs_microarcsec_uncdown)\n",
    "diam_bhs_microarcsec_fracerror=(diam_bhs_microarcsec_fracerrorup+diam_bhs_microarcsec_fracerrordown)/2\n",
    "\n",
    "sourcehan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'M87*', linestyle='')\n",
    "sizechan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'µ\" of Scharchild Radius: {format_number(diam_bhs_microarcsec)} $^{{+{diam_bhs_microarcsec_uncup}}}_{{-{diam_bhs_microarcsec_uncdown}}}$ ({format_number(diam_bhs_microarcsec_fracerror)}%)', linestyle='')\n",
    "dist_fracerror=(distanceMPc_uncerup+distanceMPc_uncerdown)/2\n",
    "distanceMPc_uncerup=format_number(float(distanceMPc_uncerup))\n",
    "distanceMPc_uncerdown=format_number(float(distanceMPc_uncerdown))\n",
    "disthan=Line2D([0], [0], color='red', marker='o', markersize=0, label=f'Distance From Earth: {format_number(distanceMPc)} $^{{+{distanceMPc_uncerup}}}_{{-{distanceMPc_uncerdown}}}$ MPc ({format_number(dist_fracerror)}%)', linestyle='')\n",
    "masshan=Line2D([0], [0], color='red', marker='o', markersize=0, label=rf'SMBH Mass: {format_number(float(log_BH_mass_solar))} ±{log_BH_mass_solar_uncerdown} log M☉ ({format_number(mass_fracerror)}%)', linestyle='')\n",
    "handles2=[sourcehan,sizechan,masshan,disthan]\n",
    "\n",
    "legend1=ax.legend(handles=handles2, loc='upper center')   \n",
    "ax.add_artist(legend1)\n",
    "ax.legend(handles=handles1, loc='lower center')   \n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xticks([])  # Remove x-axis ticks\n",
    "ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "# Remove tick labels\n",
    "ax.set_xticklabels([])  # Remove x-axis labels\n",
    "ax.set_yticklabels([])  # Remove y-axis labels\n",
    "if not os.path.exists('Extras'):\n",
    "    os.makedirs('Extras')\n",
    "#pylab.savefig(f'Extras/SMBH of SagA* and M87')\n",
    "pylab.clf() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrapolate High, Low, and Chosen Observations\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "write=True\n",
    "#write=False\n",
    "\n",
    "sigsmart=True\n",
    "\n",
    "namesandfiles=[]\n",
    "\n",
    "#set extrap to 1 just to extrapolate values for the chosen sources\n",
    "extrap=1\n",
    "\n",
    "if extrap==0:\n",
    "    write=False\n",
    "\n",
    "def round_to_sig_figs(sigsmart,x, n):\n",
    "      if sigsmart==False:\n",
    "          return(x,n)\n",
    "      if x == 0:\n",
    "            return 0\n",
    "      else:\n",
    "            digits = -int(math.floor(math.log10(abs(x)))) + (n - 1)\n",
    "            return round(x, digits)\n",
    "      \n",
    "def round_to_sig_figs2(sigsmart,x, n):\n",
    "      if sigsmart==False:\n",
    "          return(x,n)\n",
    "      if x == 0:\n",
    "            return 0\n",
    "      else:\n",
    "            digits = -int(math.floor(math.log10(abs(x)))) + (n - 1)\n",
    "            return round(x, digits)\n",
    "\n",
    "def count_sig_figs(num_input):\n",
    "\t\t\tnum_str = str(num_input).strip().replace(',', '')\n",
    "\t\t\t# Strip sign\n",
    "\t\t\tif num_str.startswith(('+', '-')):\n",
    "\t\t\t\t\t\tnum_str = num_str[1:]\n",
    "\n",
    "\t\t\t# Handle scientific notation strings by expanding to a plain decimal string\n",
    "\t\t\tif 'e' in num_str.lower():\n",
    "\t\t\t\t\t\tmant, exp = num_str.lower().split('e', 1)\n",
    "\t\t\t\t\t\texp = int(exp)\n",
    "\n",
    "\t\t\t\t\t\t# Separate mantissa integer/decimal\n",
    "\t\t\t\t\t\tif '.' in mant:\n",
    "\t\t\t\t\t\t\t\t\tint_part, dec_part = mant.split('.', 1)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tint_part, dec_part = mant, ''\n",
    "\n",
    "\t\t\t\t\t\t# Digits of mantissa with no dot\n",
    "\t\t\t\t\t\tdigits = ''.join(ch for ch in (int_part + dec_part) if ch.isdigit())\n",
    "\n",
    "\t\t\t\t\t\t# Original decimal index within the digits string\n",
    "\t\t\t\t\t\torig_idx = len(int_part)\n",
    "\n",
    "\t\t\t\t\t\t# New decimal index after shifting by exponent\n",
    "\t\t\t\t\t\tnew_idx = orig_idx + exp\n",
    "\n",
    "\t\t\t\t\t\tif new_idx <= 0:\n",
    "\t\t\t\t\t\t\t\t\tinteger = '0'\n",
    "\t\t\t\t\t\t\t\t\tdecimal = '0' * (-new_idx) + digits\n",
    "\t\t\t\t\t\t\t\t\tnum_str = integer + '.' + decimal\n",
    "\t\t\t\t\t\telif new_idx >= len(digits):\n",
    "\t\t\t\t\t\t\t\t\tinteger = digits + '0' * (new_idx - len(digits))\n",
    "\t\t\t\t\t\t\t\t\tnum_str = integer  # no decimal part needed\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tinteger = digits[:new_idx]\n",
    "\t\t\t\t\t\t\t\t\tdecimal = digits[new_idx:]\n",
    "\t\t\t\t\t\t\t\t\tnum_str = integer + '.' + decimal\n",
    "\n",
    "\t\t\t# Now count sig figs on the plain decimal representation\n",
    "\t\t\tif '.' in num_str:\n",
    "\t\t\t\t\t\tinteger, decimal = num_str.split('.', 1)\n",
    "\t\t\t\t\t\tsig_part = integer.lstrip('0') + ''.join(c for c in decimal if c.isdigit())\n",
    "\t\t\t\t\t\treturn sum(c.isdigit() for c in sig_part)\n",
    "\t\t\telse:\n",
    "\t\t\t\t\t\tsig_part = num_str.lstrip('0').rstrip('0')\n",
    "\t\t\t\t\t\treturn sum(c.isdigit() for c in sig_part)\n",
    "\n",
    "\n",
    "def match_decimal_places(sigsmart,target, reference):\n",
    "      if sigsmart==False:\n",
    "          return f\"{target}\"\n",
    "      # Count digits after decimal in the reference (as string)\n",
    "      ref_str = str(reference)\n",
    "      if '.' in ref_str:\n",
    "            decimals = len(ref_str.split('.')[1])\n",
    "      else:\n",
    "            decimals = 0\n",
    "      \n",
    "      # Format the target to that number of decimal places\n",
    "      return f\"{target:.{decimals}f}\"\n",
    "\n",
    "sourcesofinterest=('4258','1194','3079','4945','Circinus','1068')\n",
    "\n",
    "lim1=[200,400]\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "get_freq_chosen=[]\n",
    "\n",
    "def find_flux_with_smallest_beam(arrays,isource):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    # flux,fluxunc,beam,freq,date,telescope\n",
    "    arrays = np.array(arrays)\n",
    "    index_of_smallest_beam = np.argmin(arrays[:, 2].astype(float))\n",
    "    flux = arrays[index_of_smallest_beam, 0]\n",
    "    fluxunc = arrays[index_of_smallest_beam, 1]\n",
    "    beam = arrays[index_of_smallest_beam, 2]\n",
    "    freq = arrays[index_of_smallest_beam, 3]\n",
    "    date = arrays[index_of_smallest_beam, 4].replace('_1','')\n",
    "    tele = arrays[index_of_smallest_beam, 5]\n",
    "    file = arrays[index_of_smallest_beam, 6].replace('\\n','')\n",
    "    return flux, fluxunc, beam, freq, date, tele, file\n",
    "\n",
    "def find_fluxs_with_high_freq(arrays, logfreq_flux_with_smallest_beam):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "\n",
    "    arrays = np.array(arrays)\n",
    "    index_of_highest_freq = np.argmax(arrays[:, 3].astype(float))\n",
    "    high_freq=10**float(arrays[index_of_highest_freq, 3])\n",
    "\n",
    "    if high_freq==freq_chosen:\n",
    "        return('NA')\n",
    "    \n",
    "    result_entries = []\n",
    "\n",
    "    #flux = arrays[index_of_highest_freq, 0]\n",
    "    #fluxunc = arrays[index_of_highest_freq, 1]\n",
    "    #beam = arrays[index_of_highest_freq, 2]\n",
    "    #freq = arrays[index_of_highest_freq, 3]\n",
    "    #date = arrays[index_of_highest_freq, 4]\n",
    "    #tele = arrays[index_of_highest_freq, 5]\n",
    "\n",
    "    #result_entries.append((flux, fluxunc, beam, freq, date, tele))\n",
    "\n",
    "    for i, entry in enumerate(arrays):\n",
    "        ifreq = 10**float(entry[3])\n",
    "        #if ifreq > freq_chosen:\n",
    "        if (ifreq / freq_chosen) > 1.099:\n",
    "            # Frequency is more than 10% 10\\\\% higher than the chosen frequency\n",
    "            result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]))\n",
    "\n",
    "    return  result_entries\n",
    "\n",
    "def find_fluxs_with_low_freq(arrays, logfreq_flux_with_smallest_beam):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "\n",
    "    arrays = np.array(arrays)\n",
    "    #these variables should be changed to represent lowest frequency... it was copy and pasted from find_fluxs_with_high_freq\n",
    "    index_of_highest_freq = np.argmin(arrays[:, 3].astype(float))\n",
    "    high_freq=10**float(arrays[index_of_highest_freq, 3])\n",
    "\n",
    "    if high_freq==freq_chosen:\n",
    "        return('NA')\n",
    "    \n",
    "    result_entries = []\n",
    "\n",
    "    #flux = arrays[index_of_highest_freq, 0]\n",
    "    #fluxunc = arrays[index_of_highest_freq, 1]\n",
    "    #beam = arrays[index_of_highest_freq, 2]\n",
    "    #freq = arrays[index_of_highest_freq, 3]\n",
    "    #date = arrays[index_of_highest_freq, 4]\n",
    "    #tele = arrays[index_of_highest_freq, 5]\n",
    "    #result_entries.append((flux, fluxunc, beam, freq, date, tele))\n",
    "\n",
    "    for i, entry in enumerate(arrays):\n",
    "        ifreq = 10**float(entry[3])\n",
    "        #if ifreq < freq_chosen:\n",
    "        if (ifreq / freq_chosen) < 0.901:\n",
    "            # Frequency is more than 10% 10\\\\% lower than the chosen frequency\n",
    "            result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]))\n",
    "\n",
    "    return  result_entries\n",
    "\n",
    "def dust_extrap_lowest(arrays, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam):\n",
    "\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "    beam_chosen=10**float(logbeam_flux_with_smallest_beam)\n",
    "\n",
    "    result_entries = []\n",
    "\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    for entry in arrays:\n",
    "        ilogflux = float(entry[0])\n",
    "        iflux = 10**float(entry[0])\n",
    "        \n",
    "        ilogfluxunc = entry[1]\n",
    " \n",
    "        if ilogfluxunc!='NA':\n",
    "            ifluxunc = log_to_linear_uncertainty(ilogflux, float(ilogfluxunc))\n",
    "        else:\n",
    "            ifluxunc = 'NA'\n",
    "\n",
    "        ibeam = 10**float(entry[2])\n",
    "        ifreq = 10**float(entry[3])\n",
    "\n",
    "        iflux_extrap = iflux * (freq_chosen/ifreq)**4.5\n",
    "\n",
    "        #dust emission is extended... not a point source\n",
    "        iflux_extrap = iflux_extrap * (beam_chosen/ibeam)**2\n",
    "\n",
    "        if ifluxunc!='NA':\n",
    "            iflux_extrap_unc = ifluxunc * (freq_chosen/ifreq)**4.5\n",
    "            iflux_extrap_unc = iflux_extrap_unc * (beam_chosen/ibeam)**2\n",
    "            iflux_extrap_unc = linear_to_log_uncertainty(iflux_extrap,iflux_extrap_unc)\n",
    "        else:\n",
    "            iflux_extrap_unc = 'NA'\n",
    "\n",
    "        iflux_extrap= np.log10(iflux_extrap)\n",
    "        result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], iflux_extrap, iflux_extrap_unc, entry[5]))\n",
    "\n",
    "    # Find the entry with the lowest extrapolated flux\n",
    "    min_flux_entry = min(result_entries, key=lambda x: x[5])  # x[5] accesses the iflux_extrap\n",
    "    max_flux_entry = max(result_entries, key=lambda x: x[5])\n",
    "\n",
    "    # Return the details from the entry with the lowest extrapolated flux\n",
    "    flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele = min_flux_entry  # Unpacking the details from the entry tuple\n",
    "    flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2 = max_flux_entry  # Unpacking the details from the entry tuple\n",
    "    return [flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele],[flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2]\n",
    "\n",
    "\n",
    "def jet_extrap(arrays, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam):\n",
    "\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "    beam_chosen=10**float(logbeam_flux_with_smallest_beam)\n",
    "\n",
    "    result_entries = []\n",
    "\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    for entry in arrays:\n",
    "        ilogflux = float(entry[0])\n",
    "        iflux = 10**float(entry[0])\n",
    "        \n",
    "        ilogfluxunc = entry[1]\n",
    " \n",
    "        if ilogfluxunc!='NA':\n",
    "            ifluxunc = log_to_linear_uncertainty(ilogflux, float(ilogfluxunc))\n",
    "        else:\n",
    "            ifluxunc = 'NA'\n",
    "\n",
    "        ibeam = 10**float(entry[2])\n",
    "        ifreq = 10**float(entry[3])\n",
    "\n",
    "        iflux_extrap = iflux * (freq_chosen/ifreq)**(-0.5)\n",
    "\n",
    "        #compact jet is a point source... no beam correction\n",
    "        #iflux_extrap = iflux_extrap * (beam_chosen/ibeam)**2\n",
    "\n",
    "        if ifluxunc!='NA':\n",
    "            iflux_extrap_unc = ifluxunc * (freq_chosen/ifreq)**(-0.5)\n",
    "            iflux_extrap_unc = linear_to_log_uncertainty(iflux_extrap,iflux_extrap_unc)\n",
    "        else:\n",
    "            iflux_extrap_unc = 'NA'\n",
    "\n",
    "        iflux_extrap= np.log10(iflux_extrap)\n",
    "        result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], iflux_extrap, iflux_extrap_unc, entry[5]))\n",
    "\n",
    "    # Find the entry with the lowest extrapolated flux\n",
    "    min_flux_entry = min(result_entries, key=lambda x: x[5])  # x[1] accesses the iflux_extrap\n",
    "    max_flux_entry = max(result_entries, key=lambda x: x[5])\n",
    "    # Return the details from the entry with the lowest extrapolated flux\n",
    "    flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele = min_flux_entry  # Unpacking the details from the entry tuple\n",
    "    flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2 = max_flux_entry  # Unpacking the details from the entry tuple\n",
    "\n",
    "    return [flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele],[flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2]\n",
    "\n",
    "\n",
    "def linear_to_log_uncertainty(lin_x, lin_delta_x):\n",
    "    return lin_delta_x / (lin_x * np.log(10))\n",
    "\n",
    "def log_to_linear_uncertainty(log_x, log_x_uncertainty):\n",
    "    return float(log_x_uncertainty) * 10**float(log_x) * np.log(10)\n",
    "\n",
    "graph_array1=[]\n",
    "graph_array2=[]\n",
    "\n",
    "nograph=[]\n",
    "\n",
    "                        #'flux'\n",
    "                        #'frequency'         \n",
    "                        #'beam size'\n",
    "                        #'date'  \n",
    "\n",
    "for isource, data in grouped_data.items():\n",
    "    breaker=1\n",
    "    if extrap==1:\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in isource.lower():\n",
    "                breaker=0\n",
    "        if breaker==1:\n",
    "            continue\n",
    "\n",
    "    contam_table=f'contam_{isource}.tex'\n",
    "\n",
    "    with open(contam_table, 'w') as file:\n",
    "        if write==True:\n",
    "            original_stdout = sys.stdout\n",
    "            sys.stdout = file\n",
    "\n",
    "        # Main loop to read and process sources from the input file\n",
    "        if os.path.exists(txtnamesandcoords):\n",
    "            with open(txtnamesandcoords, 'r') as infile:\n",
    "                for line in infile:\n",
    "\n",
    "                    # Parse the line into a list of name-coordinate pairs\n",
    "                    params = ast.literal_eval(line)\n",
    "                    for inamecoords in params:                \n",
    "                        source_name = inamecoords[0][0]\n",
    "                        if not isource.lower() in source_name.lower():\n",
    "                            continue\n",
    "                        source=source_name\n",
    "                        ra = inamecoords[1][1]\n",
    "                        dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                        findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                        distanceMPc=findvals[0][0]\n",
    "                        distanceMPc_uncer=findvals[0][1]\n",
    "                        method=findvals[1]\n",
    "                        ynfindref=findvals[2]\n",
    "                        refcode=findvals[3]\n",
    "                        red_depend=findvals[4]\n",
    "        else:\n",
    "            print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "        arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "        arcsectopc=arcsectokpc*1000\n",
    "\n",
    "        arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "        arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "        arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "        distance='NA'\n",
    "        with open(Greenepath, 'r') as infile:\n",
    "            j=-1\n",
    "            breaker=1\n",
    "            for line in infile:\n",
    "                j=j+1\n",
    "                if j>20:\n",
    "                    continue\n",
    "                source_name=line.split(' ')[0]\n",
    "                source_name=source_name.replace(\"−\",\"-\")\n",
    "                if isource=='WISEAJ043703':\n",
    "                    isource='J0437'\n",
    "                if isource.lower() in source_name.lower():\n",
    "                    log_BH_mass_solar=line.split(' ')[3]\n",
    "                    log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                    breaker=0\n",
    "                if 'cgcg' in isource.lower():\n",
    "                    log_BH_mass_solar=7.38\n",
    "                    log_BH_mass_solar_offset=0.012\n",
    "                    breaker=0\n",
    "                if '4945' in isource.lower():\n",
    "                    log_BH_mass_solar=6.15\n",
    "                    log_BH_mass_solar_offset='NA'\n",
    "                    breaker=0\n",
    "            if breaker!=1:\n",
    "                mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "            else:\n",
    "                print(f'{source} not found')\n",
    "            \n",
    "\n",
    "            fluxs1=[]\n",
    "            fluxs2=[]\n",
    "            fluxsuplim=[]\n",
    "            with open(source_text, 'r') as infile:\n",
    "                j=-1\n",
    "                for line in infile:\n",
    "                    if line=='\\n':\n",
    "                        continue\n",
    "                    line=eval(line)\n",
    "                    source=line[0]\n",
    "                    if isource in source:\n",
    "                        file=line[7]\n",
    "                        telescope=line[1]\n",
    "                        if telescope=='VLBA':\n",
    "                            continue\n",
    "                        date=line[4].replace('_1','')\n",
    "                        snr=line[6].split('\\n')[0]\n",
    "\n",
    "                        freq=np.log10(float(line[2]))\n",
    "                        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "                        checklow=len(str(line[3]).split('*'))\n",
    "                        if snr!='NA':\n",
    "                            linflux=float(line[3].split('*')[0])\n",
    "                            linfluxunc=float(linflux)/float(snr)\n",
    "\n",
    "                            fluxunc=linear_to_log_uncertainty(linflux,linfluxunc)\n",
    "                        else:\n",
    "                            fluxunc='NA'\n",
    "\n",
    "                        if '-' not in line[5]:\n",
    "                            beam=np.log10(float(line[5]))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        #for extrap==0 we are looking for an obs to fix the coordinates for all the fits\n",
    "                        #we look for an observations in the 200-400 GHz range that are a detection... then to \n",
    "                        #all other frequency ranges.  We look for the highest resolution that is a detection\n",
    "                        if extrap==0 and checklow==1:\n",
    "                            if 10**freq<lim1[1] and 10**freq>lim1[0]:\n",
    "                                if date=='2021/09/03':\n",
    "                                    #input(linflux)\n",
    "                                    #input(linfluxunc)\n",
    "                                    pass\n",
    "                                fluxs1.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "                            fluxs2.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "\n",
    "                        #for extrap==1 we are extrapolating to the chosen frequency... which is the frequency\n",
    "                        #of the obs of the highest resolution in the 200-400GHz range.  In this case we do not \n",
    "                        #care about lower limits. If the observation of highest resolution is a lower limit this\n",
    "                        #is what is reported... furthermore extrapolations are upper limits so that we include \n",
    "                        #non detections for this as well\n",
    "                        if extrap==1:\n",
    "                            if 10**freq<lim1[1] and 10**freq>lim1[0]:\n",
    "                                if date=='2021/09/03':\n",
    "                                    #input(linflux)\n",
    "                                    #input(linfluxunc)\n",
    "                                    pass\n",
    "                                fluxs1.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "                            fluxs2.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "            if fluxs1:      \n",
    "                graph_array1.append(isource)\n",
    "                flux_with_smallest_beam = find_flux_with_smallest_beam(fluxs1,isource)\n",
    "\n",
    "                if flux_with_smallest_beam[1]!='NA':\n",
    "                    sobsfluxerr=f'{log_to_linear_uncertainty(flux_with_smallest_beam[0],flux_with_smallest_beam[1]):.1f}'\n",
    "                    if sobsfluxerr=='0.0':\n",
    "                        sobsflux=f'{10**float(flux_with_smallest_beam[0]):.2f}'\n",
    "                        sobsfluxerr=f'{log_to_linear_uncertainty(flux_with_smallest_beam[0],flux_with_smallest_beam[1]):.2f}'\n",
    "                    else:\n",
    "                        sobsflux=f'{10**float(flux_with_smallest_beam[0]):.1f}'\n",
    "                else:\n",
    "                    sobsfluxerr='NA'\n",
    "                    sobsflux=f'{10**float(flux_with_smallest_beam[0]):.1f}'\n",
    "                \n",
    "                \n",
    "                namesandfiles.append([isource,'chosenfile',flux_with_smallest_beam[6]])\n",
    "                if extrap==0:\n",
    "                    continue\n",
    "\n",
    "                logbeam_flux_with_smallest_beam=flux_with_smallest_beam[2]\n",
    "                logfreq_flux_with_smallest_beam=flux_with_smallest_beam[3]\n",
    "                get_freq_chosen.append([isource,10**float(logfreq_flux_with_smallest_beam),10**float(logbeam_flux_with_smallest_beam)])\n",
    "\n",
    "                graph_array1.append(flux_with_smallest_beam)\n",
    "                log_diam_bhs_microarcsec_unc = linear_to_log_uncertainty(diam_bhs_microarcsec,diam_bhs_microarcsec_unc)\n",
    "                log_diam_bhs_microarcsec = np.log10(diam_bhs_microarcsec)\n",
    "                if '4945' in isource:\n",
    "                    log_diam_bhs_microarcsec_unc=0\n",
    "                bhs=[log_diam_bhs_microarcsec,log_diam_bhs_microarcsec_unc]\n",
    "                graph_array1.append(bhs)\n",
    "                flux_high_freq_high_beam='NA'\n",
    "                flux_low_freq_low_beam='NA'\n",
    "\n",
    "                beamobs=10**float(flux_with_smallest_beam[2])\n",
    "                beamobs=format_number(beamobs)\n",
    "\n",
    "                beamhigh='NA'\n",
    "                beamlow='NA'\n",
    "                freqlow='NA'\n",
    "\n",
    "                print(fr\"\"\"\\begin{{deluxetable*}}{{lllllll}}\\\n",
    "\\tablecaption{{Continuum Flux and Extrapolation to {10**float(flux_with_smallest_beam[3]):.0f} GHz for {isource}}}\n",
    "\\tablehead{{ \n",
    "\\colhead{{Source}} & \\colhead{{Extrapolation}} & \\colhead{{Telescope}} & \\colhead{{Flux[mJy[beam]$^{{-1}}]$}} & \\colhead{{Frequency[GHz]}} & \\colhead{{beamsize[\"]}} & \\colhead{{Date[yyyy/mm/dd]}}\n",
    "}}\n",
    "\\startdata\"\"\")\n",
    "                if fluxs2:\n",
    "                    fluxs_with_highest_freq = find_fluxs_with_high_freq(fluxs2,logfreq_flux_with_smallest_beam)\n",
    "                    fluxs_with_lowest_freq = find_fluxs_with_low_freq(fluxs2,logfreq_flux_with_smallest_beam)\n",
    "                    \n",
    "\n",
    "                    obsflux_str = sobsflux            # e.g. \"12.30\" or \"0.0450\"\n",
    "                    # Count sig figs from the string to preserve trailing zeros:\n",
    "                    obs_sigs = count_sig_figs(obsflux_str)\n",
    "\n",
    "                    if fluxs_with_highest_freq != 'NA':\n",
    "                        flux_high_freq_high_beam, flux_high_freq_high_beam2 = dust_extrap_lowest(fluxs_with_highest_freq, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam)\n",
    "                        #low lim\n",
    "                        beamhigh=10**float(flux_high_freq_high_beam[2])\n",
    "                        beamhigh=format_number(beamhigh)\n",
    "\n",
    "                        highflux=10**float(flux_high_freq_high_beam[5])\n",
    "                        highfluxerr=log_to_linear_uncertainty(flux_high_freq_high_beam[5],flux_high_freq_high_beam[6])\n",
    "\n",
    "                        highflux=round_to_sig_figs(sigsmart,highflux, obs_sigs)\n",
    "                        highfluxerr=match_decimal_places(sigsmart,highfluxerr, highflux)\n",
    "                        #high lim\n",
    "                        beamhigh2=10**float(flux_high_freq_high_beam2[2])\n",
    "                        beamhigh2=format_number(beamhigh2)\n",
    "\n",
    "                        highflux2=10**float(flux_high_freq_high_beam2[5])\n",
    "                        highfluxerr2=log_to_linear_uncertainty(flux_high_freq_high_beam2[5],flux_high_freq_high_beam2[6])\n",
    "\n",
    "                        highflux2=round_to_sig_figs(sigsmart,highflux2, obs_sigs)\n",
    "                        highfluxerr2=match_decimal_places(sigsmart,highfluxerr2, highflux2)\n",
    "\n",
    "                        if fluxs_with_lowest_freq != 'NA':\n",
    "                            flux_low_freq_low_beam,flux_low_freq_low_beam2 = jet_extrap(fluxs_with_lowest_freq, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam)\n",
    "                            #low lim\n",
    "                            freqlow=10**float(flux_low_freq_low_beam[3])\n",
    "                            if freqlow<10:\n",
    "                                freqlow=f\"{freqlow:.1f}\"\n",
    "                            else:\n",
    "                                freqlow=f\"{freqlow:.0f}\"\n",
    "                            beamlow=10**float(flux_low_freq_low_beam[2])\n",
    "                            beamlow=format_number(beamlow)\n",
    "\n",
    "                            lowflux=10**float(flux_low_freq_low_beam[5])\n",
    "                            lowflux=round_to_sig_figs(sigsmart,lowflux, obs_sigs)\n",
    "\n",
    "                            if flux_low_freq_low_beam[6] == 'NA':\n",
    "                                lowfluxerr='NA'\n",
    "                                lowflux = f'{lowflux}*'\n",
    "                            else:\n",
    "                                lowfluxerr=log_to_linear_uncertainty(flux_low_freq_low_beam[5],flux_low_freq_low_beam[6])\n",
    "                                lowfluxerr=match_decimal_places(sigsmart,lowfluxerr, lowflux)\n",
    "\n",
    "\n",
    "                            #high lim\n",
    "                            freqlow2=10**float(flux_low_freq_low_beam2[3])\n",
    "                            if freqlow2<10:\n",
    "                                freqlow2=f\"{freqlow2:.1f}\"\n",
    "                            else:\n",
    "                                freqlow2=f\"{freqlow2:.0f}\"\n",
    "                            beamlow2=10**float(flux_low_freq_low_beam2[2])\n",
    "                            beamlow2=format_number(beamlow2)\n",
    "\n",
    "                            lowflux2=10**float(flux_low_freq_low_beam2[5])\n",
    "                            lowflux2=round_to_sig_figs(sigsmart,lowflux2, obs_sigs)\n",
    "\n",
    "\n",
    "                            if flux_low_freq_low_beam2[6] == 'NA':\n",
    "                                lowfluxerr2='NA'\n",
    "                                lowflux2= f'{lowflux2}*'\n",
    "                            else:\n",
    "                                lowfluxerr2=log_to_linear_uncertainty(flux_low_freq_low_beam2[5],flux_low_freq_low_beam2[6])\n",
    "                                lowfluxerr2=match_decimal_places(sigsmart,lowfluxerr2, lowflux2)\n",
    "\n",
    "                            print(f\"\"\"{isource} &\n",
    "Direct Obs &\n",
    "{flux_with_smallest_beam[5]} &\n",
    "{sobsflux} ± {sobsfluxerr} &\n",
    "{10**float(flux_with_smallest_beam[3]):.0f} &\n",
    "{beamobs} &\n",
    "{flux_with_smallest_beam[4]}\n",
    "\\\\\\\\\n",
    "{isource} &\n",
    "Hot Dust &\n",
    "{flux_high_freq_high_beam[7]} &\n",
    "{highflux} ± {highfluxerr} &\n",
    "{10**float(flux_high_freq_high_beam[3]):.0f}  &\n",
    "{beamhigh} &\n",
    "{flux_high_freq_high_beam[4]}\n",
    "\\\\\\\\\n",
    "{isource} &\n",
    "Extended Jet &\n",
    "{flux_low_freq_low_beam[7]} &\n",
    "{lowflux} ± {lowfluxerr} &\n",
    "{freqlow} &\n",
    "{beamlow} &\n",
    "{flux_low_freq_low_beam[4]}\n",
    "\\\\\\\\\n",
    "\\enddata\n",
    "\\\\tablecomments{{\n",
    "\\\\textbf{{Direct Observation:}} The observation with the smallest beam size between 200--400~GHz.\\\\\\\\\n",
    "\\\\textbf{{High Dust Extrapolation:}} All observations in Table~\\\\ref{{tab:mr1}} at frequencies 10\\\\% higher than the direct observation are considered. Each flux value is extrapolated to {10**float(flux_with_smallest_beam[3]):.0f}~GHz using a power-law spectral index of $+3$, and scaled by the squared ratio of beam sizes (beam size is defined as the geometric mean of the major and minor FWHM axes). The lowest extrapolated value is reported.\\\\\\\\\n",
    "\\\\textbf{{Low Jet Extrapolation:}} All observations in Table~\\\\ref{{tab:mr1}} at frequencies 10\\\\% lower than the direct observation are considered. Each flux value is extrapolated to {10**float(flux_with_smallest_beam[3]):.0f}~GHz using a power-law spectral index of $-0.5$; no beam-size corrections are applied. The lowest extrapolated value is reported.\n",
    "}}\n",
    "\\end{{deluxetable*}}\"\"\")\n",
    "                        else:\n",
    "                            print(f\"\"\"{isource} &\n",
    "Direct Obs&\n",
    "{flux_with_smallest_beam[5]} &\n",
    "{sobsflux} ± {sobsfluxerr} &\n",
    "{10**float(flux_with_smallest_beam[3]):.0f} &\n",
    "{beamobs} &\n",
    "{flux_with_smallest_beam[4]}\n",
    "\\\\\\\\\n",
    "{isource} &\n",
    "Hot Dust &\n",
    "{flux_high_freq_high_beam[7]} &&\n",
    "{highflux} ± {highfluxerr} &\n",
    "{10**float(flux_high_freq_high_beam[3]):.0f}  &\n",
    "{beamhigh} &\n",
    "{flux_high_freq_high_beam[4]}\n",
    "\\\\\\\\\n",
    "\\enddata\n",
    "\\\\tablecomments{{\n",
    "\\\\textbf{{Direct Observation:}} The observation with the smallest beam size between 200--400~GHz.\\\\\\\\\n",
    "\\\\textbf{{High Dust Extrapolation:}} All observations in Table~\\\\ref{{tab:mr1}} at frequencies 10\\\\% higher than the direct observation are considered. Each flux value is extrapolated to {10**float(flux_with_smallest_beam[3]):.0f}~GHz using a power-law spectral index of $+3$, and scaled by the squared ratio of beam sizes (assuming beam size is defined as the geometric mean of the major and minor FWHM axes). The lowest extrapolated value is reported.\\\\\\\\\n",
    "\\\\textbf{{Low Jet Extrapolation:}} Not applicable for this source, as no observations 10\\\\% below the frequency of the direct observation are available.\n",
    "}}\n",
    "        \\end{{deluxetable*}}\"\"\")\n",
    "                    else:\n",
    "                        flux_low_freq_low_beam,flux_low_freq_low_beam2 = jet_extrap(fluxs_with_lowest_freq, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam)\n",
    "                    \n",
    "                        if flux_low_freq_low_beam[6]!='NA':\n",
    "                            print_low=f'{10**float(flux_low_freq_low_beam[5]):.2f} ± {log_to_linear_uncertainty(flux_low_freq_low_beam[5],flux_low_freq_low_beam[6]):.2f}'\n",
    "                        else:\n",
    "                            print_low = f'{10**float(flux_low_freq_low_beam[5]):.2f}*'\n",
    "                        if fluxs_with_lowest_freq != 'NA':\n",
    "\n",
    "\n",
    "                            freqlow=10**float(flux_low_freq_low_beam[3])\n",
    "                            if freqlow<10:\n",
    "                                freqlow=f\"{freqlow:.1f}\"\n",
    "                            else:\n",
    "                                freqlow=f\"{freqlow:.0f}\"\n",
    "                            beamlow=10**float(flux_low_freq_low_beam[2])\n",
    "                            beamlow=format_number(beamlow)\n",
    "\n",
    "                            if flux_low_freq_low_beam[6]=='NA':\n",
    "                                lowflux=10**float(flux_low_freq_low_beam[5])\n",
    "                                lowflux=round_to_sig_figs(sigsmart,lowflux, obs_sigs)\n",
    "                                print_lowflux = f'{lowflux}*'\n",
    "\n",
    "                            else:\n",
    "                                lowflux=10**float(flux_low_freq_low_beam[5])\n",
    "                                lowflux=round_to_sig_figs(sigsmart,lowflux, obs_sigs)\n",
    "\n",
    "                                lowfluxerr=log_to_linear_uncertainty(flux_low_freq_low_beam[5],flux_low_freq_low_beam[6])\n",
    "                                lowfluxerr=match_decimal_places(sigsmart,lowfluxerr, lowflux)\n",
    "\n",
    "                                print_lowflux = f'{lowflux} ± {lowfluxerr}'\n",
    "\n",
    "\n",
    "                            print(f\"\"\"{isource} &\n",
    "Direct Obs&\n",
    "{flux_with_smallest_beam[5]} &\n",
    "{sobsflux} ± {sobsfluxerr} &\n",
    "{10**float(flux_with_smallest_beam[3]):.0f} &\n",
    "{beamobs} &\n",
    "{flux_with_smallest_beam[4]}\n",
    "\\\\\\\\\n",
    "{isource} &\n",
    "Extended Jet &\n",
    "{flux_low_freq_low_beam[7]} &\n",
    "{lowflux} ± {lowfluxerr} &\n",
    "{freqlow} &\n",
    "{beamlow} &\n",
    "{flux_low_freq_low_beam[4]} \n",
    "\\\\\\\\\n",
    "\\enddata\n",
    "\\\\tablecomments{{\n",
    "\\\\textbf{{Direct Observation:}} The observation with the smallest beam size between 200--400~GHz.\\\\\\\\\n",
    "\\\\textbf{{High Dust Extrapolation:}} Not applicable for this source, as no observations 10\\\\% above the frequency of the direct observation are available.\\\\\\\\\n",
    "\\\\textbf{{Low Jet Extrapolation:}} All observations in Table~\\\\ref{{tab:mr1}} at frequencies 10\\\\% lower than the direct observation are considered. Each flux value is extrapolated to {10**float(flux_with_smallest_beam[3]):.0f}~GHz using a power-law spectral index of $-0.5$; no beam-size corrections are applied. The lowest extrapolated value is reported.\n",
    "}}    \n",
    "    \\end{{deluxetable*}}\"\"\")\n",
    "                        else:\n",
    "                            print(f\"\"\"{isource} &\n",
    "    Direct Obs&\n",
    "    {flux_with_smallest_beam[5]} &\n",
    "    {sobsflux} ± {sobsfluxerr} &\n",
    "    {10**float(flux_with_smallest_beam[3]):.0f} &\n",
    "    {beamobs} &\n",
    "    {flux_with_smallest_beam[4]}\n",
    "    \\\\\\\\\n",
    "    \\enddata\n",
    "\\\\tablecomments{{\n",
    "\\\\textbf{{Direct Observation:}} The observation with the smallest beam size between 200--400~GHz.\\\\\\\\\n",
    "\\\\textbf{{High Dust Extrapolation:}} Not applicable for this source, as no observations 10\\\\% above the frequency of the direct observation are available.\\\\\\\\\n",
    "\\\\textbf{{Low Jet Extrapolation:}} Not applicable for this source, as no observations 10\\\\% below the frequency of the direct observation are available.\n",
    "}}    \n",
    "    \\end{{deluxetable*}}\"\"\")\n",
    "            else:\n",
    "                log_diam_bhs_microarcsec_unc = linear_to_log_uncertainty(diam_bhs_microarcsec,diam_bhs_microarcsec_unc)\n",
    "                log_diam_bhs_microarcsec = np.log10(diam_bhs_microarcsec)\n",
    "                bhs=[log_diam_bhs_microarcsec,log_diam_bhs_microarcsec_unc]\n",
    "                if not fluxs2:\n",
    "                    nograph.append([isource,bhs])\n",
    "                    namesandfiles.append([isource,'chosenfile','noobs'])\n",
    "                else:\n",
    "                    flux_with_smallest_beam = find_flux_with_smallest_beam(fluxs2,isource)\n",
    "                    namesandfiles.append([isource,'chosenfile',flux_with_smallest_beam[6]])\n",
    "            if write==True:\n",
    "                sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Extrapolate High, Low, and Chosen Observations Fluxes\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "write=False\n",
    "\n",
    "sigsmart=True\n",
    "\n",
    "namesandfiles=[]\n",
    "\n",
    "#set extrap to 1 just to extrapolate values for the chosen sources\n",
    "extrap=1\n",
    "\n",
    "if extrap==0:\n",
    "    write=False\n",
    "\n",
    "def round_to_sig_figs(sigsmart,x, n):\n",
    "      if sigsmart==False:\n",
    "          return(x,n)\n",
    "      if x == 0:\n",
    "            return 0\n",
    "      else:\n",
    "            digits = -int(math.floor(math.log10(abs(x)))) + (n - 1)\n",
    "            return round(x, digits)\n",
    "      \n",
    "def round_to_sig_figs2(sigsmart,x, n):\n",
    "      if sigsmart==False:\n",
    "          return(x,n)\n",
    "      if x == 0:\n",
    "            return 0\n",
    "      else:\n",
    "            digits = -int(math.floor(math.log10(abs(x)))) + (n - 1)\n",
    "            return round(x, digits)\n",
    "\n",
    "def count_sig_figs(num_input):\n",
    "\t\t\tnum_str = str(num_input).strip().replace(',', '')\n",
    "\t\t\t# Strip sign\n",
    "\t\t\tif num_str.startswith(('+', '-')):\n",
    "\t\t\t\t\t\tnum_str = num_str[1:]\n",
    "\n",
    "\t\t\t# Handle scientific notation strings by expanding to a plain decimal string\n",
    "\t\t\tif 'e' in num_str.lower():\n",
    "\t\t\t\t\t\tmant, exp = num_str.lower().split('e', 1)\n",
    "\t\t\t\t\t\texp = int(exp)\n",
    "\n",
    "\t\t\t\t\t\t# Separate mantissa integer/decimal\n",
    "\t\t\t\t\t\tif '.' in mant:\n",
    "\t\t\t\t\t\t\t\t\tint_part, dec_part = mant.split('.', 1)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tint_part, dec_part = mant, ''\n",
    "\n",
    "\t\t\t\t\t\t# Digits of mantissa with no dot\n",
    "\t\t\t\t\t\tdigits = ''.join(ch for ch in (int_part + dec_part) if ch.isdigit())\n",
    "\n",
    "\t\t\t\t\t\t# Original decimal index within the digits string\n",
    "\t\t\t\t\t\torig_idx = len(int_part)\n",
    "\n",
    "\t\t\t\t\t\t# New decimal index after shifting by exponent\n",
    "\t\t\t\t\t\tnew_idx = orig_idx + exp\n",
    "\n",
    "\t\t\t\t\t\tif new_idx <= 0:\n",
    "\t\t\t\t\t\t\t\t\tinteger = '0'\n",
    "\t\t\t\t\t\t\t\t\tdecimal = '0' * (-new_idx) + digits\n",
    "\t\t\t\t\t\t\t\t\tnum_str = integer + '.' + decimal\n",
    "\t\t\t\t\t\telif new_idx >= len(digits):\n",
    "\t\t\t\t\t\t\t\t\tinteger = digits + '0' * (new_idx - len(digits))\n",
    "\t\t\t\t\t\t\t\t\tnum_str = integer  # no decimal part needed\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tinteger = digits[:new_idx]\n",
    "\t\t\t\t\t\t\t\t\tdecimal = digits[new_idx:]\n",
    "\t\t\t\t\t\t\t\t\tnum_str = integer + '.' + decimal\n",
    "\n",
    "\t\t\t# Now count sig figs on the plain decimal representation\n",
    "\t\t\tif '.' in num_str:\n",
    "\t\t\t\t\t\tinteger, decimal = num_str.split('.', 1)\n",
    "\t\t\t\t\t\tsig_part = integer.lstrip('0') + ''.join(c for c in decimal if c.isdigit())\n",
    "\t\t\t\t\t\treturn sum(c.isdigit() for c in sig_part)\n",
    "\t\t\telse:\n",
    "\t\t\t\t\t\tsig_part = num_str.lstrip('0').rstrip('0')\n",
    "\t\t\t\t\t\treturn sum(c.isdigit() for c in sig_part)\n",
    "\n",
    "\n",
    "def match_decimal_places(sigsmart,target, reference):\n",
    "      if sigsmart==False:\n",
    "          return f\"{target}\"\n",
    "      # Count digits after decimal in the reference (as string)\n",
    "      ref_str = str(reference)\n",
    "      if '.' in ref_str:\n",
    "            decimals = len(ref_str.split('.')[1])\n",
    "      else:\n",
    "            decimals = 0\n",
    "      \n",
    "      # Format the target to that number of decimal places\n",
    "      return f\"{target:.{decimals}f}\"\n",
    "\n",
    "sourcesofinterest=('4258','1194','3079','4945','Circinus','1068')\n",
    "\n",
    "lim1=[200,400]\n",
    "\n",
    "threshold=0.0015\n",
    "\n",
    "get_freq_chosen=[]\n",
    "\n",
    "def find_flux_with_smallest_beam(arrays,isource):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    # flux,fluxunc,beam,freq,date,telescope\n",
    "    arrays = np.array(arrays)\n",
    "    index_of_smallest_beam = np.argmin(arrays[:, 2].astype(float))\n",
    "    flux = arrays[index_of_smallest_beam, 0]\n",
    "    fluxunc = arrays[index_of_smallest_beam, 1]\n",
    "    beam = arrays[index_of_smallest_beam, 2]\n",
    "    freq = arrays[index_of_smallest_beam, 3]\n",
    "    date = arrays[index_of_smallest_beam, 4].replace('_1','')\n",
    "    tele = arrays[index_of_smallest_beam, 5]\n",
    "    file = arrays[index_of_smallest_beam, 6].replace('\\n','')\n",
    "    return flux, fluxunc, beam, freq, date, tele, file\n",
    "\n",
    "def find_fluxs_with_high_freq(arrays, logfreq_flux_with_smallest_beam):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "\n",
    "    arrays = np.array(arrays)\n",
    "    index_of_highest_freq = np.argmax(arrays[:, 3].astype(float))\n",
    "    high_freq=10**float(arrays[index_of_highest_freq, 3])\n",
    "\n",
    "    if high_freq==freq_chosen:\n",
    "        return('NA')\n",
    "    \n",
    "    result_entries = []\n",
    "\n",
    "    #flux = arrays[index_of_highest_freq, 0]\n",
    "    #fluxunc = arrays[index_of_highest_freq, 1]\n",
    "    #beam = arrays[index_of_highest_freq, 2]\n",
    "    #freq = arrays[index_of_highest_freq, 3]\n",
    "    #date = arrays[index_of_highest_freq, 4]\n",
    "    #tele = arrays[index_of_highest_freq, 5]\n",
    "\n",
    "    #result_entries.append((flux, fluxunc, beam, freq, date, tele))\n",
    "\n",
    "    for i, entry in enumerate(arrays):\n",
    "        ifreq = 10**float(entry[3])\n",
    "        #if ifreq > freq_chosen:\n",
    "        if (ifreq / freq_chosen) > 1.099:\n",
    "            # Frequency is more than 10% 10\\\\% higher than the chosen frequency\n",
    "            result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]))\n",
    "\n",
    "    return  result_entries\n",
    "\n",
    "def find_fluxs_with_low_freq(arrays, logfreq_flux_with_smallest_beam):\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "\n",
    "    arrays = np.array(arrays)\n",
    "    #these variables should be changed to represent lowest frequency... it was copy and pasted from find_fluxs_with_high_freq\n",
    "    index_of_highest_freq = np.argmin(arrays[:, 3].astype(float))\n",
    "    high_freq=10**float(arrays[index_of_highest_freq, 3])\n",
    "\n",
    "    if high_freq==freq_chosen:\n",
    "        return('NA')\n",
    "    \n",
    "    result_entries = []\n",
    "\n",
    "    #flux = arrays[index_of_highest_freq, 0]\n",
    "    #fluxunc = arrays[index_of_highest_freq, 1]\n",
    "    #beam = arrays[index_of_highest_freq, 2]\n",
    "    #freq = arrays[index_of_highest_freq, 3]\n",
    "    #date = arrays[index_of_highest_freq, 4]\n",
    "    #tele = arrays[index_of_highest_freq, 5]\n",
    "    #result_entries.append((flux, fluxunc, beam, freq, date, tele))\n",
    "\n",
    "    for i, entry in enumerate(arrays):\n",
    "        ifreq = 10**float(entry[3])\n",
    "        #if ifreq < freq_chosen:\n",
    "        if (ifreq / freq_chosen) < 0.901:\n",
    "            # Frequency is more than 10% 10\\\\% lower than the chosen frequency\n",
    "            result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]))\n",
    "\n",
    "    return  result_entries\n",
    "\n",
    "def dust_extrap_lowest(arrays, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam):\n",
    "\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "    beam_chosen=10**float(logbeam_flux_with_smallest_beam)\n",
    "\n",
    "    result_entries = []\n",
    "\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    for entry in arrays:\n",
    "        ilogflux = float(entry[0])\n",
    "        iflux = 10**float(entry[0])\n",
    "        \n",
    "        ilogfluxunc = entry[1]\n",
    " \n",
    "        if ilogfluxunc!='NA':\n",
    "            ifluxunc = log_to_linear_uncertainty(ilogflux, float(ilogfluxunc))\n",
    "        else:\n",
    "            ifluxunc = 'NA'\n",
    "\n",
    "        ibeam = 10**float(entry[2])\n",
    "        ifreq = 10**float(entry[3])\n",
    "\n",
    "        iflux_extrap = iflux * (freq_chosen/ifreq)**4.5\n",
    "\n",
    "        #dust emission is extended... not a point source\n",
    "        iflux_extrap = iflux_extrap * (beam_chosen/ibeam)**2\n",
    "\n",
    "        if ifluxunc!='NA':\n",
    "            iflux_extrap_unc = ifluxunc * (freq_chosen/ifreq)**4.5\n",
    "            iflux_extrap_unc = iflux_extrap_unc * (beam_chosen/ibeam)**2\n",
    "            iflux_extrap_unc = linear_to_log_uncertainty(iflux_extrap,iflux_extrap_unc)\n",
    "        else:\n",
    "            iflux_extrap_unc = 'NA'\n",
    "\n",
    "        iflux_extrap= np.log10(iflux_extrap)\n",
    "        result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], iflux_extrap, iflux_extrap_unc, entry[5]))\n",
    "\n",
    "    # Find the entry with the lowest extrapolated flux\n",
    "    min_flux_entry = min(result_entries, key=lambda x: x[5])  # x[5] accesses the iflux_extrap\n",
    "    max_flux_entry = max(result_entries, key=lambda x: x[5])\n",
    "\n",
    "    # Return the details from the entry with the lowest extrapolated flux\n",
    "    flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele = min_flux_entry  # Unpacking the details from the entry tuple\n",
    "    flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2 = max_flux_entry  # Unpacking the details from the entry tuple\n",
    "    return [flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele],[flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2]\n",
    "\n",
    "\n",
    "def jet_extrap(arrays, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam):\n",
    "\n",
    "    freq_chosen=10**float(logfreq_flux_with_smallest_beam)\n",
    "    beam_chosen=10**float(logbeam_flux_with_smallest_beam)\n",
    "\n",
    "    result_entries = []\n",
    "\n",
    "    # Find the index of the smallest beam size in the array\n",
    "    for entry in arrays:\n",
    "        ilogflux = float(entry[0])\n",
    "        iflux = 10**float(entry[0])\n",
    "        \n",
    "        ilogfluxunc = entry[1]\n",
    " \n",
    "        if ilogfluxunc!='NA':\n",
    "            ifluxunc = log_to_linear_uncertainty(ilogflux, float(ilogfluxunc))\n",
    "        else:\n",
    "            ifluxunc = 'NA'\n",
    "\n",
    "        ibeam = 10**float(entry[2])\n",
    "        ifreq = 10**float(entry[3])\n",
    "\n",
    "        iflux_extrap = iflux * (freq_chosen/ifreq)**(-0.5)\n",
    "\n",
    "        #compact jet is a point source... no beam correction\n",
    "        #iflux_extrap = iflux_extrap * (beam_chosen/ibeam)**2\n",
    "\n",
    "        if ifluxunc!='NA':\n",
    "            iflux_extrap_unc = ifluxunc * (freq_chosen/ifreq)**(-0.5)\n",
    "            iflux_extrap_unc = linear_to_log_uncertainty(iflux_extrap,iflux_extrap_unc)\n",
    "        else:\n",
    "            iflux_extrap_unc = 'NA'\n",
    "\n",
    "        iflux_extrap= np.log10(iflux_extrap)\n",
    "        result_entries.append((entry[0], entry[1], entry[2], entry[3], entry[4], iflux_extrap, iflux_extrap_unc, entry[5]))\n",
    "\n",
    "    # Find the entry with the lowest extrapolated flux\n",
    "    min_flux_entry = min(result_entries, key=lambda x: x[5])  # x[1] accesses the iflux_extrap\n",
    "    max_flux_entry = max(result_entries, key=lambda x: x[5])\n",
    "    # Return the details from the entry with the lowest extrapolated flux\n",
    "    flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele = min_flux_entry  # Unpacking the details from the entry tuple\n",
    "    flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2 = max_flux_entry  # Unpacking the details from the entry tuple\n",
    "\n",
    "    return [flux, fluxunc, beam, freq, date, iflux_extrap, iflux_extrap_unc, tele],[flux2, fluxunc2, beam2, freq2, date2, iflux_extrap2, iflux_extrap_unc2, tele2]\n",
    "\n",
    "\n",
    "def linear_to_log_uncertainty(lin_x, lin_delta_x):\n",
    "    return lin_delta_x / (lin_x * np.log(10))\n",
    "\n",
    "def log_to_linear_uncertainty(log_x, log_x_uncertainty):\n",
    "    return float(log_x_uncertainty) * 10**float(log_x) * np.log(10)\n",
    "\n",
    "graph_array1=[]\n",
    "graph_array2=[]\n",
    "\n",
    "nograph=[]\n",
    "\n",
    "                        #'flux'\n",
    "                        #'frequency'         \n",
    "                        #'beam size'\n",
    "                        #'date'  \n",
    "\n",
    "for isource, data in grouped_data.items():\n",
    "    breaker=1\n",
    "    if extrap==1:\n",
    "        for i in sourcesofinterest:\n",
    "            if i.lower() in isource.lower():\n",
    "                breaker=0\n",
    "        if breaker==1:\n",
    "            continue\n",
    "\n",
    "    contam_table=f'contam_{isource}.tex'\n",
    "\n",
    "    with open(contam_table, 'w') as file:\n",
    "        if write==True:\n",
    "            original_stdout = sys.stdout\n",
    "            sys.stdout = file\n",
    "\n",
    "        # Main loop to read and process sources from the input file\n",
    "        if os.path.exists(txtnamesandcoords):\n",
    "            with open(txtnamesandcoords, 'r') as infile:\n",
    "                for line in infile:\n",
    "\n",
    "                    # Parse the line into a list of name-coordinate pairs\n",
    "                    params = ast.literal_eval(line)\n",
    "                    for inamecoords in params:                \n",
    "                        source_name = inamecoords[0][0]\n",
    "                        if not isource.lower() in source_name.lower():\n",
    "                            continue\n",
    "                        source=source_name\n",
    "                        ra = inamecoords[1][1]\n",
    "                        dec = inamecoords[1][2]  # Galaxy Dec in sexagesimal format\n",
    "                        findvals=process_source(source_name, wantrefs, ra, dec, threshold, inamecoords)\n",
    "                        distanceMPc=findvals[0][0]\n",
    "                        distanceMPc_uncer=findvals[0][1]\n",
    "                        method=findvals[1]\n",
    "                        ynfindref=findvals[2]\n",
    "                        refcode=findvals[3]\n",
    "                        red_depend=findvals[4]\n",
    "        else:\n",
    "            print(f\"File {txtnamesandcoords} does not exist.\")\n",
    "\n",
    "        arcsectokpc= np.pi / (180 * 3600) * distanceMPc * 1000\n",
    "        arcsectopc=arcsectokpc*1000\n",
    "\n",
    "        arcsectokpc_error = np.pi / (180 * 3600) * distanceMPc_uncer * 1000\n",
    "        arcsectopc_unc=arcsectokpc_error*1000\n",
    "\n",
    "        arcsectopc_fracerror=(arcsectopc_unc/arcsectopc)*100\n",
    "\n",
    "        distance='NA'\n",
    "        with open(Greenepath, 'r') as infile:\n",
    "            j=-1\n",
    "            breaker=1\n",
    "            for line in infile:\n",
    "                j=j+1\n",
    "                if j>20:\n",
    "                    continue\n",
    "                source_name=line.split(' ')[0]\n",
    "                source_name=source_name.replace(\"−\",\"-\")\n",
    "                if isource=='WISEAJ043703':\n",
    "                    isource='J0437'\n",
    "                if isource.lower() in source_name.lower():\n",
    "                    log_BH_mass_solar=line.split(' ')[3]\n",
    "                    log_BH_mass_solar_offset=line.split(' ')[5]\n",
    "                    breaker=0\n",
    "                if 'cgcg' in isource.lower():\n",
    "                    log_BH_mass_solar=7.38\n",
    "                    log_BH_mass_solar_offset=0.012\n",
    "                    breaker=0\n",
    "                if '4945' in isource.lower():\n",
    "                    log_BH_mass_solar=6.15\n",
    "                    log_BH_mass_solar_offset='NA'\n",
    "                    breaker=0\n",
    "            if breaker!=1:\n",
    "                mass, mass_unc, mass_fracerror, distance, distance_uncer, dist_fracerror, diam_bhs_microarcsec, diam_bhs_microarcsec_unc, diam_bhs_microarcsec_fracerror=getsize(log_BH_mass_solar,log_BH_mass_solar_uncer,distanceMPc,distanceMPc_uncer,arcsectopc,arcsectopc_unc)\n",
    "            else:\n",
    "                print(f'{source} not found')\n",
    "            \n",
    "\n",
    "            fluxs1=[]\n",
    "            fluxs2=[]\n",
    "            fluxsuplim=[]\n",
    "            with open(source_text, 'r') as infile:\n",
    "                j=-1\n",
    "                for line in infile:\n",
    "                    if line=='\\n':\n",
    "                        continue\n",
    "                    line=eval(line)\n",
    "                    source=line[0]\n",
    "                    if isource in source:\n",
    "                        file=line[7]\n",
    "                        telescope=line[1]\n",
    "                        if telescope=='VLBA':\n",
    "                            continue\n",
    "                        date=line[4].replace('_1','')\n",
    "                        snr=line[6].split('\\n')[0]\n",
    "\n",
    "                        freq=np.log10(float(line[2]))\n",
    "                        flux=np.log10(float(str(line[3]).split('*')[0]))\n",
    "                        checklow=len(str(line[3]).split('*'))\n",
    "                        if snr!='NA':\n",
    "                            linflux=float(line[3].split('*')[0])\n",
    "                            linfluxunc=float(linflux)/float(snr)\n",
    "\n",
    "                            fluxunc=linear_to_log_uncertainty(linflux,linfluxunc)\n",
    "                        else:\n",
    "                            fluxunc='NA'\n",
    "\n",
    "                        if '-' not in line[5]:\n",
    "                            beam=np.log10(float(line[5]))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        #for extrap==0 we are looking for an obs to fix the coordinates for all the fits\n",
    "                        #we look for an observations in the 200-400 GHz range that are a detection... then to \n",
    "                        #all other frequency ranges.  We look for the highest resolution that is a detection\n",
    "                        if extrap==0 and checklow==1:\n",
    "                            if 10**freq<lim1[1] and 10**freq>lim1[0]:\n",
    "                                if date=='2021/09/03':\n",
    "                                    #input(linflux)\n",
    "                                    #input(linfluxunc)\n",
    "                                    pass\n",
    "                                fluxs1.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "                            fluxs2.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "\n",
    "                        #for extrap==1 we are extrapolating to the chosen frequency... which is the frequency\n",
    "                        #of the obs of the highest resolution in the 200-400GHz range.  In this case we do not \n",
    "                        #care about lower limits. If the observation of highest resolution is a lower limit this\n",
    "                        #is what is reported... furthermore extrapolations are upper limits so that we include \n",
    "                        #non detections for this as well\n",
    "                        if extrap==1:\n",
    "                            if 10**freq<lim1[1] and 10**freq>lim1[0]:\n",
    "                                if date=='2021/09/03':\n",
    "                                    #input(linflux)\n",
    "                                    #input(linfluxunc)\n",
    "                                    pass\n",
    "                                fluxs1.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "                            fluxs2.append([flux,fluxunc,beam,freq,date,telescope,file])\n",
    "            if fluxs1:      \n",
    "                graph_array1.append(isource)\n",
    "                flux_with_smallest_beam = find_flux_with_smallest_beam(fluxs1,isource)\n",
    "\n",
    "                if flux_with_smallest_beam[1]!='NA':\n",
    "                    sobsfluxerr=f'{log_to_linear_uncertainty(flux_with_smallest_beam[0],flux_with_smallest_beam[1]):.1f}'\n",
    "                    if sobsfluxerr=='0.0':\n",
    "                        sobsflux=f'{10**float(flux_with_smallest_beam[0]):.2f}'\n",
    "                        sobsfluxerr=f'{log_to_linear_uncertainty(flux_with_smallest_beam[0],flux_with_smallest_beam[1]):.2f}'\n",
    "                    else:\n",
    "                        sobsflux=f'{10**float(flux_with_smallest_beam[0]):.1f}'\n",
    "                else:\n",
    "                    sobsfluxerr='NA'\n",
    "                    sobsflux=f'{10**float(flux_with_smallest_beam[0]):.1f}'\n",
    "                \n",
    "                \n",
    "                namesandfiles.append([isource,'chosenfile',flux_with_smallest_beam[6]])\n",
    "                if extrap==0:\n",
    "                    continue\n",
    "\n",
    "                logbeam_flux_with_smallest_beam=flux_with_smallest_beam[2]\n",
    "                logfreq_flux_with_smallest_beam=flux_with_smallest_beam[3]\n",
    "                get_freq_chosen.append([isource,10**float(logfreq_flux_with_smallest_beam),10**float(logbeam_flux_with_smallest_beam)])\n",
    "\n",
    "                graph_array1.append(flux_with_smallest_beam)\n",
    "                log_diam_bhs_microarcsec_unc = linear_to_log_uncertainty(diam_bhs_microarcsec,diam_bhs_microarcsec_unc)\n",
    "                log_diam_bhs_microarcsec = np.log10(diam_bhs_microarcsec)\n",
    "                if '4945' in isource:\n",
    "                    log_diam_bhs_microarcsec_unc=0\n",
    "                bhs=[log_diam_bhs_microarcsec,log_diam_bhs_microarcsec_unc]\n",
    "                graph_array1.append(bhs)\n",
    "                flux_high_freq_high_beam='NA'\n",
    "                flux_low_freq_low_beam='NA'\n",
    "\n",
    "                beamobs=10**float(flux_with_smallest_beam[2])\n",
    "                beamobs=format_number(beamobs)\n",
    "\n",
    "                beamhigh='NA'\n",
    "                beamlow='NA'\n",
    "                freqlow='NA'\n",
    "                if fluxs2:\n",
    "                    fluxs_with_highest_freq = find_fluxs_with_high_freq(fluxs2,logfreq_flux_with_smallest_beam)\n",
    "                    fluxs_with_lowest_freq = find_fluxs_with_low_freq(fluxs2,logfreq_flux_with_smallest_beam)\n",
    "                    \n",
    "\n",
    "                    obsflux_str = sobsflux            # e.g. \"12.30\" or \"0.0450\"\n",
    "                    # Count sig figs from the string to preserve trailing zeros:\n",
    "                    obs_sigs = count_sig_figs(obsflux_str)\n",
    "                    print(isource)\n",
    "                    if fluxs_with_highest_freq != 'NA':\n",
    "                        flux_high_freq_high_beam, flux_high_freq_high_beam2 = dust_extrap_lowest(fluxs_with_highest_freq, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam)\n",
    "                        print('high')\n",
    "                        print(flux_high_freq_high_beam[0])\n",
    "                        print(flux_high_freq_high_beam[1])\n",
    "                        #low lim\n",
    "                        beamhigh=10**float(flux_high_freq_high_beam[2])\n",
    "                        beamhigh=format_number(beamhigh)\n",
    "\n",
    "                        highflux=10**float(flux_high_freq_high_beam[5])\n",
    "                        highfluxerr=log_to_linear_uncertainty(flux_high_freq_high_beam[5],flux_high_freq_high_beam[6])\n",
    "\n",
    "                        highflux=round_to_sig_figs(sigsmart,highflux, obs_sigs)\n",
    "                        highfluxerr=match_decimal_places(sigsmart,highfluxerr, highflux)\n",
    "                        #high lim\n",
    "                        beamhigh2=10**float(flux_high_freq_high_beam2[2])\n",
    "                        beamhigh2=format_number(beamhigh2)\n",
    "\n",
    "                        highflux2=10**float(flux_high_freq_high_beam2[5])\n",
    "                        highfluxerr2=log_to_linear_uncertainty(flux_high_freq_high_beam2[5],flux_high_freq_high_beam2[6])\n",
    "\n",
    "                        highflux2=round_to_sig_figs(sigsmart,highflux2, obs_sigs)\n",
    "                        highfluxerr2=match_decimal_places(sigsmart,highfluxerr2, highflux2)\n",
    "\n",
    "                        if fluxs_with_lowest_freq != 'NA':\n",
    "                            flux_low_freq_low_beam,flux_low_freq_low_beam2 = jet_extrap(fluxs_with_lowest_freq, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam)\n",
    "                            #low lim\n",
    "                            freqlow=10**float(flux_low_freq_low_beam[3])\n",
    "                            if freqlow<10:\n",
    "                                freqlow=f\"{freqlow:.1f}\"\n",
    "                            else:\n",
    "                                freqlow=f\"{freqlow:.0f}\"\n",
    "                            beamlow=10**float(flux_low_freq_low_beam[2])\n",
    "                            beamlow=format_number(beamlow)\n",
    "\n",
    "                            lowflux=10**float(flux_low_freq_low_beam[5])\n",
    "                            lowflux=round_to_sig_figs(sigsmart,lowflux, obs_sigs)\n",
    "\n",
    "                            if flux_low_freq_low_beam[6] == 'NA':\n",
    "                                lowfluxerr='NA'\n",
    "                                lowflux = f'{lowflux}*'\n",
    "                            else:\n",
    "                                lowfluxerr=log_to_linear_uncertainty(flux_low_freq_low_beam[5],flux_low_freq_low_beam[6])\n",
    "                                lowfluxerr=match_decimal_places(sigsmart,lowfluxerr, lowflux)\n",
    "\n",
    "\n",
    "                            #high lim\n",
    "                            freqlow2=10**float(flux_low_freq_low_beam2[3])\n",
    "                            if freqlow2<10:\n",
    "                                freqlow2=f\"{freqlow2:.1f}\"\n",
    "                            else:\n",
    "                                freqlow2=f\"{freqlow2:.0f}\"\n",
    "                            beamlow2=10**float(flux_low_freq_low_beam2[2])\n",
    "                            beamlow2=format_number(beamlow2)\n",
    "\n",
    "                            lowflux2=10**float(flux_low_freq_low_beam2[5])\n",
    "                            lowflux2=round_to_sig_figs(sigsmart,lowflux2, obs_sigs)\n",
    "\n",
    "\n",
    "                            if flux_low_freq_low_beam2[6] == 'NA':\n",
    "                                lowfluxerr2='NA'\n",
    "                                lowflux2= f'{lowflux2}*'\n",
    "                            else:\n",
    "                                lowfluxerr2=log_to_linear_uncertainty(flux_low_freq_low_beam2[5],flux_low_freq_low_beam2[6])\n",
    "                                lowfluxerr2=match_decimal_places(sigsmart,lowfluxerr2, lowflux2)\n",
    "                    else:\n",
    "                        flux_low_freq_low_beam,flux_low_freq_low_beam2 = jet_extrap(fluxs_with_lowest_freq, logfreq_flux_with_smallest_beam, logbeam_flux_with_smallest_beam)\n",
    "                        #print('high')\n",
    "                        #print(flux_low_freq_low_beam[1])                    \n",
    "                        if flux_low_freq_low_beam[6]!='NA':\n",
    "                            print_low=f'{10**float(flux_low_freq_low_beam[5]):.2f} ± {log_to_linear_uncertainty(flux_low_freq_low_beam[5],flux_low_freq_low_beam[6]):.2f}'\n",
    "                        else:\n",
    "                            print_low = f'{10**float(flux_low_freq_low_beam[5]):.2f}*'\n",
    "                        if fluxs_with_lowest_freq != 'NA':\n",
    "\n",
    "\n",
    "                            freqlow=10**float(flux_low_freq_low_beam[3])\n",
    "                            if freqlow<10:\n",
    "                                freqlow=f\"{freqlow:.1f}\"\n",
    "                            else:\n",
    "                                freqlow=f\"{freqlow:.0f}\"\n",
    "                            beamlow=10**float(flux_low_freq_low_beam[2])\n",
    "                            beamlow=format_number(beamlow)\n",
    "\n",
    "                            if flux_low_freq_low_beam[6]=='NA':\n",
    "                                lowflux=10**float(flux_low_freq_low_beam[5])\n",
    "                                lowflux=round_to_sig_figs(sigsmart,lowflux, obs_sigs)\n",
    "                                print_lowflux = f'{lowflux}*'\n",
    "\n",
    "                            else:\n",
    "                                lowflux=10**float(flux_low_freq_low_beam[5])\n",
    "                                lowflux=round_to_sig_figs(sigsmart,lowflux, obs_sigs)\n",
    "\n",
    "                                lowfluxerr=log_to_linear_uncertainty(flux_low_freq_low_beam[5],flux_low_freq_low_beam[6])\n",
    "                                lowfluxerr=match_decimal_places(sigsmart,lowfluxerr, lowflux)\n",
    "\n",
    "                                print_lowflux = f'{lowflux} ± {lowfluxerr}'\n",
    "            else:\n",
    "                log_diam_bhs_microarcsec_unc = linear_to_log_uncertainty(diam_bhs_microarcsec,diam_bhs_microarcsec_unc)\n",
    "                log_diam_bhs_microarcsec = np.log10(diam_bhs_microarcsec)\n",
    "                bhs=[log_diam_bhs_microarcsec,log_diam_bhs_microarcsec_unc]\n",
    "                if not fluxs2:\n",
    "                    nograph.append([isource,bhs])\n",
    "                    namesandfiles.append([isource,'chosenfile','noobs'])\n",
    "                else:\n",
    "                    flux_with_smallest_beam = find_flux_with_smallest_beam(fluxs2,isource)\n",
    "                    namesandfiles.append([isource,'chosenfile',flux_with_smallest_beam[6]])\n",
    "            if write==True:\n",
    "                sys.stdout = original_stdout\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vlbi comments\n",
    "comments_ngc1068='NGC~1068 exhibits multiple spatial components across GHz frequencies, typically interpreted as a central nuclear source flanked by northern and southern jet features, each separated by approximately 0.2~arcsec from the nucleus. Detection of the central component varies between studies, possibly due to intrinsic variability or resolution limitations. Extrapolated fluxes are computed by summing all resolved components and scaling to 225~GHz using a power-law index of $-0.5$.'\n",
    "comments_circinus='Only a single unresolved component is detected. The extrapolated flux is calculated by applying a power-law index of $-0.5$ to scale the observed value to 349~GHz.'\n",
    "comments_ngc4258='NGC~4258 exhibits two compact jet components separated by 0.002~arcseconds. The brightness of the northern component is variable, while the southern component appears stable. The extrapolated flux listed here is derived by summing the flux densities of both components and extrapolating to 225~GHz using a power-law index of $-0.5$. The central region remains unresolved and is presumed to mark the location of the SMBH.'\n",
    "comments_ngc3079='NGC~3079 exhibits four compact, variable radio components (A, B, C, and D), with separations ranging from 0.005\\\\arcsec{} to 0.06\\\\arcsec{}. Maser emission suggests the SMBH lies in a quiet region between components~A and B \\\\citet{Kondratko2005}. Detection of individual components varies across observations depending on observing frequency and intrinsic source variability. Extrapolated fluxes are computed by summing all resolved components and applying a power-law index of $-0.5$ to scale to 225~GHz.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low Radio VLBI TOT\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import math\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "import re\n",
    "import decimal\n",
    "import numpy as np\n",
    "\n",
    "getcontext().prec = 25\n",
    "\n",
    "def flux_key(val):\n",
    "    # Numeric types (Decimal, float, int, NumPy scalars)\n",
    "    if isinstance(val, (int, float, decimal.Decimal, np.floating)):\n",
    "        return float(val)\n",
    "    # String case: extract all numbers, pick the larger if multiple\n",
    "    if isinstance(val, str):\n",
    "        nums = re.findall(r'[-+]?\\d+(?:\\.\\d+)?(?:[eE][-+]?\\d+)?', val)\n",
    "        if not nums:\n",
    "            raise ValueError(f\"no numeric content in {val!r}\")\n",
    "        return min(float(n) for n in nums)\n",
    "    # Fallback: try casting\n",
    "    return float(val)\n",
    "\n",
    "write1=True\n",
    "write1=False\n",
    "\n",
    "def writesource(isource, array, comments):\n",
    "    contam_table=f'contam_{isource}.tex'\n",
    "    with open(contam_table, 'r') as file:\n",
    "        line=file.readlines()\n",
    "        found=0\n",
    "        i=-1\n",
    "        for iline in line:\n",
    "            i=i+1\n",
    "            if 'Extended Jet' in iline:\n",
    "                found=1\n",
    "                ifound=i\n",
    "        if found==1:\n",
    "            foundfluxval,foundfluxvalunc=(line[ifound+2].replace('&','')).split('±')\n",
    "            foundfluxval=float(foundfluxval)\n",
    "    for i in get_freq_chosen:\n",
    "        if isource==i[0]:\n",
    "            freq_chosen=float(i[1])\n",
    "            beam_chosen=float(i[2])\n",
    "    alltots=writetotsource(array,freq_chosen)\n",
    "\n",
    "    vlbi_table2=f'VLBI_tot_{isource}.tex'\n",
    "            \n",
    "    min_idx = min(range(len(alltots)), key=lambda i: flux_key(alltots[i][0]))\n",
    "    min_val = flux_key(alltots[min_idx][0])\n",
    "    newrefs = [row[2].replace(', ', '') for row in alltots]\n",
    "    newrefs=list(set(newrefs))\n",
    "    newrefstring = f\"\\\\citep{{{','.join(newrefs)}}}\"\n",
    "\n",
    "    if min_val==foundfluxval:\n",
    "        input('SAME FLUXES')\n",
    "\n",
    "    if min_val>foundfluxval:\n",
    "        pass\n",
    "    elif min_val<foundfluxval:\n",
    "        for i, iarray in enumerate(alltots):\n",
    "            if i != min_idx:\n",
    "                continue   # skip everything except the min entry\n",
    "            freq=float(iarray[4])\n",
    "            if freq<10:\n",
    "                freq=f\"{freq:.1f}\"\n",
    "            else:\n",
    "                freq=f\"{freq:.0f}\"\n",
    "\n",
    "            beamsize=iarray[5]\n",
    "            beamsize=format_number(beamsize)\n",
    "\n",
    "            if iarray[1]!='NA':\n",
    "                printflux=f\"{iarray[0]} ± {iarray[1]}\"\n",
    "            else:\n",
    "                printflux=f'{iarray[0]}*'\n",
    "    \n",
    "            newref =iarray[2].replace(', ', '')\n",
    "            newrefstring=newrefstring.replace(newref,'')\n",
    "            newrefstring=newrefstring.replace('{,','{')\n",
    "            newrefstring=newrefstring.replace(',}','}')\n",
    "            newrefstring2=f\"\\\\citep{{{newref}}}\"+\"$^{1}$\"\n",
    "            newrefstring=newrefstring2+', ' + newrefstring\n",
    "\n",
    "\n",
    "\n",
    "            with open(contam_table, 'r') as file:\n",
    "                line=file.readlines()\n",
    "                found=0\n",
    "                i=-1\n",
    "                for iline in line:\n",
    "                    i=i+1\n",
    "                    if 'Extended Jet' in iline:\n",
    "                        found=1\n",
    "                        ifound=i\n",
    "\n",
    "            line[ifound+1] = 'VLBI$^{1}$ &\\n'  \n",
    "            line[ifound+2] = f'{printflux} &\\n'\n",
    "            line[ifound+3] = f'{freq} &\\n'\n",
    "            line[ifound+4] = f'{beamsize} &\\n'\n",
    "            line[ifound+5] = f'{iarray[3]}  \\n'\n",
    "            line[ifound+11]=line[ifound+11].replace('than the direct observation', f'than the direct observation and VLBI observations from {newrefstring} are considered.')    \n",
    "\n",
    "\n",
    "            # 4) Write back (overwrite)\n",
    "            contam_table_new=contam_table.replace('.tex','_new.tex')\n",
    "            with open(contam_table_new, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.writelines(line)\n",
    "\n",
    "def writetotsource(array,freq_chosen):\n",
    "    returnvals=[]\n",
    "\n",
    "    new_array = []\n",
    "\n",
    "    # Split the array into chunks of 7\n",
    "    for i in range(0, len(array), 7):\n",
    "        iarray = array[i:i+7]\n",
    "        new_array.append(iarray)\n",
    "    \n",
    "    # Sort the array by the first 5 elements of each sub-array\n",
    "    new_array.sort(key=lambda x: x[:5])\n",
    "\n",
    "    # Group the sorted array by the first 5 elements\n",
    "    grouped_refs = [list(group) for _, group in groupby(new_array, key=lambda x: x[:5])]\n",
    "    for i in grouped_refs:\n",
    "        totflux=[]\n",
    "        totflux_err=[]\n",
    "        ref=i[0][1]\n",
    "        date=i[0][2]\n",
    "        freq=float(i[0][3])\n",
    "        beamsize=i[0][4]\n",
    "\n",
    "        for ii in i:\n",
    "            if len(str(ii[6][0]).split(\"*\"))<2:\n",
    "                totflux.append(ii[6][0])\n",
    "            else:\n",
    "                totflux.append(ii[6][0].split('*')[0])\n",
    "            if ii[6][1]!='NA':\n",
    "                totflux_err.append(ii[6][1])\n",
    "            else:\n",
    "                totflux_err.append('NA')\n",
    "        # Add the fluxes and propagate the errors\n",
    "\n",
    "        totflux_err = [Decimal(item) for item in totflux_err if item != 'NA']\n",
    "        totflux_errcop = copy.deepcopy(totflux_err)\n",
    "        if totflux_err==[]:\n",
    "            totflux_err = 'NA'\n",
    "        else:\n",
    "            findsumlen=np.sum(np.array(totflux_err))\n",
    "            findsumlen1=copy.deepcopy(findsumlen)\n",
    "            findsumlen=[float(item) for item in totflux_err]\n",
    "            findsumlen_decimal = [Decimal(str(x)) for x in findsumlen]\n",
    "            findsumlen = sum(findsumlen_decimal)\n",
    "\n",
    "            totflux_err=np.sqrt(np.sum(np.array(totflux_err)**2))\n",
    "            scale_factor = Decimal((freq_chosen / freq) ** (-0.5))\n",
    "            totflux_err = totflux_err * scale_factor\n",
    "\n",
    "        totflux1=copy.deepcopy(totflux)\n",
    "        totflux2=copy.deepcopy(totflux)\n",
    "        sendbacker=0\n",
    "\n",
    "        i=-1\n",
    "        for iflux in totflux:\n",
    "            i=i+1\n",
    "            if '-' in str(iflux):\n",
    "                sendbacker=1\n",
    "                totflux1[i]=float(iflux.split('-')[0])\n",
    "                totflux2[i]=float(iflux.split('-')[1])\n",
    "        if sendbacker==1:\n",
    "            totflux1=[float(item) for item in totflux1]\n",
    "            totflux2=[float(item) for item in totflux2]\n",
    "\n",
    "            totflux1=np.sum(totflux1)\n",
    "            totflux1_sigs=count_sig_figs(totflux1)\n",
    "            totflux1=totflux1 * (freq_chosen/freq)**(-0.5)\n",
    "\n",
    "            totflux2=np.sum(totflux2)\n",
    "            totflux2_sigs=count_sig_figs(totflux2)\n",
    "            totflux2=totflux2 * (freq_chosen/freq)**(-0.5)\n",
    "\n",
    "\n",
    "            if totflux1_sigs!=totflux2_sigs:\n",
    "                #input('DIFFERENT SIG FIGS BETWEEN TWO FLUXES')\n",
    "                pass\n",
    "\n",
    "            totflux1=round_to_sig_figs(sigsmart,totflux1, totflux1_sigs)\n",
    "            totflux2=round_to_sig_figs(sigsmart,totflux2, totflux2_sigs)\n",
    "\n",
    "            if totflux1<totflux2:\n",
    "                totflux2=match_decimal_places(sigsmart,totflux2, totflux1)\n",
    "                totflux_err=match_decimal_places(sigsmart,totflux_err, totflux1)\n",
    "            else:\n",
    "                totflux1=match_decimal_places(sigsmart,totflux1, totflux2)\n",
    "                totflux_err=match_decimal_places(sigsmart,totflux_err, totflux2)\n",
    "\n",
    "            sendback=f'{totflux1} , {totflux2}'\n",
    "            returnvals.append([sendback,totflux_err,ref,date,freq,beamsize])\n",
    "\n",
    "        if sendbacker==0:\n",
    "            totflux=[float(item) for item in totflux]\n",
    "            totflux_decimal = [Decimal(str(x)) for x in totflux]\n",
    "            totflux = sum(totflux_decimal)\n",
    "\n",
    "            if totflux_err!='NA':\n",
    "                totflux_sigs=count_sig_figs(totflux+findsumlen1)\n",
    "            else:\n",
    "                totflux_sigs=count_sig_figs(totflux)\n",
    "\n",
    "            scale_factor = Decimal((freq_chosen / freq) ** (-0.5))\n",
    "            totflux = totflux * scale_factor\n",
    "\n",
    "            totflux=round_to_sig_figs(sigsmart,totflux, totflux_sigs)\n",
    "            \n",
    "            if totflux_err!='NA':\n",
    "                totflux_err=match_decimal_places(sigsmart,totflux_err, totflux)\n",
    "\n",
    "                if float(totflux_err) == 0:\n",
    "                    totflux_sigs=totflux_sigs + 1\n",
    "\n",
    "                    totflux = sum(totflux_decimal)\n",
    "                    scale_factor = Decimal((freq_chosen / freq) ** (-0.5))\n",
    "                    totflux = totflux * scale_factor\n",
    "\n",
    "                    totflux=round_to_sig_figs(sigsmart,totflux, totflux_sigs)\n",
    "\n",
    "                    totflux_err = [float(item) for item in totflux_errcop if item != 'NA']\n",
    "                    totflux_err=np.sqrt(np.sum(np.array(totflux_err))**2)\n",
    "\n",
    "                    totflux_err = totflux_err * (freq_chosen/freq)**(-0.5)\n",
    "                    totflux_err=match_decimal_places(sigsmart,totflux_err, totflux)\n",
    "\n",
    "            returnvals.append([totflux,totflux_err,ref,date,freq,beamsize])\n",
    "\n",
    "    return(returnvals)\n",
    "\n",
    "lowradio=[]\n",
    "#Source, Frequency [GHz], Flux [mJy], Beam size, snr, Reference\n",
    "\n",
    "########\n",
    "#NGC 3079\n",
    "ngc3079=[]\n",
    "########\n",
    "\n",
    "#(B-D is 0.06\", A-B is 0.02\", A-C is 5 0.005\"\n",
    "#A is between D and B\n",
    "#C between A and B\n",
    "comments1=comments_ngc3079\n",
    "\n",
    "###\n",
    "#Irwin, 1988, APJ, 335: 658\n",
    "###\n",
    "\n",
    "#frequency: 5GHz\n",
    "#telescope: US VLBI network in Mark 3\n",
    "#date: 1986, June\n",
    "#beam size: .00224 x 0.00074 arcsec\n",
    "beamsize=np.sqrt(.00224*0.00074)\n",
    "\n",
    "#Componet A\n",
    "#flux: 12.3 ± 4.5 mJy\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Irwin, 1988')\n",
    "ngc3079.append('1986, June')\n",
    "ngc3079.append('5')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet A')\n",
    "ngc3079.append(('12.3','4.5'))\n",
    "\n",
    "#Componet B\n",
    "#flux: 12.1 ± 6.7 mJy\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Irwin, 1988')\n",
    "ngc3079.append('1986, June')\n",
    "ngc3079.append('5')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('12.1','6.7'))\n",
    "\n",
    "#Componet C\n",
    "#flux: 19.1 ± 27.0 mJy\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Irwin, 1988')\n",
    "ngc3079.append('1986, June')\n",
    "ngc3079.append('5')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet C')\n",
    "ngc3079.append(('19.1','27.0'))\n",
    "\n",
    "###\n",
    "#Trotter, 1998, APJ 495: 740\n",
    "###\n",
    "\n",
    "#frequency: 5 GHz\n",
    "#telescope: NRAO VLBA\n",
    "#date: 1992 September 15  \n",
    "#beam size: .0084 x .0025 \"\n",
    "beamsize=np.sqrt(.0084*.0025)\n",
    "\n",
    "#Componet A\n",
    "#flux: 6.0 ± 0.5 mJy\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1992, September 15')\n",
    "ngc3079.append('5')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet A')\n",
    "ngc3079.append(('6.0','0.5'))\n",
    "\n",
    "#Componet B\n",
    "#flux: 16.8 ± 0.4 mJy\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1992, September 15')\n",
    "ngc3079.append('5')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('16.8','0.4'))\n",
    "\n",
    "#Componet D\n",
    "#flux: 4.3 ± 0.5 mJy\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1992, September 15')\n",
    "ngc3079.append('5')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet D')\n",
    "ngc3079.append(('4.3','0.5'))\n",
    "\n",
    "#frequency: 8 GHz\n",
    "#telescope: NRAO VLBA\n",
    "#date: 1992 September 29\n",
    "#beam size: .0018 x .0006 \"\n",
    "beamsize=np.sqrt(.0018*.0006)\n",
    "\n",
    "#Componet A\n",
    "#flux: 37 ± 2\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1992, September 29')\n",
    "ngc3079.append('8')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet A')\n",
    "ngc3079.append(('37','2'))\n",
    "\n",
    "#Componet B\n",
    "#flux: 15 ± 2\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1992, September 29')\n",
    "ngc3079.append('8')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('15','2'))\n",
    "\n",
    "#frequency: 22\n",
    "#telescope: NRAO VLBA\n",
    "#date: 1995 January 9\n",
    "#beam size: .0015 x .00098\"\n",
    "beamsize=np.sqrt(.0015*.00098)\n",
    "\n",
    "#Componet A\n",
    "#flux: 6 ± 1\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1995, January 9')\n",
    "ngc3079.append('22')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet A')\n",
    "ngc3079.append(('6','1'))\n",
    "\n",
    "#Componet B\n",
    "#flux: 16 ± 1\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1995, January 9')\n",
    "ngc3079.append('22')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('16','1'))\n",
    "\n",
    "#Componet C\n",
    "#flux: 11 ± 2\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Trotter, 1998')\n",
    "ngc3079.append('1995, January 9')\n",
    "ngc3079.append('22')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet C')\n",
    "ngc3079.append(('11','2'))\n",
    "\n",
    "###\n",
    "#Sawada-Satoh, 2000, PASJ 52: 421\n",
    "###\n",
    "\n",
    "#VLBI: Very Long Baseline Array (VLBA), phased VLA (Y) and the Effelsberg (EB) 100-m\n",
    "#EB: 8.4, 15, 22\n",
    "#VLA: 1.4, 22\n",
    "#VLBA: All\n",
    "\n",
    "#frequency: 1.4 GHz\n",
    "#telescope: VLBA, VLA\n",
    "#date: 1996 October 20\n",
    "#beam size: .0147 x .0128 \"\n",
    "beamsize=np.sqrt(.0147*.0128)\n",
    "\n",
    "#Componet A+C\n",
    "#flux: 5.9 ± 1.7\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('1.4')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet A+C')\n",
    "ngc3079.append(('5.9','1.7'))\n",
    "\n",
    "#Componet B\n",
    "#flux: 5.7 ± 1.7\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('1.4')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('5.7','1.7'))\n",
    "\n",
    "#frequency: 8.4 GHz\n",
    "#telescope: VLBA, EB\n",
    "#date: 1996 October 20\n",
    "#beam size: 0.0013 x 0.00091 \"\n",
    "beamsize=np.sqrt(0.0013*0.0009)\n",
    "\n",
    "#Componet A\n",
    "#flux: 1.9 ± 0.6\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('8.4')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet A')\n",
    "ngc3079.append(('1.9', '0.6'))\n",
    "\n",
    "#Componet B\n",
    "#flux: 14.2 ± 0.7\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('8.4')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('14.2', '0.7'))\n",
    "\n",
    "#Componet C\n",
    "#flux: 2.1 ± 0.9\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('8.4')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet C')\n",
    "ngc3079.append(('2.1', '0.9'))\n",
    "\n",
    "#frequency: 15 GHz\n",
    "#telescope: VLBA, EB\n",
    "#date: 1996 October 20\n",
    "#beam size: 0.00066 x 0.00057 \"\n",
    "beamsize=np.sqrt(0.00066*0.00057)\n",
    "\n",
    "#Componet B\n",
    "#flux: 24.4 ± 0.6\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('15')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('24.4', '0.6'))\n",
    "\n",
    "#frequency: 22 GHz\n",
    "#telescope: VLBA, EB, VLA\n",
    "#date: 1996 October 20\n",
    "#beam size: 0.00041 x 0.0003 \"\n",
    "beamsize=np.sqrt(0.00041*0.0003)\n",
    "\n",
    "#Componet B\n",
    "#flux: 12.1 ± 0.7\n",
    "ngc3079.append('NGC3079')\n",
    "ngc3079.append('Sawada, 2000')\n",
    "ngc3079.append('1996/10/20')\n",
    "ngc3079.append('22')\n",
    "ngc3079.append(beamsize)\n",
    "ngc3079.append('Componet B')\n",
    "ngc3079.append(('12.2', '0.7'))\n",
    "\n",
    "writesource('NGC3079',ngc3079,comments1)\n",
    "\n",
    "#########\n",
    "#NGC 1068\n",
    "ngc1068=[]\n",
    "#########\n",
    "\n",
    "comments1=comments_ngc1068\n",
    "\n",
    "###\n",
    "#Ulvestad, 1987, Astronomical Journal, 93:22, 10.1086/114286:\n",
    "###\n",
    "\n",
    "#North Center and South Components Seperated by 0.3\"\n",
    "\n",
    "#frequency: 1.4 GHz\n",
    "#telescope: VLBI using the European VLBI Network (EVN)\n",
    "#date: 1984 June 16\n",
    "#beam size: 0.06\" X 0.04\"\n",
    "beamsize=np.sqrt(0.06*0.04)\n",
    "#Uncertainties of 10%\n",
    "#Unresolved Core:\n",
    "#Total: 89 + 10 mJy (71 + 10 mJy in a component less than 0.02\" ( 1.5 pc) in diameter)\n",
    "\n",
    "#North\n",
    "#23\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1984, June 16')\n",
    "ngc1068.append('1.4')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('North')\n",
    "ngc1068.append(('23', f'{23/10:.2f}'))\n",
    "\n",
    "#Center\n",
    "#89\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1984, June 16')\n",
    "ngc1068.append('1.4')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Center')\n",
    "ngc1068.append(('89', f'{89/10:.2f}'))\n",
    "\n",
    "#South\n",
    "#35\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1984, June 16')\n",
    "ngc1068.append('1.4')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('South')\n",
    "ngc1068.append(('35', f'{35/10:.2f}'))\n",
    "\n",
    "#frequency: 15 GHz\n",
    "#telescope: VLA\n",
    "#date: 1983 Nov 3 \n",
    "#beam size: 0.136\" X 0.121\"\n",
    "beamsize=np.sqrt(0.136*0.121)\n",
    "#Uncertainties of 20%\n",
    "\n",
    "#North\n",
    "#54\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1983, Nov 3')\n",
    "ngc1068.append('15')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('North')\n",
    "ngc1068.append(('54', f'{54/20:.2f}'))\n",
    "\n",
    "#Center\n",
    "#75\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1983, Nov 3')\n",
    "ngc1068.append('15')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Center')\n",
    "ngc1068.append(('75', f'{75/20:.2f}'))\n",
    "\n",
    "#South\n",
    "#29\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1983, Nov 3')\n",
    "ngc1068.append('15')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('South')\n",
    "ngc1068.append(('29', f'{29/20:.2f}'))\n",
    "\n",
    "#frequency: 23 GHz\n",
    "#telescope: VLA\n",
    "#date: 1983 Nov 2 \n",
    "#beam size: 0.075\" X 0.074\"\n",
    "beamsize=np.sqrt(0.075*0.074)\n",
    "#Uncertainties of 40%\n",
    "\n",
    "#North\n",
    "#33\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1983, Nov 3')\n",
    "ngc1068.append('23')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('North')\n",
    "ngc1068.append(('33', f'{33/40:.2f}'))\n",
    "\n",
    "#Center\n",
    "#63\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1983, Nov 3')\n",
    "ngc1068.append('23')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Center')\n",
    "ngc1068.append(('63', f'{63/40:.2f}'))\n",
    "\n",
    "#South\n",
    "#24\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Ulvestad, 1987')\n",
    "ngc1068.append('1983, Nov 3')\n",
    "ngc1068.append('23')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('South')\n",
    "ngc1068.append(('24', f'{24/40:.2f}'))\n",
    "\n",
    "###\n",
    "#Greenhill, 1996, APJ 472: L21\n",
    "###\n",
    "\n",
    "#frequency: 22 GHz\n",
    "#date: 1994 Nov 5\n",
    "#telescope: VLBA and VLA\n",
    "#beam size: 0.0014 x .001 mas\n",
    "beamsize=np.sqrt(0.0014*0.001)\n",
    "#Core\n",
    "\n",
    "#<0.45mJy at 1 sigma => 1.35 mJy -> 1.4 mJy\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Greenhill, 1996')\n",
    "ngc1068.append('1994, Nov 5')\n",
    "ngc1068.append('22')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Core')\n",
    "ngc1068.append(('1.4*', 'NA'))\n",
    "\n",
    "###\n",
    "#Krips, 2006, A&A: 446:113\n",
    "###\n",
    "\n",
    "#frequency: 100GHz\n",
    "#telescope: IRAM PdBI\n",
    "#date: 2003 February\n",
    "#beam: 2.1 x 1.2\"\n",
    "beamsize=np.sqrt(2.1*1.2)\n",
    "\n",
    "#North\n",
    "#17 ± 0.5\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Krips, 2006')\n",
    "ngc1068.append('2003, February')\n",
    "ngc1068.append('100')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('North')\n",
    "ngc1068.append(('17', '0.5'))\n",
    "\n",
    "#Center\n",
    "#36 ± 0.4 mJy\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Krips, 2006')\n",
    "ngc1068.append('2003, February')\n",
    "ngc1068.append('100')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Center')\n",
    "ngc1068.append(('36', '0.4'))\n",
    "\n",
    "#South\n",
    "#7 ±  0.6\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Krips, 2006')\n",
    "ngc1068.append('2003, February')\n",
    "ngc1068.append('100')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('South')\n",
    "ngc1068.append(('7', '0.6'))\n",
    "\n",
    "#frequency: 300GHz\n",
    "#telescope: IRAM PdBI\n",
    "#date: February 2003\n",
    "#beam: 1.0 x 0.6\"\n",
    "beamsize=np.sqrt(1*0.6)\n",
    "\n",
    "#North\n",
    "#6 ± 1.0\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Krips, 2006')\n",
    "ngc1068.append('2003, February')\n",
    "ngc1068.append('300')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('North')\n",
    "ngc1068.append(('6', '1'))\n",
    "\n",
    "#Center\n",
    "#22 ± 0.8\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Krips, 2006')\n",
    "ngc1068.append('2003, February')\n",
    "ngc1068.append('300')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Center')\n",
    "ngc1068.append(('22', '0.8'))\n",
    "\n",
    "#frequency: 20GHz\n",
    "#telescope: VLBA, GBT, VLA\n",
    "#date: 2021/11/14\n",
    "#beam: 1.34 × 0.52 mas,\n",
    "beamsize=np.sqrt(.00134*0.00052)\n",
    "\n",
    "ngc1068.append('NGC1068')\n",
    "ngc1068.append('Gallimore, 2024')\n",
    "ngc1068.append('2021/11/14')\n",
    "ngc1068.append('22')\n",
    "ngc1068.append(beamsize)\n",
    "ngc1068.append('Center')\n",
    "ngc1068.append(('0.4515', '0.0001'))\n",
    "\n",
    "writesource('NGC1068', ngc1068, comments1)\n",
    "\n",
    "#########\n",
    "#Circinus\n",
    "circinus=[]\n",
    "#########\n",
    "\n",
    "comments1=comments_circinus\n",
    "\n",
    "###\n",
    "#Elmouttie, 1998, MNRAS 297: 1202\n",
    "###\n",
    "\n",
    "#frequency: 1.37 GHz\n",
    "#Telescobe :ATCA in Narrabi\n",
    "#Date: March 1994 - December 1996\n",
    "#beam size: 6.0 x 5.4 \"\n",
    "beamsize=np.sqrt(6*5.4)\n",
    "\n",
    "#flux: 120 ± 0.110 mJy\n",
    "circinus.append('circinus')\n",
    "circinus.append('Elmouttie, 1998')\n",
    "circinus.append('1994/03-1996/12')\n",
    "circinus.append('1.4')\n",
    "circinus.append(beamsize)\n",
    "circinus.append('NA')\n",
    "circinus.append(('120', '12'))\n",
    "\n",
    "#frequency: 2.37 GHz\n",
    "#Telescobe :ATCA in Narrabi\n",
    "#Date: March 1994 - December 1996\n",
    "#beam size: 3.4 x 3.1 \"\n",
    "beamsize=np.sqrt(3.4*3.1)\n",
    "#flux: 70 ± 0.060 mJy\n",
    "circinus.append('circinus')\n",
    "circinus.append('Elmouttie, 1998')\n",
    "circinus.append('1994/03-1996/12')\n",
    "circinus.append('2.37')\n",
    "circinus.append(beamsize)\n",
    "circinus.append('NA')\n",
    "circinus.append(('70', '7'))\n",
    "\n",
    "#frequency: 4.80 GHz\n",
    "#Telescobe :ATCA in Narrabi\n",
    "#Date: March 1994 - December 1996\n",
    "#beam size: 1.4 x 1.3 \"\n",
    "beamsize=np.sqrt(1.4*1.3)\n",
    "#flux: 50 ± 0.080 mJy\n",
    "circinus.append('circinus')\n",
    "circinus.append('Elmouttie, 1998')\n",
    "circinus.append('1994/03-1996/12')\n",
    "circinus.append('4.8')\n",
    "circinus.append(beamsize)\n",
    "circinus.append('NA')\n",
    "circinus.append(('50', '5'))\n",
    "\n",
    "#frequency: 8.64 GHz\n",
    "#Telescobe :ATCA in Narrabi\n",
    "#Date: March 1994 - December 1996\n",
    "#beam size: 0.9 x 0.8 \"\n",
    "beamsize=np.sqrt(0.9*0.8)\n",
    "#flux: 50 ± 0.095 mJy\n",
    "circinus.append('circinus')\n",
    "circinus.append('Elmouttie, 1998')\n",
    "circinus.append('1994/03-1996/12')\n",
    "circinus.append('8.64')\n",
    "circinus.append(beamsize)\n",
    "circinus.append('NA')\n",
    "circinus.append(('50', '5'))\n",
    "\n",
    "writesource('Circinus',circinus,comments1)\n",
    "\n",
    "#########\n",
    "#NGC 4258\n",
    "ngc4258=[]\n",
    "#########\n",
    "\n",
    "#North and South Componets Seperated by 0.002\"\n",
    "comments1=comments_ngc4258\n",
    "\n",
    "###\n",
    "#Herrnstein 1998 ApJ 497 69 \n",
    "    #DOI 10.1086/31128\n",
    "###\n",
    "\n",
    "#frequency:22 GHz\n",
    "#telescope: VLBA and VLA\n",
    "#date: 1997 March 7, 23 and April 7\n",
    "#beam size: 0.0006 x 0.0003 \"\n",
    "beamsize=np.sqrt(0.0006*0.0003)\n",
    "\n",
    "#North\n",
    "#2.5 - 3.5 ± 0.3 mJy\n",
    "ngc4258.append('ngc4258')\n",
    "ngc4258.append('Herrnstein, 1998b')\n",
    "ngc4258.append('1997, March 7, 23 and April 7')\n",
    "ngc4258.append('22')\n",
    "ngc4258.append(beamsize)\n",
    "ngc4258.append('North')\n",
    "ngc4258.append((f'2.5-3.5','0.03'))\n",
    "\n",
    "#Center\n",
    "#<0.220 mJy\n",
    "ngc4258.append('ngc4258')\n",
    "ngc4258.append('Herrnstein, 1998b')\n",
    "ngc4258.append('1997, March 7, 23 and April 7')\n",
    "ngc4258.append('22')\n",
    "ngc4258.append(beamsize)\n",
    "ngc4258.append('Center')\n",
    "ngc4258.append((f'0.220*', 'NA'))\n",
    "#South\n",
    "#0.5 ± 0.1 mJy\n",
    "ngc4258.append('ngc4258')\n",
    "ngc4258.append('Herrnstein, 1998b')\n",
    "ngc4258.append('1997, March 7, 23 and April 7')\n",
    "ngc4258.append('22')\n",
    "ngc4258.append(beamsize)\n",
    "ngc4258.append('South')\n",
    "ngc4258.append(('0.5', '0.1'))\n",
    "\n",
    "writesource('NGC4258', ngc4258, comments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low Radio VLBI INDIV\n",
    "\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import math\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "getcontext().prec = 25\n",
    "\n",
    "write1=False\n",
    "\n",
    "def writesource(isource, array, comments):\n",
    "    for i in get_freq_chosen:\n",
    "        if isource==i[0]:\n",
    "            freq_chosen=float(i[1])\n",
    "            beam_chosen=float(i[2])\n",
    "    alltots=writetotsource(array,freq_chosen)\n",
    "\n",
    "    vlbi_table2=f'VLBI_tot_{isource}.tex'\n",
    "\n",
    "    with open(vlbi_table2, 'w') as file:\n",
    "        if write1==True:\n",
    "            original_stdout = sys.stdout\n",
    "            sys.stdout = file\n",
    "\n",
    "        print(fr\"\"\"\\begin{{deluxetable*}}{{lllllll}}\\\n",
    "\\tablecaption{{VLBI extrapolations for {isource} to {freq_chosen:.0f} GHz}}\n",
    "\\tablehead{{ \n",
    "\\colhead{{Source}} & \\colhead{{Extrap Flux[mJy]$}} & \\colhead{{Freq[GHz]}} & \\colhead{{beamsize[\"]}} & \\colhead{{Reference}} & \\colhead{{Date}} \n",
    "}}\n",
    "\\startdata\"\"\")\n",
    "        \n",
    "        for iarray in alltots:\n",
    "            freq=float(iarray[4])\n",
    "            if freq<10:\n",
    "                freq=f\"{freq:.1f}\"\n",
    "            else:\n",
    "                freq=f\"{freq:.0f}\"\n",
    "\n",
    "            beamsize=iarray[5]\n",
    "            beamsize=format_number(beamsize)\n",
    "\n",
    "            if iarray[1]!='NA':\n",
    "                printflux=f\"{iarray[0]} ± {iarray[1]}\"\n",
    "            else:\n",
    "                printflux=f'{iarray[0]}*'\n",
    "    \n",
    "            newref = iarray[2].replace(\", \", \"\")\n",
    "\n",
    "            print(f\"\"\"{isource} &\n",
    "{printflux} &\n",
    "{freq} &\n",
    "{beamsize} &\n",
    "{newref} &\n",
    "{iarray[3]} \n",
    "\\\\\\\\\"\"\")\n",
    "            \n",
    "        print(fr\"\"\"\\enddata\n",
    "\\tablecomments{{{comments}}}\n",
    "\\end{{deluxetable*}}\"\"\")\n",
    "\n",
    "        if write1==True:\n",
    "            sys.stdout = original_stdout\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for sources without data at 200-400 GHz\n",
    "print(nograph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "\n",
    "def modified_blackbody_shape(nu, T, beta):\n",
    "    \"\"\"\n",
    "    Modified blackbody shape using Astropy constants:\n",
    "        S(nu) ∝ nu^(beta+3) / (exp(h nu / k_B T) - 1)\n",
    "    Parameters\n",
    "    ----------\n",
    "    nu : Quantity\n",
    "        Frequency (with units)\n",
    "    T : Quantity\n",
    "        Temperature (with units)\n",
    "    beta : float\n",
    "        Emissivity index\n",
    "    \"\"\"\n",
    "    x = (const.h * nu / (const.k_B * T)).decompose().value\n",
    "    return (nu.to(u.Hz).value ** (beta + 3)) / (np.exp(x) - 1)\n",
    "\n",
    "# Example: compare 20 K and 1500 K at 200 GHz\n",
    "nu = 200 * u.GHz\n",
    "beta = 1.5\n",
    "\n",
    "F_20   = modified_blackbody_shape(nu, 20 * u.K, beta)\n",
    "F_1500 = modified_blackbody_shape(nu, 2000 * u.K, beta)\n",
    "ratio  = F_1500 / F_20\n",
    "\n",
    "print(f\"nu = {nu}\")\n",
    "print(f\"S(nu) shape at T=20 K   : {F_20:.3e}\")\n",
    "print(f\"S(nu) shape at T=1500 K : {F_1500:.3e}\")\n",
    "print(f\"Ratio (1500 K / 20 K)   : {ratio:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
