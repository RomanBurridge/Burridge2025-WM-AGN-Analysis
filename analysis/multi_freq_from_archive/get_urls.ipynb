{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "os.chdir('analysis/multi_freq_from_archive')\n",
    "\n",
    "from astroquery.alma import Alma\n",
    "alma = Alma()\n",
    "from astropy import units as u\n",
    "from astropy import coordinates\n",
    "import numpy as np\n",
    "from astroquery.nvas import Nvas\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import wget\n",
    "\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on local computer to SMA Images\n",
    "parent_dir = Path.cwd().parent\n",
    "smapath=f'{parent_dir}/Gaussian_Fit_Pipline/230316_128/images/flag1_cal1/fields/science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to obtain coordinates from sourcename\n",
    "from astroquery.ipac.ned import Ned\n",
    "from PyAstronomy import pyasl\n",
    "from astropy import coordinates\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def getname(coord2,sourcename):\n",
    "    result_table = Ned.query_region(coord2, radius=1*u.arcsec, equinox='J2000')    \n",
    "    allnames=np.unique(result_table['Object Name'])\n",
    "    newsourcename='NA'\n",
    "    if len(allnames)>1:\n",
    "        while 0==0:\n",
    "            input(f'{len(allnames)} names exist for this location.  When cycling through names press y to store name.  Press Enter to start the cycling process.')\n",
    "            keepnames=[]\n",
    "            for iall in allnames:\n",
    "                yn=input(f'{iall}')\n",
    "                if yn=='y':\n",
    "                    isourcename=iall\n",
    "                    yn=input(f'The name you have choosen is {isourcename}.  Enter CHOOSE for this naming priority.  Enter KEEP to keep this name, but not as a priority.')\n",
    "\n",
    "                    if ' ' in isourcename:\n",
    "                        isourcename=isourcename.replace(' ','')\n",
    "                    if '\\n' in isourcename:\n",
    "                        isourcename=isourcename.replace('\\n','')  \n",
    "\n",
    "                    if yn=='CHOOSE':\n",
    "                        newsourcename=isourcename\n",
    "                    if yn=='KEEP':\n",
    "                        keepnames.append(isourcename)   \n",
    "\n",
    "            if newsourcename!='NA':\n",
    "                sourcename=newsourcename\n",
    "\n",
    "            input(f'your have chosen {sourcename} for the priority name')\n",
    "            input(f'your have chosen {keepnames} for the secondary names')\n",
    "            numchoose=input('Enter \"AGAIN\" to see the list again, or Enter to continue.')\n",
    "            if numchoose=='AGAIN':\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        newname=allnames[0]\n",
    "        if ' ' in newname:\n",
    "            newname=newname.replace(' ','')\n",
    "        if '\\n' in newname:\n",
    "            newname=newname.replace('\\n','')  \n",
    "        if newname.upper()==sourcename.upper():\n",
    "            sourcename=allnames[0]\n",
    "            keepnames=['NA']\n",
    "        else:\n",
    "            keepnames=[newname]\n",
    "    return(sourcename,keepnames)\n",
    "\n",
    "def getsourcenames():\n",
    "    files=[]\n",
    "    txtsources='sources.txt'\n",
    "\n",
    "    if os.path.exists(txtsources):\n",
    "        with open(txtsources, 'r') as infile:\n",
    "            remembernames=[]\n",
    "            for params in infile:\n",
    "                sourcename=params\n",
    "                try:\n",
    "                    result_table = Ned.query_object(sourcename)\n",
    "                except Exception as e:\n",
    "                    sourcename=input('Sourcename does not seem to exist.  Enter \"1\" to enter coordinates or rewrite \"sources.txt\"')\n",
    "\n",
    "                    if sourcename=='1':\n",
    "                        coord=input(f'Enter coordinates in J2000 hh:mm:ss dd:mm:ss')\n",
    "                        if ' ' not in coord:\n",
    "                            input(\"Improper coordinate format.  Try again\")\n",
    "                            continue\n",
    "                        coord=coord.split(' ')\n",
    "                        ra=coord[0]\n",
    "                        dec=coord[1]\n",
    "                        try:\n",
    "                            coord2 = coordinates.SkyCoord(ra=ra, dec=dec, unit=(u.hourangle, u.deg), frame='fk5')\n",
    "                        except Exception as e:\n",
    "                            input('Improper Coordinates.  Try again.')\n",
    "                            continue\n",
    "                        sourcename,keepnames=getname(coord2,sourcename)  \n",
    "                        input(f'The priority name of the source you have chosen is {sourcename}')\n",
    "                        result_table = Ned.query_object(sourcename)\n",
    "\n",
    "                ra=result_table['RA'][0]\n",
    "                dec=result_table['DEC'][0]\n",
    "                sexa = pyasl.coordsDegToSexa(ra, dec)\n",
    "                sexa=sexa.split(' ')\n",
    "                #rasexa=f'{sexa[0]}h{sexa[1]}m{sexa[2]}s'\n",
    "                #decsexa=f'{sexa[0]}d{sexa[1]}m{sexa[2]}s'\n",
    "                rasexa=f'{sexa[0]}:{sexa[1]}:{sexa[2]}'\n",
    "                decsexa=f'{sexa[4]}:{sexa[5]}:{sexa[6]}'\n",
    "\n",
    "                coord2 = coordinates.SkyCoord(ra=rasexa, dec=decsexa, unit=(u.hourangle, u.deg), frame='fk5')\n",
    "                \n",
    "                if ' ' in sourcename:\n",
    "                    sourcename=sourcename.replace(' ','')\n",
    "                if '\\n' in sourcename:\n",
    "                    sourcename=sourcename.replace('\\n','')\n",
    "\n",
    "                if sourcename!='NGC5765b':\n",
    "                    pass\n",
    "                    #continue\n",
    "\n",
    "                sourcename,keepnames=getname(coord2,sourcename) \n",
    "\n",
    "                if ' ' in sourcename:\n",
    "                    sourcename=sourcename.replace(' ','')\n",
    "                if '\\n' in sourcename:\n",
    "                    sourcename=sourcename.replace('\\n','')\n",
    "\n",
    "                totconts=[]\n",
    "                sciname1=sourcename\n",
    "                sciname2=keepnames\n",
    "\n",
    "                # Find all sequences of digits in the string\n",
    "                number_sequences1 = re.findall(r'\\d+', sciname1)\n",
    "\n",
    "                if number_sequences1!=[]:\n",
    "\n",
    "                    # Find the maximum length of the sequences\n",
    "                    max_length1 = max(len(seq) for seq in number_sequences1)\n",
    "\n",
    "                    # Get all sequences that have the maximum length\n",
    "                    longest_sequences1 = [seq for seq in number_sequences1 if len(seq) == max_length1]\n",
    "\n",
    "                else:\n",
    "                    newfind=1\n",
    "                    for iremembernames in remembernames:\n",
    "                        if iremembernames[0]==sciname1:\n",
    "                            newfind=0\n",
    "                            sciname1=iremembernames[1]\n",
    "                    if newfind==1:\n",
    "                        sciname1a=input(f\"Enter a name to look for in file names for {sciname1}\")\n",
    "                        remembernames.append([sciname1,sciname1a])\n",
    "                        sciname1=sciname1a\n",
    "\n",
    "                for itotconts in longest_sequences1:\n",
    "                    totconts.append(itotconts)\n",
    "\n",
    "                for isciname2 in sciname2:\n",
    "                    if sciname2[0]=='NA':\n",
    "                        continue\n",
    "                    number_sequences2 = re.findall(r'\\d+', isciname2)\n",
    "                    max_length2 = max(len(seq) for seq in number_sequences2)\n",
    "                    longest_sequences2 = [seq for seq in number_sequences2 if len(seq) == max_length2]\n",
    "\n",
    "                    for itotconts2 in longest_sequences2:\n",
    "                        totconts.append(itotconts2)\n",
    "\n",
    "                file=[[sourcename,keepnames],[totconts,rasexa,decsexa]]\n",
    "                files.append(file)\n",
    "    else:\n",
    "        input('Create file for source names names \"sources.txt\" with one line per source.')\n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make filenames using functions\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "txtnamesandcoords='namesandcoords.txt'\n",
    "\n",
    "yn2='y'\n",
    "if os.path.exists(txtnamesandcoords):\n",
    "    with open(txtnamesandcoords, 'r') as infile:\n",
    "        for params in infile:\n",
    "            params=eval(params)\n",
    "            for inamecoords in params:\n",
    "                oname=inamecoords[0]\n",
    "                nname=inamecoords[1][0]\n",
    "                ra=inamecoords[1][1]\n",
    "                dec=inamecoords[1][2]\n",
    "                #print(f'{oname.ljust(30)}: {nname}: {ra} {dec}')\n",
    "                print(oname)\n",
    "                files=inamecoords\n",
    "    namesandcoords=params\n",
    "    input(f'{txtnamesandcoords} already exist.  Take a look.')\n",
    "    yn2=input('Do you want to erase and write another? y/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string killer\n",
    "def killstrings(kills,file):\n",
    "    rasexa=file[1]\n",
    "    decsexa=file[2]\n",
    "\n",
    "    allkills=[]\n",
    "    for ikill in kills:\n",
    "        allkills.append(ikill)\n",
    "\n",
    "    thisnamer=file[0]\n",
    "    thisnamer3='notstring'\n",
    "    newx=0\n",
    "\n",
    "    killtxt='killtxt.txt'\n",
    "\n",
    "    if os.path.exists(killtxt):\n",
    "        with open(killtxt, 'r') as infile:\n",
    "            for params in infile:\n",
    "                allkills.append(params)\n",
    "\n",
    "    for iall in allkills:\n",
    "        if newx==0:\n",
    "            thisnamerar=[thisnamer]\n",
    "            thisnamer2=thisnamerar.copy()\n",
    "            thisnamer2=thisnamer2[0]\n",
    "        if newx==1:\n",
    "            thisnamer2=thisnamer3\n",
    "        kill1=[]\n",
    "        kill2=[]\n",
    "        if iall in thisnamer2:\n",
    "            kill1=thisnamer2.split(iall)[0]\n",
    "            kill2=thisnamer2.split(iall)[1]\n",
    "        if len(kill1)!=0:\n",
    "            if len(kill2)!=0:\n",
    "                break\n",
    "        if len(kill1)!=0:\n",
    "            if len(kill2)==0:\n",
    "                thisnamer3=kill1\n",
    "                newx=1\n",
    "        if len(kill2)!=0:\n",
    "            if len(kill1)==0:\n",
    "                thisnamer3=kill2 \n",
    "                newx=1\n",
    "    try: \n",
    "        for i in thisnamer3:\n",
    "            int(i)\n",
    "        filename=thisnamer3\n",
    "        return([[filename,rasexa,decsexa],allkills])\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "    while 0==0:     \n",
    "        if thisnamer3!='notstring':\n",
    "            thisnamer=thisnamer3      \n",
    "        if thisnamer3=='notstring':\n",
    "            thisnamer=file[0]   \n",
    "        kill=input(f'{thisnamer} choose a string to kill.  Enter 1 to choose your own file name.  Enter 2 to print off the string to copy and paste.  Press 3 to keep as is.')\n",
    "        if kill=='2':\n",
    "            print(thisnamer)\n",
    "            kill=input(f'{thisnamer} choose a string to kill.  Enter 1 to choose your own file name.')\n",
    "        if kill=='':\n",
    "            yn=input(f'Do you want to keep source name \"{thisnamer}\" as is?  Enter y/n')\n",
    "            if yn=='y':\n",
    "                filename=thisnamer\n",
    "                return([[filename,rasexa,decsexa],allkills])\n",
    "            else:\n",
    "                continue\n",
    "        if kill=='1':\n",
    "            newname=input(f'Enter New Filename')\n",
    "            yn=input(f'Do you want to keep source name \"{newname}\"?  Enter y/n')\n",
    "            if yn=='y':\n",
    "                filename=newname\n",
    "                return([[filename,rasexa,decsexa],allkills])\n",
    "            if yn=='n':\n",
    "                continue\n",
    "        if kill=='3':\n",
    "            filename=thisnamer\n",
    "            return([[filename,rasexa,decsexa],allkills])\n",
    "        killname=thisnamer.split(kill)\n",
    "        if len(killname)==1:\n",
    "            input('String you Entered is not in source try again')\n",
    "            continue\n",
    "\n",
    "        allkills.append(kill)\n",
    "        kill1=thisnamer.split(kill)[0]\n",
    "        kill2=thisnamer.split(kill)[1]\n",
    "\n",
    "        borf='3'\n",
    "        if len(kill1)!=0:\n",
    "            if len(kill2)!=0:\n",
    "                input('Enter a string to kill that is not in the middle')\n",
    "                continue\n",
    "\n",
    "        if len(kill1)!=0:\n",
    "            if len(kill2)==0:\n",
    "                filename=kill1\n",
    "                borf='4'\n",
    "\n",
    "        if len(kill2)!=0:\n",
    "            if len(kill1)==0:\n",
    "                filename=kill2\n",
    "                borf='4'\n",
    "\n",
    "        if borf==3:\n",
    "            input('something is wrong')\n",
    "\n",
    "        yn=input(f'Do you want to keep source name \"{filename}\"?  Enter y/n')\n",
    "        if yn=='y':\n",
    "            return([[filename,rasexa,decsexa],allkills])\n",
    "        if yn=='n':\n",
    "            yn=input(f'Do you want to remove more strings from \"{filename}\"?  Enter y.  Otherwise you will restart the naming process.')\n",
    "            if yn=='y':\n",
    "                newsend=([filename,rasexa,decsexa])\n",
    "                new=killstrings(allkills,newsend)\n",
    "                return([[new[0][0],rasexa,decsexa],new[1]])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write new strings with coordinates to a text\n",
    "if yn2=='y': \n",
    "    nfiles=getsourcenames()\n",
    "    txtnamesandcoords='namesandcoords.txt'\n",
    "    if os.path.exists(txtnamesandcoords):\n",
    "        os.remove(txtnamesandcoords)\n",
    "    with open(txtnamesandcoords, 'w') as file:\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = file\n",
    "        print(nfiles)\n",
    "        sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect urls from ALMA and VLA for selected targets\n",
    "#iterating for sources\n",
    "\n",
    "allsource_urls=[]\n",
    "\n",
    "if os.path.exists(txtnamesandcoords):\n",
    "    with open(txtnamesandcoords, 'r') as infile:\n",
    "        for params in infile:\n",
    "            params=eval(params)\n",
    "            files=params\n",
    "\n",
    "try:\n",
    "    VLAlist=os.listdir('VLA')\n",
    "    ALMAlist=os.listdir('ALMA')\n",
    "    checksize=len(VLAlist)+len(ALMAlist)\n",
    "except Exception as e:\n",
    "    checksize=0\n",
    "\n",
    "if checksize!=0:\n",
    "    downloadyn=input('Do you want to redownload urls?  y/n  ')\n",
    "\n",
    "if downloadyn=='y':\n",
    "    print('The first round of filtering only keeps files that contain \".fit\"')\n",
    "    print('And filters out names with \"_ph\", \"_bp\", \"README\", fluxcal\", \"phasecal\\n')\n",
    "    for file in files:\n",
    "        source=file[0][0]\n",
    "\n",
    "        #urls by a single source\n",
    "        all_urls=[]\n",
    "        ra=file[1][1]\n",
    "        dec=file[1][2]\n",
    "        galactic_center = coordinates.SkyCoord(ra, dec, frame='icrs', unit=(u.hourangle, u.deg))\n",
    "        print(f'vla urls for {source}')\n",
    "        vlaobs = Nvas.get_image_list(galactic_center, radius=2*u.arcsec)\n",
    "\n",
    "        #vla by observation\n",
    "        print(f'vla sizes for {source}')\n",
    "        for i in vlaobs:\n",
    "            url = i\n",
    "            if not 'fits' in url:\n",
    "                print(url)\n",
    "                input('check url')\n",
    "            response = requests.head(url)\n",
    "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "            all_urls.append([source,'vla',url,file_size])\n",
    "        print(f'alma observations for {source}')\n",
    "        gc_data = alma.query_region(galactic_center, 2*u.arcsec)\n",
    "\n",
    "        if len(gc_data)!=0:\n",
    "            membernames=[]\n",
    "            for igc_data in gc_data:\n",
    "                membername=igc_data['member_ous_uid']\n",
    "                membernames.append(membername)\n",
    "            membernames= np.unique(membernames)\n",
    "\n",
    "            #alma by observation\n",
    "            for membername in membernames:    \n",
    "                print(f'alma urls for {source} : {membername}')\n",
    "                almaobs = alma.get_data_info(membername, expand_tarfiles=True)\n",
    "\n",
    "                allboth=[]\n",
    "                for i in almaobs:\n",
    "                    url=i['access_url']\n",
    "                    uid=i['ID']\n",
    "                    size=i['content_length']\n",
    "\n",
    "                    #response = requests.head(url)\n",
    "                    #file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "                    #print(size)\n",
    "                    #print(file_size)\n",
    "                    #input('check')\n",
    "\n",
    "                    both=[url,uid,size]\n",
    "                    allboth.append(both)\n",
    "                #eliminating phase and bandpass urls\n",
    "                all_urls_3=[]\n",
    "                for i in allboth:\n",
    "                    url = i[0]\n",
    "                    if '_ph' in url:\n",
    "                        continue\n",
    "                    if '_bp' in url:\n",
    "                        continue\n",
    "                    if 'README' in url:\n",
    "                        continue\n",
    "                    if 'fluxcal' in url:\n",
    "                        continue\n",
    "                    if 'phasecal' in url:\n",
    "                        continue\n",
    "                    all_urls_3.append([source,'alma',i])\n",
    "\n",
    "                #sorting a single observation by suffix\n",
    "                tarfiles=[]\n",
    "                fitfiles=[]\n",
    "                xmlfiles=[]\n",
    "                tgzfiles=[]\n",
    "                txtfiles=[]\n",
    "                pyfiles=[]\n",
    "                logfiles=[]\n",
    "                pdffiles=[]\n",
    "                csvfiles=[]\n",
    "                htmlfiles=[]\n",
    "                datfiles=[]\n",
    "                pngfiles=[]\n",
    "\n",
    "                for i in all_urls_3:\n",
    "                    url=i[2][0]\n",
    "                    if '.tar' in url:\n",
    "                        tarfiles.append(i)\n",
    "                    elif '.fit' in url:\n",
    "                        fitfiles.append(i)\n",
    "                    elif '.xml' in url:\n",
    "                        tgzfiles.append(i)\n",
    "                    elif '.tgz' in url:\n",
    "                        tgzfiles.append(i)\n",
    "                    elif '.txt' in url:\n",
    "                        tgzfiles.append(i)\n",
    "                    elif '.py' in url:\n",
    "                        pyfiles.append(i)\n",
    "                    elif '.log' in url:\n",
    "                        logfiles.append(i)\n",
    "                    elif '.pdf' in url:\n",
    "                        pdffiles.append(i)\n",
    "                    elif '.csv' in url:\n",
    "                        csvfiles.append(i)\n",
    "                    elif '.html' in url:\n",
    "                        htmlfiles.append(i)\n",
    "                    elif '.dat' in url:\n",
    "                        datfiles.append(i) \n",
    "                    elif '.png' in url:\n",
    "                        pngfiles.append(i) \n",
    "                    else:\n",
    "                        print(i)\n",
    "                        input('check')\n",
    "\n",
    "                #storing files with .fit from a single observation to the source url\n",
    "                all_urls.append(fitfiles)\n",
    "        if len(gc_data)!=0:\n",
    "            all_urls.append([])\n",
    "            \n",
    "        allsource_urls.append(all_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for repeated urls\n",
    "if downloadyn=='y':\n",
    "    adatacheck=[]\n",
    "    for i in allsource_urls:\n",
    "        for ii in i:\n",
    "            if len(ii)==0:\n",
    "                continue\n",
    "            if ii[1]=='vla':\n",
    "                pass\n",
    "            elif ii[0][1]=='alma':\n",
    "                for iii in ii:\n",
    "                    adatacheck.append(iii)\n",
    "            else:\n",
    "                print(ii)\n",
    "                input('check telescope')\n",
    "\n",
    "    k1=-1\n",
    "    for i in adatacheck:\n",
    "        k1=k1+1\n",
    "        k2=-1\n",
    "        for ii in adatacheck:\n",
    "            k2=k2+1\n",
    "            if i[2][0]==ii[2][0]:\n",
    "                if k2!=k1:\n",
    "                    print(i)\n",
    "                    input('check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort through urls to find continuum images\n",
    "if downloadyn=='y':\n",
    "    vla_obs=[]\n",
    "    conts=[]\n",
    "\n",
    "    readmes=[]\n",
    "    contsub=[]\n",
    "    tt0s=[]\n",
    "    tt1s=[]\n",
    "    alphas=[]\n",
    "    lines=[]\n",
    "\n",
    "    mfss=[]\n",
    "    cubes=[]\n",
    "    repBWs=[]\n",
    "    sds=[]\n",
    "    concats=[]\n",
    "\n",
    "    Windows=[]\n",
    "    SBrings=[]\n",
    "\n",
    "    splitcals=[]\n",
    "    manuals=[]\n",
    "\n",
    "    chemicalurls=[]\n",
    "    others=[]\n",
    "\n",
    "    chemicals=['SiO',\n",
    "            'HeII',\n",
    "            'CS',\n",
    "            'H13CN',\n",
    "            'HCN',\n",
    "            'CO6',\n",
    "            '13CO',\n",
    "            'CH3CN',\n",
    "            'CH3OH',\n",
    "            'HC3N',\n",
    "            'C18O',\n",
    "            'CO32',\n",
    "            'CS76',\n",
    "            'HCOp43',\n",
    "            'C17O',\n",
    "            'CN',\n",
    "            'H2CO',\n",
    "            'HCN',\n",
    "            'NHC',\n",
    "            'C3H2',\n",
    "            'SO',\n",
    "            'CO21',\n",
    "            'CO',\n",
    "            'HCOp',\n",
    "            'H20',\n",
    "            'HNC',\n",
    "            'HC15N',\n",
    "            'co32',\n",
    "            ]\n",
    "\n",
    "    print('These observations do not have the following words in the filename: \"cont\", \"mfs\", \"repBW\", \"cube\", \"sd\", \"split.cal\".  However These words may still supply a continuum image file')\n",
    "    print('Files with the following words have also been filtered out: \"readme\", \"contsub\", \"tt0\", \"tt1\", \"alpha\", \"line\", \"concats\", and a variety of chemical names such as \"SiO')\n",
    "    print('***Look at the README for theses missing uids, as well as the observations that have words in the filename that may still supply a continuum image***')\n",
    "    print('***Figure out which band and how many other images at what epoch and resolution these images are to asses the necissesity of producing a continuum image***\\n')\n",
    "    #https://almascience.nrao.edu/portal/documents-and-tools/cycle9/alma-qa2-data-products-for-cycle-9\n",
    "    for i in allsource_urls:\n",
    "        for ii in i:\n",
    "            others=[]\n",
    "            if len(ii)==0:\n",
    "                continue\n",
    "            if ii[1]=='vla':\n",
    "                vla_obs.append(ii)\n",
    "            if ii[0][1]=='alma':\n",
    "                ireadmes=[]\n",
    "                icontsub=[]\n",
    "                itt0s=[]\n",
    "                itt1s=[]\n",
    "                ialphas=[]\n",
    "                ilines=[]\n",
    "                iconts=[]\n",
    "                iconcats=[]\n",
    "\n",
    "                imfss=[]\n",
    "                icubes=[]\n",
    "                irepBWs=[]\n",
    "                iWindows=[]\n",
    "                iSBrings=[]\n",
    "                isds=[]\n",
    "\n",
    "                isplitcals=[]\n",
    "                imanuals=[]\n",
    "\n",
    "                ichemicalurls=[]\n",
    "                iothers=[]\n",
    "\n",
    "                itot=[]\n",
    "                contcheck=[]\n",
    "                for iii in ii:\n",
    "                    itot.append(iii)\n",
    "                    size=iii[2][2]\n",
    "                    uid=iii[2][1]\n",
    "                    url=iii[2][0]\n",
    "                    source=iii[0]\n",
    "                    #Make a Function for Doing the following\n",
    "                    if 'README' in url:\n",
    "                        ireadmes.append(ii)\n",
    "                    #continuum subtracted\n",
    "                    elif 'contsub' in url:\n",
    "                        icontsub.append(url)\n",
    "                    #0th order Taylor Expansion\n",
    "                    elif 'tt0' in url:\n",
    "                        itt0s.append(url)\n",
    "                    #First order T.E.\n",
    "                    elif 'tt1' in url:\n",
    "                        itt1s.append(url)\n",
    "                    #Exponential Parameter\n",
    "                    elif 'alpha' in url:\n",
    "                        ialphas.append(url)\n",
    "                    #Spectral Line\n",
    "                    elif 'line' in url:\n",
    "                        ilines.append(url)\n",
    "                    #\"aggregate bandwidth image\"\n",
    "                    #Single bandwdith with extra data?\n",
    "                    elif 'mfs' in url:\n",
    "                        imfss.append(url)\n",
    "                    #2D Position and 1D Spectral => 3D Cube Array\n",
    "                    elif 'cube' in url:\n",
    "                        icubes.append(url)\n",
    "                    #\"cube at representative bandwidth\"\n",
    "                    elif 'repBW' in url:\n",
    "                        irepBWs.append(url)\n",
    "                    #Single Dish Observation\n",
    "                    elif 'sd' in url:\n",
    "                        isds.append(url)\n",
    "                    #Several visibility data sets\n",
    "                    elif 'concat' in url:\n",
    "                        iconcats.append(url)\n",
    "\n",
    "                    elif 'split.cal' in url:\n",
    "                        isplitcals.append(url)          \n",
    "                    \n",
    "                    elif 'Window_a' in url:\n",
    "                        iWindows.append([url,uid])\n",
    "\n",
    "                    elif 'SBring' in url:\n",
    "                        iSBrings.append([url,uid])\n",
    "\n",
    "                    elif 'manual' in url:\n",
    "                        imanuals.append([url,uid])\n",
    "\n",
    "                    #Continuum\n",
    "                    else:\n",
    "                        otherchecker=0\n",
    "                        for chem in chemicals:\n",
    "                            if chem in url:\n",
    "                                ichemicalurls.append(url)\n",
    "                                otherchecker=1\n",
    "\n",
    "                        if otherchecker==0:\n",
    "                            if 'cont' in url:\n",
    "                                iconts.append([url,size,source])\n",
    "                                contcheck.append(url)\n",
    "                            else:\n",
    "                                iothers.append(url)\n",
    "\n",
    "                Windows.append(iWindows)\n",
    "                SBrings.append(iSBrings)\n",
    "            \n",
    "                if len(contcheck)==0:\n",
    "                    if len(imfss)==0:\n",
    "                        if len(icubes)==0:\n",
    "                            if len(isds)==0:\n",
    "                                if len(iconcats)==0:\n",
    "                                    if len(ichemicalurls)==0:\n",
    "                                        if len(isplitcals)==0:\n",
    "                                            if len(imanuals)==0:\n",
    "                                                for i in itot:\n",
    "                                                    print(i)\n",
    "                                                print('\\n')\n",
    "                conts.append(iconts)\n",
    "\n",
    "    for i in Windows:\n",
    "        for ii in i:\n",
    "            url=ii[0]\n",
    "            uid=ii[1]\n",
    "            print(f'{uid}: Look at README')\n",
    "            print(f'\"_Window_a\" in url')\n",
    "            print(url)\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "    for i in SBrings:\n",
    "        for ii in i:\n",
    "            url=ii[0]\n",
    "            uid=ii[1]\n",
    "            print(f'{uid} Look at the README for ')\n",
    "            print(f'\"SBring\" in url:')\n",
    "            print(url)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter through continuums to choose one per observation\n",
    "import re\n",
    "\n",
    "if downloadyn=='y':\n",
    "    def keeponly_ifcan(contin,x):\n",
    "        contout=[]\n",
    "        xlower=x.lower()\n",
    "        for contj in contin:\n",
    "            contjlower=contj[0].lower()\n",
    "            #capitalization will not matter\n",
    "            if xlower in contjlower:\n",
    "                contout.append(contj)\n",
    "        if len(contout)==0:\n",
    "            contout=contin\n",
    "\n",
    "        return(contout)\n",
    "\n",
    "\n",
    "\n",
    "    if os.path.exists(txtnamesandcoords):\n",
    "        with open(txtnamesandcoords, 'r') as infile:\n",
    "            for params in infile:\n",
    "                params=eval(params)\n",
    "                files=params    \n",
    "\n",
    "    newvals=[]\n",
    "    sucess=0\n",
    "\n",
    "    remembernames=[]\n",
    "\n",
    "    for i in conts:\n",
    "        if i==[]:\n",
    "            continue\n",
    "        #https://almascience.eso.org/alma-data/ari_l\n",
    "        #ari_l seemse to be a more upgraded preprocessing pipeline\n",
    "        #pb_cor is the the cleaned imaged\n",
    "        #regcal as used as apposed to selfcal\n",
    "        source=i[0][2]\n",
    "        tester=0\n",
    "        for file in files:\n",
    "            isource=file[0][0]\n",
    "            if isource==source:\n",
    "                totconts=file[1][0]\n",
    "                tester=1\n",
    "        if tester==0:\n",
    "            input(f\"something wrong with {source}\")\n",
    "\n",
    "        newcontsb1=[]\n",
    "        for itotconts in totconts:\n",
    "            newcontsb1.append(keeponly_ifcan(i,itotconts))\n",
    "        newcontsb2=[]\n",
    "        nofind=1\n",
    "        for inewconts in newcontsb1:\n",
    "            #as long as inewconts is not the same as i newcontsb2 is filled and set to newconts\n",
    "            if len(inewconts)!=len(i):\n",
    "                for i2 in inewconts:\n",
    "                    newcontsb2.append(i2)\n",
    "        if newcontsb2!=[]:\n",
    "            newconts=newcontsb2\n",
    "        else:\n",
    "            #resorts to returning the original list\n",
    "            newconts=keeponly_ifcan(i,source)\n",
    "\n",
    "\n",
    "        newconts2=keeponly_ifcan(newconts,'pbcor')\n",
    "        newconts3=keeponly_ifcan(newconts2,'ari_l')\n",
    "        newconts4=keeponly_ifcan(newconts3,'regcal')\n",
    "\n",
    "        if len(newconts4)==0:\n",
    "            input('error')\n",
    "        if len(newconts4)>1: \n",
    "            for inewconts4 in newconts4:\n",
    "                print(inewconts4[0])\n",
    "            print('\\n')\n",
    "            sucess=sucess+1\n",
    "\n",
    "        newvals.append(newconts4)\n",
    "\n",
    "    if sucess==0:\n",
    "        print('SUCESS!  One continuum per observation If not Filtered Out')\n",
    "    else:\n",
    "        print('More Work to do.  More than one continuum per observation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download urls -- one per observation\n",
    "if downloadyn=='y':\n",
    "    path1='ALMA'\n",
    "    if os.path.exists(path1):\n",
    "        shutil.rmtree(path1)\n",
    "    os.mkdir(path1)\n",
    "\n",
    "    path2='VLA'\n",
    "    if os.path.exists(path2):\n",
    "        shutil.rmtree(path2)\n",
    "\n",
    "    os.mkdir(path2)\n",
    "\n",
    "    #for alma\n",
    "    for inewvals in newvals:\n",
    "        if len(inewvals)!=1:\n",
    "            input(f'more than 1 file for {inewvals}')\n",
    "        tele='alma'\n",
    "        source=inewvals[0][2]\n",
    "        size=inewvals[0][1]\n",
    "        url=inewvals[0][0]\n",
    "\n",
    "        path3=f'{path1}/{source}'\n",
    "        if not os.path.exists(path3):\n",
    "            os.mkdir(path3)\n",
    "\n",
    "        path4=f'{path3}'\n",
    "\n",
    "        print(f'{url} Downloading')\n",
    "        wget.download(url, out=path4)\n",
    "        print(f'{url} Done')\n",
    "\n",
    "        matcher=0\n",
    "        for ifile in files:\n",
    "            if ifile[0][0]==source:\n",
    "                ra=ifile[1][1]\n",
    "                dec=ifile[1][2]\n",
    "                matcher=1\n",
    "\n",
    "        if matcher==0:\n",
    "            input(f'no matchers for alma {url}')\n",
    "\n",
    "    for ivlas in vla_obs:\n",
    "        tele='vla'\n",
    "        source=ivlas[0]\n",
    "        size=ivlas[3]\n",
    "        url=ivlas[2]\n",
    "\n",
    "        path3=f'{path2}/{source}'\n",
    "        if not os.path.exists(path3):\n",
    "            os.mkdir(path3)\n",
    "\n",
    "        path4=f'{path3}'\n",
    "        #input(path4)\n",
    "            \n",
    "        print(f'{url} Downloading')\n",
    "        wget.download(url, out=path4)\n",
    "        print(f'{url} Done')\n",
    "\n",
    "        matcher=0\n",
    "        for ifile in files:\n",
    "            if ifile[0][0]==source:\n",
    "                ra=ifile[1][1]\n",
    "                dec=ifile[1][2]\n",
    "                matcher=1\n",
    "\n",
    "        if matcher==0:\n",
    "            input(f'no matchers for vla {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the coordinate is in the image\n",
    "if downloadyn=='y':\n",
    "    def check_coordinates_in_image(file_path, ra_hms, dec_dms):\n",
    "        try:\n",
    "            # Convert RA/Dec from sexagesimal to decimal degrees\n",
    "            target_coords = SkyCoord(ra=ra_hms, dec=dec_dms, unit=('hourangle', 'deg'), frame='icrs')\n",
    "            #ra_decimal, dec_decimal = target_coords.ra.deg, target_coords.dec.deg\n",
    "            # Open the file and extract WCS and image size\n",
    "            with fits.open(file_path) as hdul:\n",
    "                wcs = WCS(hdul[0].header)\n",
    "                image_size = hdul[0].data.shape[-2:]  # Get spatial dimensions\n",
    "            # Convert RA/Dec to pixel coordinates\n",
    "            pixel_coords = skycoord_to_pixel(target_coords, wcs)\n",
    "            # Check if pixel coordinates are within image bounds\n",
    "            x, y = pixel_coords\n",
    "            inside_image = (0 <= x < image_size[1]) and (0 <= y < image_size[0])\n",
    "            return inside_image\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "        \n",
    "    #for icheck in allcheck:\n",
    "    #file_path = 'VLA/4258/1.41I1.23_AD0364_1995AUG28_1_23.9U3.92M.imfits'\n",
    "    #file_path = 'VLA/4258/1.45I5.42_AH782_2002AUG11_1_213.U3000M.imfits'\n",
    "\n",
    "        for ifile in files:\n",
    "            continue\n",
    "            input(ifile[0])\n",
    "            if ifile[0]==source:\n",
    "                ra=ifile[1]\n",
    "                dec=ifile[2]\n",
    "                matcher=1\n",
    "        if matcher==0:\n",
    "            input(f'no matchers for {url}') \n",
    "\n",
    "    #file_path = 'VLA/5765b/1.45I5.42_AH782_2002AUG11_1_213.U3000M.imfits'\n",
    "    #ra='14:50:51.519'\n",
    "    #dec='05:06:52.317'\n",
    "\n",
    "    #ra_hms = \"12:18:57.5046\"\n",
    "    #dec_dms = \"47:18:14.303\"\n",
    "    #files=icheck[0]\n",
    "    #ra=icheck[1][0]\n",
    "\n",
    "    path1='ALMA'\n",
    "    path2='VLA'\n",
    "\n",
    "    #alma\n",
    "\n",
    "    whichsources=[]\n",
    "    totsources=[]\n",
    "    badfiles=[]\n",
    "\n",
    "    almasources=[]\n",
    "    for inewvals in newvals:\n",
    "        source=inewvals[0][2]\n",
    "        almasources.append(source)\n",
    "    ualmasources = list(set(almasources))\n",
    "\n",
    "\n",
    "    for source in ualmasources:\n",
    "\n",
    "        #path1 is alma\n",
    "        path3=f'{path1}/{source}'\n",
    "        path4=f'{path3}'\n",
    "\n",
    "        for ifile in files:\n",
    "            if ifile[0]==source:\n",
    "                ra=ifile[1]\n",
    "                dec=ifile[2]\n",
    "                matcher=1\n",
    "        if matcher==0:\n",
    "            input(f'no matchers for {url}')\n",
    "\n",
    "        almafiles=os.listdir(path4)\n",
    "        for ialmafile in almafiles:\n",
    "            ialmafile=f'{path4}/{ialmafile}'\n",
    "            if os.path.exists(ialmafile):\n",
    "                totsources.append(source)\n",
    "                cheval=check_coordinates_in_image(ialmafile,ra,dec)\n",
    "                if cheval!=True:\n",
    "                    print(ialmafile)\n",
    "                    badfiles.append(ialmafile)\n",
    "                    whichsources.append(source)\n",
    "                    if cheval!=False:\n",
    "                        input(f'not T or F:{cheval}')\n",
    "\n",
    "    vlasources=[]\n",
    "    for ivals in vla_obs:\n",
    "        source=ivlas[0]\n",
    "        vlasources.append(source)\n",
    "    uvlasources = list(set(almasources))\n",
    "\n",
    "    for source in uvlasources:\n",
    "        source=ivlas[0]\n",
    "\n",
    "        path3=f'{path2}/{source}'\n",
    "        path4=f'{path3}'\n",
    "\n",
    "        for ifile in files:\n",
    "            if ifile[0]==source:\n",
    "                ra=ifile[1]\n",
    "                dec=ifile[2]\n",
    "                matcher=1\n",
    "        if matcher==0:\n",
    "            input(f'no matchers for {url}')\n",
    "\n",
    "        vlafiles=os.listdir(path4)\n",
    "        for ivlafile in vlafiles:\n",
    "            if os.path.exists(ivlafile):\n",
    "                totsources.append(source)\n",
    "                if cheval!=True:\n",
    "                    print(ivlafile)\n",
    "                    badfiles.append(ivlafile)\n",
    "                    whichsources.append(source)\n",
    "                    if cheval!=False:\n",
    "                        input(f'not T or F:{cheval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Percentage of files that are outside of the coordinate for each source\n",
    "if downloadyn=='download':\n",
    "    conts = Counter(whichsources)\n",
    "    contstot = Counter(totsources)\n",
    "\n",
    "    key_to_dicts = defaultdict(list)\n",
    "\n",
    "    for key in set(conts.keys()).union(contstot.keys()):\n",
    "        key_to_dicts[key].append(conts.get(key, 0)) \n",
    "        key_to_dicts[key].append(contstot.get(key, 0))  \n",
    "\n",
    "    for key, counts in key_to_dicts.items():\n",
    "        pass\n",
    "        #print(f\"{key}: {counts}\")\n",
    "\n",
    "    percentages = {\n",
    "        key: (counts[0] / counts[1]) * 100 if counts[1] != 0 else 0\n",
    "        for key, counts in key_to_dicts.items()\n",
    "    }\n",
    "\n",
    "    print(\"Percentage of Files that are wrong coordinates for Each Source:\")\n",
    "    for key, percentage in percentages.items():\n",
    "        if percentage!=0:\n",
    "            print(f\"{key}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Files where coordinate is outside of image\n",
    "if downloadyn=='download':\n",
    "    for i in badfiles:\n",
    "        print(f\"Processing: {i}\")\n",
    "        if os.path.exists(i):\n",
    "            try:\n",
    "                if os.path.isfile(i):\n",
    "                    os.remove(i)  # Remove file\n",
    "                    print(f\"File removed: {i}\")\n",
    "                elif os.path.isdir(i):\n",
    "                    shutil.rmtree(i)  # Remove directory\n",
    "                    print(f\"Directory removed: {i}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error while removing {i}: {e}\")\n",
    "        else:\n",
    "            print(f\"Path does not exist: {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
